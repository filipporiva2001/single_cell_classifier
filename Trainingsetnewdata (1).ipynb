{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f20f680b-9de0-4519-93d7-795622d77621",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-09 13:54:17.693399: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-09 13:54:17.739946: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-09 13:54:18.633390: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /n/sci/SCI-004375-NYUDATA/Filippo/Multiome\n",
      "90% split point for P24: 58390\n",
      "90% split point for P48: 54368\n",
      "90% split point for Adult: 42648\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import glob\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from joblib import dump\n",
    "import os\n",
    "\n",
    "\n",
    "# Assuming P24, P48, and Adult datasets are loaded as numpy arrays\n",
    "# Define the directory path where your data is located\n",
    "directory_path = '/n/sci/SCI-004375-NYUDATA/Filippo/Multiome'\n",
    "os.chdir(directory_path)\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# Loading in shuffled datasets with full file paths\n",
    "Adult = np.load(os.path.join(directory_path, \"AdultData_Shuffled.npy\"))\n",
    "ClustersAdult = np.load(os.path.join(directory_path, \"AdultIDs_Shuffled.npy\"))\n",
    "\n",
    "P24 = np.load(os.path.join(directory_path, \"P24Data_Shuffled.npy\"))\n",
    "ClustersP24 = np.load(os.path.join(directory_path, \"P24IDs_Shuffled.npy\"))\n",
    "\n",
    "P48 = np.load(os.path.join(directory_path, \"P48Data_Shuffled.npy\"))\n",
    "ClustersP48 = np.load(os.path.join(directory_path, \"P48IDs_Shuffled.npy\"))\n",
    "# Calculate 90% split point for each dataset\n",
    "split_P24 = int(len(P24) * 0.9)\n",
    "split_P48 = int(len(P48) * 0.9)\n",
    "split_Adult = int(len(Adult) * 0.9)\n",
    "\n",
    "# Print the split points\n",
    "print(\"90% split point for P24:\", split_P24)\n",
    "print(\"90% split point for P48:\", split_P48)\n",
    "print(\"90% split point for Adult:\", split_Adult)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c20d4435-8d4a-4933-a423-80bcb190c12a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 13:16:09.609362: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-11 13:16:09.653132: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-11 13:16:12.201466: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /n/sci/SCI-004375-NYUDATA/Filippo/Multiome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 13:16:17.445269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38141 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:e3:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1\n",
      "Run 1, Epoch 1/30\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1720721778.440549 2586610 service.cc:145] XLA service 0x7fd37c007d60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1720721778.440581 2586610 service.cc:153]   StreamExecutor device (0): NVIDIA A100-PCIE-40GB, Compute Capability 8.0\n",
      "2024-07-11 13:16:18.461797: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-11 13:16:19.348876: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m166/371\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.2598 - loss: 5.3180"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1720721781.955193 2586610 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3839 - loss: 4.7167  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1720721784.803382 2586680 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_65', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "I0000 00:00:1720721785.280731 2586680 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_65', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "I0000 00:00:1720721786.428635 2586680 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_65', 188 bytes spill stores, 188 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.81874, saving model to autosaveAdult_1_01.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - accuracy: 0.3843 - loss: 4.7152 - val_accuracy: 0.8187 - val_loss: 2.9388 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4570 - loss: 4.0862  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1720721795.207732 2586805 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_65', 300 bytes spill stores, 300 bytes spill loads\n",
      "\n",
      "I0000 00:00:1720721795.280023 2586800 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_65', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "I0000 00:00:1720721795.700615 2586801 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_65', 40 bytes spill stores, 40 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.84772, saving model to autosaveP24_1_01.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.4573 - loss: 4.0848 - val_accuracy: 0.8477 - val_loss: 2.2092 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4686 - loss: 6.4613  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.88297, saving model to autosaveP48_1_01.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.4688 - loss: 6.4666 - val_accuracy: 0.8830 - val_loss: 9.4000 - learning_rate: 0.0500\n",
      "Run 1, Epoch 2/30\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6407 - loss: 3.6684  \n",
      "Epoch 2: val_accuracy improved from 0.81874 to 0.82781, saving model to autosaveAdult_1_02.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6407 - loss: 3.6685 - val_accuracy: 0.8278 - val_loss: 2.8421 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7095 - loss: 2.7416  \n",
      "Epoch 2: val_accuracy improved from 0.84772 to 0.86174, saving model to autosaveP24_1_02.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7095 - loss: 2.7415 - val_accuracy: 0.8617 - val_loss: 2.0548 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6888 - loss: 9.9202  \n",
      "Epoch 2: val_accuracy improved from 0.88297 to 0.94123, saving model to autosaveP48_1_02.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.6888 - loss: 9.9169 - val_accuracy: 0.9412 - val_loss: 4.5293 - learning_rate: 0.0500\n",
      "Run 1, Epoch 3/30\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6940 - loss: 3.0351  \n",
      "Epoch 3: val_accuracy improved from 0.82781 to 0.85714, saving model to autosaveAdult_1_03.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6941 - loss: 3.0343 - val_accuracy: 0.8571 - val_loss: 2.0414 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7653 - loss: 2.2157  \n",
      "Epoch 3: val_accuracy improved from 0.86174 to 0.89350, saving model to autosaveP24_1_03.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7653 - loss: 2.2153 - val_accuracy: 0.8935 - val_loss: 1.5240 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8064 - loss: 4.5531  \n",
      "Epoch 3: val_accuracy improved from 0.94123 to 0.95315, saving model to autosaveP48_1_03.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8065 - loss: 4.5515 - val_accuracy: 0.9532 - val_loss: 2.3516 - learning_rate: 0.0250\n",
      "Run 1, Epoch 4/30\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7694 - loss: 2.1200  \n",
      "Epoch 4: val_accuracy improved from 0.85714 to 0.85925, saving model to autosaveAdult_1_04.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7694 - loss: 2.1198 - val_accuracy: 0.8593 - val_loss: 1.7571 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8080 - loss: 1.6758  \n",
      "Epoch 4: val_accuracy improved from 0.89350 to 0.89535, saving model to autosaveP24_1_04.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8080 - loss: 1.6757 - val_accuracy: 0.8953 - val_loss: 1.3860 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8734 - loss: 2.4295  \n",
      "Epoch 4: val_accuracy improved from 0.95315 to 0.95779, saving model to autosaveP48_1_04.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8734 - loss: 2.4290 - val_accuracy: 0.9578 - val_loss: 1.5772 - learning_rate: 0.0250\n",
      "Run 1, Epoch 5/30\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7863 - loss: 1.8129  \n",
      "Epoch 5: val_accuracy improved from 0.85925 to 0.86643, saving model to autosaveAdult_1_05.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7863 - loss: 1.8129 - val_accuracy: 0.8664 - val_loss: 1.6054 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8129 - loss: 1.5485  \n",
      "Epoch 5: val_accuracy did not improve from 0.89535\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8129 - loss: 1.5485 - val_accuracy: 0.8944 - val_loss: 1.3360 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8979 - loss: 1.6868  \n",
      "Epoch 5: val_accuracy improved from 0.95779 to 0.96706, saving model to autosaveP48_1_05.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8979 - loss: 1.6867 - val_accuracy: 0.9671 - val_loss: 1.2199 - learning_rate: 0.0250\n",
      "Run 1, Epoch 6/30\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7992 - loss: 1.6543  \n",
      "Epoch 6: val_accuracy improved from 0.86643 to 0.86790, saving model to autosaveAdult_1_06.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7992 - loss: 1.6542 - val_accuracy: 0.8679 - val_loss: 1.4990 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8254 - loss: 1.4473  \n",
      "Epoch 6: val_accuracy improved from 0.89535 to 0.90059, saving model to autosaveP24_1_06.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8254 - loss: 1.4473 - val_accuracy: 0.9006 - val_loss: 1.2423 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9167 - loss: 1.3659  \n",
      "Epoch 6: val_accuracy improved from 0.96706 to 0.98163, saving model to autosaveP48_1_06.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9167 - loss: 1.3658 - val_accuracy: 0.9816 - val_loss: 1.0591 - learning_rate: 0.0125\n",
      "Run 1, Epoch 7/30\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8110 - loss: 1.5288  \n",
      "Epoch 7: val_accuracy improved from 0.86790 to 0.87086, saving model to autosaveAdult_1_07.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8110 - loss: 1.5288 - val_accuracy: 0.8709 - val_loss: 1.4380 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8333 - loss: 1.3408  \n",
      "Epoch 7: val_accuracy improved from 0.90059 to 0.90290, saving model to autosaveP24_1_07.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8333 - loss: 1.3408 - val_accuracy: 0.9029 - val_loss: 1.2004 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9262 - loss: 1.2396  \n",
      "Epoch 7: val_accuracy did not improve from 0.98163\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9262 - loss: 1.2395 - val_accuracy: 0.9808 - val_loss: 0.9907 - learning_rate: 0.0125\n",
      "Run 1, Epoch 8/30\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8187 - loss: 1.4497  \n",
      "Epoch 8: val_accuracy did not improve from 0.87086\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8187 - loss: 1.4497 - val_accuracy: 0.8668 - val_loss: 1.4297 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8387 - loss: 1.2968  \n",
      "Epoch 8: val_accuracy improved from 0.90290 to 0.90506, saving model to autosaveP24_1_08.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8387 - loss: 1.2969 - val_accuracy: 0.9051 - val_loss: 1.1774 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9272 - loss: 1.1646  \n",
      "Epoch 8: val_accuracy did not improve from 0.98163\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9272 - loss: 1.1646 - val_accuracy: 0.9745 - val_loss: 0.9499 - learning_rate: 0.0125\n",
      "Run 1, Epoch 9/30\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8203 - loss: 1.4112  \n",
      "Epoch 9: val_accuracy did not improve from 0.87086\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8203 - loss: 1.4111 - val_accuracy: 0.8658 - val_loss: 1.3823 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8450 - loss: 1.2623  \n",
      "Epoch 9: val_accuracy improved from 0.90506 to 0.91045, saving model to autosaveP24_1_09.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8450 - loss: 1.2623 - val_accuracy: 0.9105 - val_loss: 1.1544 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9319 - loss: 1.1098  \n",
      "Epoch 9: val_accuracy improved from 0.98163 to 0.98179, saving model to autosaveP48_1_09.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9319 - loss: 1.1098 - val_accuracy: 0.9818 - val_loss: 0.9154 - learning_rate: 0.0063\n",
      "Run 1, Epoch 10/30\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8166 - loss: 1.3885  \n",
      "Epoch 10: val_accuracy improved from 0.87086 to 0.87381, saving model to autosaveAdult_1_10.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8167 - loss: 1.3884 - val_accuracy: 0.8738 - val_loss: 1.3526 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8452 - loss: 1.2395  \n",
      "Epoch 10: val_accuracy did not improve from 0.91045\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8452 - loss: 1.2395 - val_accuracy: 0.9095 - val_loss: 1.1398 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9327 - loss: 1.0810  \n",
      "Epoch 10: val_accuracy improved from 0.98179 to 0.98212, saving model to autosaveP48_1_10.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9327 - loss: 1.0810 - val_accuracy: 0.9821 - val_loss: 0.8901 - learning_rate: 0.0063\n",
      "Run 1, Epoch 11/30\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8286 - loss: 1.3443  \n",
      "Epoch 11: val_accuracy improved from 0.87381 to 0.87550, saving model to autosaveAdult_1_11.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8286 - loss: 1.3443 - val_accuracy: 0.8755 - val_loss: 1.3302 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8471 - loss: 1.2198  \n",
      "Epoch 11: val_accuracy did not improve from 0.91045\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8471 - loss: 1.2199 - val_accuracy: 0.9084 - val_loss: 1.1283 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9385 - loss: 1.0497  \n",
      "Epoch 11: val_accuracy did not improve from 0.98212\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9385 - loss: 1.0497 - val_accuracy: 0.9768 - val_loss: 0.8845 - learning_rate: 0.0063\n",
      "Run 1, Epoch 12/30\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8313 - loss: 1.3195  \n",
      "Epoch 12: val_accuracy improved from 0.87550 to 0.87635, saving model to autosaveAdult_1_12.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8313 - loss: 1.3195 - val_accuracy: 0.8763 - val_loss: 1.3183 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8490 - loss: 1.2063  \n",
      "Epoch 12: val_accuracy improved from 0.91045 to 0.91122, saving model to autosaveP24_1_12.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8490 - loss: 1.2064 - val_accuracy: 0.9112 - val_loss: 1.1183 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9344 - loss: 1.0426  \n",
      "Epoch 12: val_accuracy did not improve from 0.98212\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9344 - loss: 1.0426 - val_accuracy: 0.9820 - val_loss: 0.8654 - learning_rate: 0.0031\n",
      "Run 1, Epoch 13/30\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8322 - loss: 1.3089  \n",
      "Epoch 13: val_accuracy improved from 0.87635 to 0.87719, saving model to autosaveAdult_1_13.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8322 - loss: 1.3089 - val_accuracy: 0.8772 - val_loss: 1.3178 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8503 - loss: 1.1865  \n",
      "Epoch 13: val_accuracy did not improve from 0.91122\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8503 - loss: 1.1865 - val_accuracy: 0.9068 - val_loss: 1.1131 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9378 - loss: 1.0300  \n",
      "Epoch 13: val_accuracy improved from 0.98212 to 0.98229, saving model to autosaveP48_1_13.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9378 - loss: 1.0299 - val_accuracy: 0.9823 - val_loss: 0.8563 - learning_rate: 0.0031\n",
      "Run 1, Epoch 14/30\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8291 - loss: 1.3085  \n",
      "Epoch 14: val_accuracy did not improve from 0.87719\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8291 - loss: 1.3085 - val_accuracy: 0.8761 - val_loss: 1.3068 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8469 - loss: 1.1808  \n",
      "Epoch 14: val_accuracy improved from 0.91122 to 0.91137, saving model to autosaveP24_1_14.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8469 - loss: 1.1808 - val_accuracy: 0.9114 - val_loss: 1.1064 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9395 - loss: 1.0159  \n",
      "Epoch 14: val_accuracy improved from 0.98229 to 0.98278, saving model to autosaveP48_1_14.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9395 - loss: 1.0159 - val_accuracy: 0.9828 - val_loss: 0.8494 - learning_rate: 0.0031\n",
      "Run 1, Epoch 15/30\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8306 - loss: 1.2953  \n",
      "Epoch 15: val_accuracy did not improve from 0.87719\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8306 - loss: 1.2953 - val_accuracy: 0.8761 - val_loss: 1.2999 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8522 - loss: 1.1637  \n",
      "Epoch 15: val_accuracy did not improve from 0.91137\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8522 - loss: 1.1637 - val_accuracy: 0.9100 - val_loss: 1.0992 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9405 - loss: 1.0051  \n",
      "Epoch 15: val_accuracy improved from 0.98278 to 0.98361, saving model to autosaveP48_1_15.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9405 - loss: 1.0051 - val_accuracy: 0.9836 - val_loss: 0.8447 - learning_rate: 0.0016\n",
      "Run 1, Epoch 16/30\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8369 - loss: 1.2741  \n",
      "Epoch 16: val_accuracy did not improve from 0.87719\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8369 - loss: 1.2741 - val_accuracy: 0.8761 - val_loss: 1.2981 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8537 - loss: 1.1564  \n",
      "Epoch 16: val_accuracy did not improve from 0.91137\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8537 - loss: 1.1565 - val_accuracy: 0.9109 - val_loss: 1.1000 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9405 - loss: 0.9980  \n",
      "Epoch 16: val_accuracy did not improve from 0.98361\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9405 - loss: 0.9980 - val_accuracy: 0.9829 - val_loss: 0.8401 - learning_rate: 0.0016\n",
      "Run 1, Epoch 17/30\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8352 - loss: 1.2710  \n",
      "Epoch 17: val_accuracy did not improve from 0.87719\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8352 - loss: 1.2711 - val_accuracy: 0.8759 - val_loss: 1.2922 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8554 - loss: 1.1605  \n",
      "Epoch 17: val_accuracy did not improve from 0.91137\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8554 - loss: 1.1605 - val_accuracy: 0.9106 - val_loss: 1.0971 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9422 - loss: 0.9933  \n",
      "Epoch 17: val_accuracy did not improve from 0.98361\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9422 - loss: 0.9933 - val_accuracy: 0.9834 - val_loss: 0.8373 - learning_rate: 0.0016\n",
      "Run 1, Epoch 18/30\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8358 - loss: 1.2748  \n",
      "Epoch 18: val_accuracy improved from 0.87719 to 0.87867, saving model to autosaveAdult_1_18.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8358 - loss: 1.2748 - val_accuracy: 0.8787 - val_loss: 1.2894 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8512 - loss: 1.1545  \n",
      "Epoch 18: val_accuracy improved from 0.91137 to 0.91245, saving model to autosaveP24_1_18.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8512 - loss: 1.1545 - val_accuracy: 0.9125 - val_loss: 1.0942 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9419 - loss: 0.9890  \n",
      "Epoch 18: val_accuracy did not improve from 0.98361\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9419 - loss: 0.9890 - val_accuracy: 0.9829 - val_loss: 0.8345 - learning_rate: 7.8125e-04\n",
      "Run 1, Epoch 19/30\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8339 - loss: 1.2751  \n",
      "Epoch 19: val_accuracy did not improve from 0.87867\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8339 - loss: 1.2751 - val_accuracy: 0.8782 - val_loss: 1.2875 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8519 - loss: 1.1618  \n",
      "Epoch 19: val_accuracy did not improve from 0.91245\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8519 - loss: 1.1617 - val_accuracy: 0.9121 - val_loss: 1.0934 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9432 - loss: 0.9866  \n",
      "Epoch 19: val_accuracy did not improve from 0.98361\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9432 - loss: 0.9866 - val_accuracy: 0.9826 - val_loss: 0.8344 - learning_rate: 7.8125e-04\n",
      "Run 1, Epoch 20/30\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8366 - loss: 1.2672  \n",
      "Epoch 20: val_accuracy did not improve from 0.87867\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8366 - loss: 1.2672 - val_accuracy: 0.8785 - val_loss: 1.2863 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8580 - loss: 1.1403  \n",
      "Epoch 20: val_accuracy improved from 0.91245 to 0.91261, saving model to autosaveP24_1_20.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8580 - loss: 1.1403 - val_accuracy: 0.9126 - val_loss: 1.0921 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9390 - loss: 0.9961  \n",
      "Epoch 20: val_accuracy did not improve from 0.98361\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9390 - loss: 0.9961 - val_accuracy: 0.9828 - val_loss: 0.8315 - learning_rate: 7.8125e-04\n",
      "Run 1, Epoch 21/30\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8357 - loss: 1.2594  \n",
      "Epoch 21: val_accuracy did not improve from 0.87867\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8357 - loss: 1.2595 - val_accuracy: 0.8780 - val_loss: 1.2850 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8537 - loss: 1.1487  \n",
      "Epoch 21: val_accuracy did not improve from 0.91261\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8537 - loss: 1.1487 - val_accuracy: 0.9123 - val_loss: 1.0908 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9411 - loss: 0.9942  \n",
      "Epoch 21: val_accuracy did not improve from 0.98361\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9411 - loss: 0.9942 - val_accuracy: 0.9829 - val_loss: 0.8302 - learning_rate: 3.9063e-04\n",
      "Run 1, Epoch 22/30\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8331 - loss: 1.2706  \n",
      "Epoch 22: val_accuracy did not improve from 0.87867\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8331 - loss: 1.2706 - val_accuracy: 0.8778 - val_loss: 1.2842 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8517 - loss: 1.1566  \n",
      "Epoch 22: val_accuracy did not improve from 0.91261\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8517 - loss: 1.1565 - val_accuracy: 0.9109 - val_loss: 1.0900 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9424 - loss: 0.9819  \n",
      "Epoch 22: val_accuracy did not improve from 0.98361\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9424 - loss: 0.9819 - val_accuracy: 0.9825 - val_loss: 0.8289 - learning_rate: 3.9063e-04\n",
      "Run 1, Epoch 23/30\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8380 - loss: 1.2672  \n",
      "Epoch 23: val_accuracy did not improve from 0.87867\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8380 - loss: 1.2672 - val_accuracy: 0.8782 - val_loss: 1.2837 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8553 - loss: 1.1477  \n",
      "Epoch 23: val_accuracy did not improve from 0.91261\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8553 - loss: 1.1477 - val_accuracy: 0.9125 - val_loss: 1.0889 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9436 - loss: 0.9902  \n",
      "Epoch 23: val_accuracy did not improve from 0.98361\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9436 - loss: 0.9902 - val_accuracy: 0.9828 - val_loss: 0.8285 - learning_rate: 3.9063e-04\n",
      "Run 1, Epoch 24/30\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8388 - loss: 1.2488  \n",
      "Epoch 24: val_accuracy did not improve from 0.87867\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8388 - loss: 1.2488 - val_accuracy: 0.8780 - val_loss: 1.2832 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8530 - loss: 1.1438  \n",
      "Epoch 24: val_accuracy did not improve from 0.91261\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8530 - loss: 1.1438 - val_accuracy: 0.9117 - val_loss: 1.0885 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9410 - loss: 0.9880  \n",
      "Epoch 24: val_accuracy did not improve from 0.98361\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9410 - loss: 0.9880 - val_accuracy: 0.9828 - val_loss: 0.8281 - learning_rate: 1.9531e-04\n",
      "Run 1, Epoch 25/30\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8349 - loss: 1.2658  \n",
      "Epoch 25: val_accuracy did not improve from 0.87867\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8349 - loss: 1.2658 - val_accuracy: 0.8785 - val_loss: 1.2826 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8540 - loss: 1.1496  \n",
      "Epoch 25: val_accuracy did not improve from 0.91261\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8540 - loss: 1.1496 - val_accuracy: 0.9121 - val_loss: 1.0881 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9424 - loss: 0.9746  \n",
      "Epoch 25: val_accuracy did not improve from 0.98361\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9424 - loss: 0.9746 - val_accuracy: 0.9828 - val_loss: 0.8273 - learning_rate: 1.9531e-04\n",
      "Run 1, Epoch 26/30\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8352 - loss: 1.2751  \n",
      "Epoch 26: val_accuracy did not improve from 0.87867\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8353 - loss: 1.2750 - val_accuracy: 0.8780 - val_loss: 1.2824 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8553 - loss: 1.1493  \n",
      "Epoch 26: val_accuracy did not improve from 0.91261\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8553 - loss: 1.1493 - val_accuracy: 0.9121 - val_loss: 1.0876 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9425 - loss: 0.9915  \n",
      "Epoch 26: val_accuracy did not improve from 0.98361\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9425 - loss: 0.9914 - val_accuracy: 0.9829 - val_loss: 0.8269 - learning_rate: 1.9531e-04\n",
      "Run 1, Epoch 27/30\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8395 - loss: 1.2580  \n",
      "Epoch 27: val_accuracy did not improve from 0.87867\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8395 - loss: 1.2580 - val_accuracy: 0.8776 - val_loss: 1.2822 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8564 - loss: 1.1455  \n",
      "Epoch 27: val_accuracy did not improve from 0.91261\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8564 - loss: 1.1455 - val_accuracy: 0.9118 - val_loss: 1.0874 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9433 - loss: 0.9826  \n",
      "Epoch 27: val_accuracy did not improve from 0.98361\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9433 - loss: 0.9826 - val_accuracy: 0.9829 - val_loss: 0.8266 - learning_rate: 9.7656e-05\n",
      "Run 1, Epoch 28/30\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8361 - loss: 1.2649  \n",
      "Epoch 28: val_accuracy did not improve from 0.87867\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8361 - loss: 1.2649 - val_accuracy: 0.8778 - val_loss: 1.2817 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8558 - loss: 1.1552  \n",
      "Epoch 28: val_accuracy did not improve from 0.91261\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8558 - loss: 1.1552 - val_accuracy: 0.9120 - val_loss: 1.0873 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9428 - loss: 0.9875  \n",
      "Epoch 28: val_accuracy did not improve from 0.98361\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9428 - loss: 0.9875 - val_accuracy: 0.9828 - val_loss: 0.8264 - learning_rate: 9.7656e-05\n",
      "Run 1, Epoch 29/30\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8358 - loss: 1.2587  \n",
      "Epoch 29: val_accuracy did not improve from 0.87867\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8358 - loss: 1.2587 - val_accuracy: 0.8778 - val_loss: 1.2812 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8550 - loss: 1.1448  \n",
      "Epoch 29: val_accuracy did not improve from 0.91261\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8550 - loss: 1.1448 - val_accuracy: 0.9123 - val_loss: 1.0871 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9445 - loss: 0.9753  \n",
      "Epoch 29: val_accuracy did not improve from 0.98361\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9445 - loss: 0.9753 - val_accuracy: 0.9828 - val_loss: 0.8262 - learning_rate: 9.7656e-05\n",
      "Run 1, Epoch 30/30\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8352 - loss: 1.2646  \n",
      "Epoch 30: val_accuracy did not improve from 0.87867\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8352 - loss: 1.2646 - val_accuracy: 0.8778 - val_loss: 1.2812 - learning_rate: 4.8828e-05\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8579 - loss: 1.1399  \n",
      "Epoch 30: val_accuracy did not improve from 0.91261\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8578 - loss: 1.1399 - val_accuracy: 0.9117 - val_loss: 1.0870 - learning_rate: 4.8828e-05\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9434 - loss: 0.9816  \n",
      "Epoch 30: val_accuracy did not improve from 0.98361\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9434 - loss: 0.9816 - val_accuracy: 0.9828 - val_loss: 0.8260 - learning_rate: 4.8828e-05\n",
      "Completed run 1 with 30 epochs\n",
      "autosaveAdult_1_18.keras\n",
      "\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8819 - loss: 1.2786\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8779 - loss: 1.2932\n",
      "New best model saved: best_model_Adult_run_1.keras\n",
      "autosaveP24_1_20.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2584682/1666383140.py:229: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  EvalTable = pd.concat([EvalTable, pd.DataFrame({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1825/1825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9084 - loss: 1.1017\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9096 - loss: 1.1142\n",
      "New best model saved: best_model_P24_run_1.keras\n",
      "autosaveP48_1_15.keras\n",
      "\u001b[1m1699/1699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 620us/step - accuracy: 0.9798 - loss: 0.8564\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9829 - loss: 0.8532\n",
      "New best model saved: best_model_P48_run_1.keras\n",
      "Starting run 2\n",
      "Run 2, Epoch 1/30\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7506 - loss: 1.8925  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.81177, saving model to autosaveAdult_2_01.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7504 - loss: 1.8939 - val_accuracy: 0.8118 - val_loss: 2.5325 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7701 - loss: 1.8575  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.87485, saving model to autosaveP24_2_01.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7701 - loss: 1.8583 - val_accuracy: 0.8748 - val_loss: 1.9181 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8383 - loss: 2.2038  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.91905, saving model to autosaveP48_2_01.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8382 - loss: 2.2062 - val_accuracy: 0.9191 - val_loss: 3.3302 - learning_rate: 0.0500\n",
      "Run 2, Epoch 2/30\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6625 - loss: 3.0775  \n",
      "Epoch 2: val_accuracy improved from 0.81177 to 0.81536, saving model to autosaveAdult_2_02.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6624 - loss: 3.0780 - val_accuracy: 0.8154 - val_loss: 2.8036 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7208 - loss: 2.5435  \n",
      "Epoch 2: val_accuracy did not improve from 0.87485\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7208 - loss: 2.5437 - val_accuracy: 0.8664 - val_loss: 2.0624 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7653 - loss: 4.0763  \n",
      "Epoch 2: val_accuracy improved from 0.91905 to 0.92650, saving model to autosaveP48_2_02.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7653 - loss: 4.0766 - val_accuracy: 0.9265 - val_loss: 3.5037 - learning_rate: 0.0500\n",
      "Run 2, Epoch 3/30\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6940 - loss: 2.9788  \n",
      "Epoch 3: val_accuracy improved from 0.81536 to 0.85820, saving model to autosaveAdult_2_03.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6941 - loss: 2.9779 - val_accuracy: 0.8582 - val_loss: 2.0065 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7655 - loss: 2.2036  \n",
      "Epoch 3: val_accuracy improved from 0.87485 to 0.89535, saving model to autosaveP24_2_03.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7655 - loss: 2.2032 - val_accuracy: 0.8953 - val_loss: 1.4933 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8152 - loss: 3.6298  \n",
      "Epoch 3: val_accuracy improved from 0.92650 to 0.95994, saving model to autosaveP48_2_03.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8153 - loss: 3.6286 - val_accuracy: 0.9599 - val_loss: 1.9283 - learning_rate: 0.0250\n",
      "Run 2, Epoch 4/30\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7720 - loss: 2.0371  \n",
      "Epoch 4: val_accuracy improved from 0.85820 to 0.86790, saving model to autosaveAdult_2_04.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7720 - loss: 2.0370 - val_accuracy: 0.8679 - val_loss: 1.6860 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8104 - loss: 1.6353  \n",
      "Epoch 4: val_accuracy did not improve from 0.89535\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8104 - loss: 1.6352 - val_accuracy: 0.8932 - val_loss: 1.3317 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8901 - loss: 1.9768  \n",
      "Epoch 4: val_accuracy improved from 0.95994 to 0.96871, saving model to autosaveP48_2_04.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8901 - loss: 1.9764 - val_accuracy: 0.9687 - val_loss: 1.3237 - learning_rate: 0.0250\n",
      "Run 2, Epoch 5/30\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7937 - loss: 1.7564  \n",
      "Epoch 5: val_accuracy did not improve from 0.86790\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7937 - loss: 1.7564 - val_accuracy: 0.8580 - val_loss: 1.5702 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8172 - loss: 1.4899  \n",
      "Epoch 5: val_accuracy did not improve from 0.89535\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8172 - loss: 1.4899 - val_accuracy: 0.8889 - val_loss: 1.3171 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9075 - loss: 1.4817  \n",
      "Epoch 5: val_accuracy improved from 0.96871 to 0.97451, saving model to autosaveP48_2_05.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9075 - loss: 1.4816 - val_accuracy: 0.9745 - val_loss: 1.0961 - learning_rate: 0.0250\n",
      "Run 2, Epoch 6/30\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8051 - loss: 1.5787  \n",
      "Epoch 6: val_accuracy improved from 0.86790 to 0.87023, saving model to autosaveAdult_2_06.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8051 - loss: 1.5787 - val_accuracy: 0.8702 - val_loss: 1.4605 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8263 - loss: 1.4016  \n",
      "Epoch 6: val_accuracy improved from 0.89535 to 0.89735, saving model to autosaveP24_2_06.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8263 - loss: 1.4015 - val_accuracy: 0.8973 - val_loss: 1.2071 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9242 - loss: 1.2515  \n",
      "Epoch 6: val_accuracy improved from 0.97451 to 0.97898, saving model to autosaveP48_2_06.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9242 - loss: 1.2514 - val_accuracy: 0.9790 - val_loss: 0.9867 - learning_rate: 0.0125\n",
      "Run 2, Epoch 7/30\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8128 - loss: 1.4855  \n",
      "Epoch 7: val_accuracy improved from 0.87023 to 0.87107, saving model to autosaveAdult_2_07.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8128 - loss: 1.4854 - val_accuracy: 0.8711 - val_loss: 1.3952 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8365 - loss: 1.3172  \n",
      "Epoch 7: val_accuracy improved from 0.89735 to 0.90274, saving model to autosaveP24_2_07.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8365 - loss: 1.3172 - val_accuracy: 0.9027 - val_loss: 1.1727 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9282 - loss: 1.1571  \n",
      "Epoch 7: val_accuracy did not improve from 0.97898\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9282 - loss: 1.1571 - val_accuracy: 0.9772 - val_loss: 0.9313 - learning_rate: 0.0125\n",
      "Run 2, Epoch 8/30\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8239 - loss: 1.4112  \n",
      "Epoch 8: val_accuracy improved from 0.87107 to 0.87318, saving model to autosaveAdult_2_08.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8239 - loss: 1.4112 - val_accuracy: 0.8732 - val_loss: 1.3636 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8378 - loss: 1.2797  \n",
      "Epoch 8: val_accuracy did not improve from 0.90274\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8378 - loss: 1.2797 - val_accuracy: 0.9003 - val_loss: 1.1542 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9311 - loss: 1.0870  \n",
      "Epoch 8: val_accuracy improved from 0.97898 to 0.98014, saving model to autosaveP48_2_08.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9311 - loss: 1.0870 - val_accuracy: 0.9801 - val_loss: 0.8968 - learning_rate: 0.0125\n",
      "Run 2, Epoch 9/30\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8231 - loss: 1.3601  \n",
      "Epoch 9: val_accuracy improved from 0.87318 to 0.87613, saving model to autosaveAdult_2_09.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8231 - loss: 1.3601 - val_accuracy: 0.8761 - val_loss: 1.3352 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8432 - loss: 1.2392  \n",
      "Epoch 9: val_accuracy improved from 0.90274 to 0.90906, saving model to autosaveP24_2_09.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8432 - loss: 1.2392 - val_accuracy: 0.9091 - val_loss: 1.1243 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9350 - loss: 1.0552  \n",
      "Epoch 9: val_accuracy improved from 0.98014 to 0.98378, saving model to autosaveP48_2_09.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9350 - loss: 1.0552 - val_accuracy: 0.9838 - val_loss: 0.8649 - learning_rate: 0.0063\n",
      "Run 2, Epoch 10/30\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8248 - loss: 1.3411  \n",
      "Epoch 10: val_accuracy did not improve from 0.87613\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8248 - loss: 1.3411 - val_accuracy: 0.8749 - val_loss: 1.3183 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8460 - loss: 1.2214  \n",
      "Epoch 10: val_accuracy improved from 0.90906 to 0.91292, saving model to autosaveP24_2_10.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8460 - loss: 1.2214 - val_accuracy: 0.9129 - val_loss: 1.1138 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9391 - loss: 1.0281  \n",
      "Epoch 10: val_accuracy did not improve from 0.98378\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9391 - loss: 1.0281 - val_accuracy: 0.9806 - val_loss: 0.8517 - learning_rate: 0.0063\n",
      "Run 2, Epoch 11/30\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8248 - loss: 1.3256  \n",
      "Epoch 11: val_accuracy did not improve from 0.87613\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8248 - loss: 1.3255 - val_accuracy: 0.8755 - val_loss: 1.3066 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8489 - loss: 1.1923  \n",
      "Epoch 11: val_accuracy did not improve from 0.91292\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8489 - loss: 1.1923 - val_accuracy: 0.9084 - val_loss: 1.1019 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9385 - loss: 1.0069  \n",
      "Epoch 11: val_accuracy did not improve from 0.98378\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9385 - loss: 1.0069 - val_accuracy: 0.9833 - val_loss: 0.8354 - learning_rate: 0.0063\n",
      "Run 2, Epoch 12/30\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8286 - loss: 1.2844  \n",
      "Epoch 12: val_accuracy improved from 0.87613 to 0.87677, saving model to autosaveAdult_2_12.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8286 - loss: 1.2844 - val_accuracy: 0.8768 - val_loss: 1.2910 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8524 - loss: 1.1790  \n",
      "Epoch 12: val_accuracy did not improve from 0.91292\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8524 - loss: 1.1790 - val_accuracy: 0.9095 - val_loss: 1.0932 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9428 - loss: 0.9841  \n",
      "Epoch 12: val_accuracy improved from 0.98378 to 0.98394, saving model to autosaveP48_2_12.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9428 - loss: 0.9841 - val_accuracy: 0.9839 - val_loss: 0.8231 - learning_rate: 0.0031\n",
      "Run 2, Epoch 13/30\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8327 - loss: 1.2802  \n",
      "Epoch 13: val_accuracy did not improve from 0.87677\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8327 - loss: 1.2802 - val_accuracy: 0.8768 - val_loss: 1.2781 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8507 - loss: 1.1672  \n",
      "Epoch 13: val_accuracy did not improve from 0.91292\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8507 - loss: 1.1672 - val_accuracy: 0.9089 - val_loss: 1.0916 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9444 - loss: 0.9756  \n",
      "Epoch 13: val_accuracy did not improve from 0.98394\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9444 - loss: 0.9756 - val_accuracy: 0.9823 - val_loss: 0.8194 - learning_rate: 0.0031\n",
      "Run 2, Epoch 14/30\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8345 - loss: 1.2690  \n",
      "Epoch 14: val_accuracy did not improve from 0.87677\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8345 - loss: 1.2690 - val_accuracy: 0.8761 - val_loss: 1.2738 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8513 - loss: 1.1487  \n",
      "Epoch 14: val_accuracy did not improve from 0.91292\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8513 - loss: 1.1488 - val_accuracy: 0.9105 - val_loss: 1.0827 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9418 - loss: 0.9715  \n",
      "Epoch 14: val_accuracy did not improve from 0.98394\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9418 - loss: 0.9715 - val_accuracy: 0.9818 - val_loss: 0.8104 - learning_rate: 0.0031\n",
      "Run 2, Epoch 15/30\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8347 - loss: 1.2543  \n",
      "Epoch 15: val_accuracy improved from 0.87677 to 0.87719, saving model to autosaveAdult_2_15.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8347 - loss: 1.2543 - val_accuracy: 0.8772 - val_loss: 1.2688 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8554 - loss: 1.1385  \n",
      "Epoch 15: val_accuracy did not improve from 0.91292\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8554 - loss: 1.1385 - val_accuracy: 0.9121 - val_loss: 1.0798 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9404 - loss: 0.9734  \n",
      "Epoch 15: val_accuracy did not improve from 0.98394\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9404 - loss: 0.9734 - val_accuracy: 0.9839 - val_loss: 0.8063 - learning_rate: 0.0016\n",
      "Run 2, Epoch 16/30\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8377 - loss: 1.2537  \n",
      "Epoch 16: val_accuracy improved from 0.87719 to 0.87761, saving model to autosaveAdult_2_16.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8377 - loss: 1.2537 - val_accuracy: 0.8776 - val_loss: 1.2640 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8564 - loss: 1.1370  \n",
      "Epoch 16: val_accuracy improved from 0.91292 to 0.91307, saving model to autosaveP24_2_16.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8564 - loss: 1.1371 - val_accuracy: 0.9131 - val_loss: 1.0757 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9439 - loss: 0.9537  \n",
      "Epoch 16: val_accuracy did not improve from 0.98394\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9439 - loss: 0.9537 - val_accuracy: 0.9833 - val_loss: 0.8026 - learning_rate: 0.0016\n",
      "Run 2, Epoch 17/30\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8390 - loss: 1.2512  \n",
      "Epoch 17: val_accuracy did not improve from 0.87761\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8390 - loss: 1.2512 - val_accuracy: 0.8751 - val_loss: 1.2639 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8554 - loss: 1.1342  \n",
      "Epoch 17: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8554 - loss: 1.1343 - val_accuracy: 0.9108 - val_loss: 1.0743 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9441 - loss: 0.9533  \n",
      "Epoch 17: val_accuracy did not improve from 0.98394\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9441 - loss: 0.9533 - val_accuracy: 0.9829 - val_loss: 0.8028 - learning_rate: 0.0016\n",
      "Run 2, Epoch 18/30\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8349 - loss: 1.2387  \n",
      "Epoch 18: val_accuracy did not improve from 0.87761\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8349 - loss: 1.2387 - val_accuracy: 0.8755 - val_loss: 1.2588 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8582 - loss: 1.1384  \n",
      "Epoch 18: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8582 - loss: 1.1384 - val_accuracy: 0.9123 - val_loss: 1.0719 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9433 - loss: 0.9453  \n",
      "Epoch 18: val_accuracy did not improve from 0.98394\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9433 - loss: 0.9453 - val_accuracy: 0.9834 - val_loss: 0.7993 - learning_rate: 7.8125e-04\n",
      "Run 2, Epoch 19/30\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8364 - loss: 1.2437  \n",
      "Epoch 19: val_accuracy did not improve from 0.87761\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8364 - loss: 1.2437 - val_accuracy: 0.8759 - val_loss: 1.2579 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8556 - loss: 1.1328  \n",
      "Epoch 19: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8556 - loss: 1.1328 - val_accuracy: 0.9126 - val_loss: 1.0712 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9440 - loss: 0.9542  \n",
      "Epoch 19: val_accuracy did not improve from 0.98394\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9440 - loss: 0.9542 - val_accuracy: 0.9836 - val_loss: 0.7975 - learning_rate: 7.8125e-04\n",
      "Run 2, Epoch 20/30\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8407 - loss: 1.2401  \n",
      "Epoch 20: val_accuracy did not improve from 0.87761\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8407 - loss: 1.2401 - val_accuracy: 0.8772 - val_loss: 1.2560 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8567 - loss: 1.1397  \n",
      "Epoch 20: val_accuracy improved from 0.91307 to 0.91338, saving model to autosaveP24_2_20.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8567 - loss: 1.1396 - val_accuracy: 0.9134 - val_loss: 1.0698 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9419 - loss: 0.9530  \n",
      "Epoch 20: val_accuracy did not improve from 0.98394\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9419 - loss: 0.9530 - val_accuracy: 0.9833 - val_loss: 0.7962 - learning_rate: 7.8125e-04\n",
      "Run 2, Epoch 21/30\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8410 - loss: 1.2233  \n",
      "Epoch 21: val_accuracy did not improve from 0.87761\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8410 - loss: 1.2233 - val_accuracy: 0.8774 - val_loss: 1.2538 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8563 - loss: 1.1268  \n",
      "Epoch 21: val_accuracy did not improve from 0.91338\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8563 - loss: 1.1268 - val_accuracy: 0.9131 - val_loss: 1.0690 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9447 - loss: 0.9485  \n",
      "Epoch 21: val_accuracy did not improve from 0.98394\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9447 - loss: 0.9485 - val_accuracy: 0.9834 - val_loss: 0.7945 - learning_rate: 3.9063e-04\n",
      "Run 2, Epoch 22/30\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8391 - loss: 1.2365  \n",
      "Epoch 22: val_accuracy did not improve from 0.87761\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8391 - loss: 1.2364 - val_accuracy: 0.8774 - val_loss: 1.2530 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8580 - loss: 1.1197  \n",
      "Epoch 22: val_accuracy did not improve from 0.91338\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8580 - loss: 1.1197 - val_accuracy: 0.9128 - val_loss: 1.0683 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9447 - loss: 0.9503  \n",
      "Epoch 22: val_accuracy did not improve from 0.98394\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9447 - loss: 0.9503 - val_accuracy: 0.9833 - val_loss: 0.7941 - learning_rate: 3.9063e-04\n",
      "Run 2, Epoch 23/30\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8375 - loss: 1.2286  \n",
      "Epoch 23: val_accuracy did not improve from 0.87761\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8375 - loss: 1.2287 - val_accuracy: 0.8770 - val_loss: 1.2525 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8561 - loss: 1.1320  \n",
      "Epoch 23: val_accuracy did not improve from 0.91338\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8561 - loss: 1.1320 - val_accuracy: 0.9134 - val_loss: 1.0679 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9444 - loss: 0.9458  \n",
      "Epoch 23: val_accuracy did not improve from 0.98394\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9444 - loss: 0.9457 - val_accuracy: 0.9834 - val_loss: 0.7939 - learning_rate: 3.9063e-04\n",
      "Run 2, Epoch 24/30\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8393 - loss: 1.2363  \n",
      "Epoch 24: val_accuracy improved from 0.87761 to 0.87782, saving model to autosaveAdult_2_24.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8393 - loss: 1.2363 - val_accuracy: 0.8778 - val_loss: 1.2520 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8547 - loss: 1.1290  \n",
      "Epoch 24: val_accuracy did not improve from 0.91338\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8547 - loss: 1.1290 - val_accuracy: 0.9121 - val_loss: 1.0677 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9444 - loss: 0.9412  \n",
      "Epoch 24: val_accuracy did not improve from 0.98394\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9444 - loss: 0.9413 - val_accuracy: 0.9836 - val_loss: 0.7936 - learning_rate: 1.9531e-04\n",
      "Run 2, Epoch 25/30\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8397 - loss: 1.2283  \n",
      "Epoch 25: val_accuracy did not improve from 0.87782\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8397 - loss: 1.2283 - val_accuracy: 0.8774 - val_loss: 1.2517 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8556 - loss: 1.1293  \n",
      "Epoch 25: val_accuracy did not improve from 0.91338\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8556 - loss: 1.1292 - val_accuracy: 0.9132 - val_loss: 1.0671 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9440 - loss: 0.9395  \n",
      "Epoch 25: val_accuracy did not improve from 0.98394\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9440 - loss: 0.9395 - val_accuracy: 0.9834 - val_loss: 0.7929 - learning_rate: 1.9531e-04\n",
      "Run 2, Epoch 26/30\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8390 - loss: 1.2306  \n",
      "Epoch 26: val_accuracy did not improve from 0.87782\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8390 - loss: 1.2306 - val_accuracy: 0.8770 - val_loss: 1.2515 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8544 - loss: 1.1188  \n",
      "Epoch 26: val_accuracy did not improve from 0.91338\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8544 - loss: 1.1188 - val_accuracy: 0.9132 - val_loss: 1.0671 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9439 - loss: 0.9509  \n",
      "Epoch 26: val_accuracy did not improve from 0.98394\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9439 - loss: 0.9509 - val_accuracy: 0.9831 - val_loss: 0.7929 - learning_rate: 1.9531e-04\n",
      "Run 2, Epoch 27/30\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8368 - loss: 1.2405  \n",
      "Epoch 27: val_accuracy did not improve from 0.87782\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8368 - loss: 1.2405 - val_accuracy: 0.8772 - val_loss: 1.2512 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8553 - loss: 1.1318  \n",
      "Epoch 27: val_accuracy did not improve from 0.91338\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8553 - loss: 1.1318 - val_accuracy: 0.9128 - val_loss: 1.0670 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9422 - loss: 0.9373  \n",
      "Epoch 27: val_accuracy did not improve from 0.98394\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9422 - loss: 0.9373 - val_accuracy: 0.9834 - val_loss: 0.7926 - learning_rate: 9.7656e-05\n",
      "Run 2, Epoch 28/30\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8396 - loss: 1.2269  \n",
      "Epoch 28: val_accuracy did not improve from 0.87782\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8396 - loss: 1.2269 - val_accuracy: 0.8770 - val_loss: 1.2510 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8559 - loss: 1.1310  \n",
      "Epoch 28: val_accuracy did not improve from 0.91338\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8559 - loss: 1.1310 - val_accuracy: 0.9131 - val_loss: 1.0668 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9457 - loss: 0.9433  \n",
      "Epoch 28: val_accuracy did not improve from 0.98394\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9457 - loss: 0.9433 - val_accuracy: 0.9836 - val_loss: 0.7923 - learning_rate: 9.7656e-05\n",
      "Run 2, Epoch 29/30\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8390 - loss: 1.2434  \n",
      "Epoch 29: val_accuracy did not improve from 0.87782\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8390 - loss: 1.2434 - val_accuracy: 0.8772 - val_loss: 1.2511 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8586 - loss: 1.1398  \n",
      "Epoch 29: val_accuracy did not improve from 0.91338\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8586 - loss: 1.1397 - val_accuracy: 0.9129 - val_loss: 1.0664 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9438 - loss: 0.9450  \n",
      "Epoch 29: val_accuracy did not improve from 0.98394\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9438 - loss: 0.9450 - val_accuracy: 0.9834 - val_loss: 0.7921 - learning_rate: 9.7656e-05\n",
      "Run 2, Epoch 30/30\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8422 - loss: 1.2224  \n",
      "Epoch 30: val_accuracy did not improve from 0.87782\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8422 - loss: 1.2224 - val_accuracy: 0.8772 - val_loss: 1.2511 - learning_rate: 4.8828e-05\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8544 - loss: 1.1299  \n",
      "Epoch 30: val_accuracy did not improve from 0.91338\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8544 - loss: 1.1298 - val_accuracy: 0.9129 - val_loss: 1.0663 - learning_rate: 4.8828e-05\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9473 - loss: 0.9400  \n",
      "Epoch 30: val_accuracy did not improve from 0.98394\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9473 - loss: 0.9400 - val_accuracy: 0.9833 - val_loss: 0.7920 - learning_rate: 4.8828e-05\n",
      "Completed run 2 with 30 epochs\n",
      "autosaveAdult_2_24.keras\n",
      "\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 795us/step - accuracy: 0.8843 - loss: 1.2434\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8769 - loss: 1.2542\n",
      "autosaveP24_2_20.keras\n",
      "\u001b[1m1825/1825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 751us/step - accuracy: 0.9091 - loss: 1.0796\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 1.0919\n",
      "autosaveP48_2_12.keras\n",
      "\u001b[1m1699/1699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - accuracy: 0.9803 - loss: 0.8341\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9834 - loss: 0.8293\n",
      "New best model saved: best_model_P48_run_2.keras\n",
      "Starting run 3\n",
      "Run 3, Epoch 1/30\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7670 - loss: 1.7723  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.81705, saving model to autosaveAdult_3_01.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7669 - loss: 1.7737 - val_accuracy: 0.8171 - val_loss: 2.4409 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7717 - loss: 1.8099  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.86529, saving model to autosaveP24_3_01.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7716 - loss: 1.8108 - val_accuracy: 0.8653 - val_loss: 2.0605 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8657 - loss: 1.6840  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.93379, saving model to autosaveP48_3_01.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8656 - loss: 1.6853 - val_accuracy: 0.9338 - val_loss: 2.1596 - learning_rate: 0.0500\n",
      "Run 3, Epoch 2/30\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6620 - loss: 3.1454  \n",
      "Epoch 2: val_accuracy improved from 0.81705 to 0.81874, saving model to autosaveAdult_3_02.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6619 - loss: 3.1462 - val_accuracy: 0.8187 - val_loss: 2.8963 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7236 - loss: 2.5635  \n",
      "Epoch 2: val_accuracy did not improve from 0.86529\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7236 - loss: 2.5636 - val_accuracy: 0.8641 - val_loss: 2.0814 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8134 - loss: 2.6989  \n",
      "Epoch 2: val_accuracy improved from 0.93379 to 0.94637, saving model to autosaveP48_3_02.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8134 - loss: 2.6992 - val_accuracy: 0.9464 - val_loss: 2.3335 - learning_rate: 0.0500\n",
      "Run 3, Epoch 3/30\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7010 - loss: 2.9972  \n",
      "Epoch 3: val_accuracy improved from 0.81874 to 0.85461, saving model to autosaveAdult_3_03.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7011 - loss: 2.9965 - val_accuracy: 0.8546 - val_loss: 2.0302 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7594 - loss: 2.2493  \n",
      "Epoch 3: val_accuracy improved from 0.86529 to 0.89242, saving model to autosaveP24_3_03.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7595 - loss: 2.2489 - val_accuracy: 0.8924 - val_loss: 1.4961 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8437 - loss: 2.5375  \n",
      "Epoch 3: val_accuracy improved from 0.94637 to 0.97385, saving model to autosaveP48_3_03.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8437 - loss: 2.5367 - val_accuracy: 0.9738 - val_loss: 1.4384 - learning_rate: 0.0250\n",
      "Run 3, Epoch 4/30\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7717 - loss: 2.0713  \n",
      "Epoch 4: val_accuracy improved from 0.85461 to 0.86200, saving model to autosaveAdult_3_04.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.7717 - loss: 2.0710 - val_accuracy: 0.8620 - val_loss: 1.6922 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8084 - loss: 1.6186  \n",
      "Epoch 4: val_accuracy improved from 0.89242 to 0.89565, saving model to autosaveP24_3_04.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8084 - loss: 1.6186 - val_accuracy: 0.8957 - val_loss: 1.3416 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9065 - loss: 1.5523  \n",
      "Epoch 4: val_accuracy improved from 0.97385 to 0.97401, saving model to autosaveP48_3_04.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9065 - loss: 1.5521 - val_accuracy: 0.9740 - val_loss: 1.1088 - learning_rate: 0.0250\n",
      "Run 3, Epoch 5/30\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7857 - loss: 1.7398  \n",
      "Epoch 5: val_accuracy improved from 0.86200 to 0.86305, saving model to autosaveAdult_3_05.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7857 - loss: 1.7398 - val_accuracy: 0.8631 - val_loss: 1.5622 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8180 - loss: 1.5071  \n",
      "Epoch 5: val_accuracy improved from 0.89565 to 0.89750, saving model to autosaveP24_3_05.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8180 - loss: 1.5071 - val_accuracy: 0.8975 - val_loss: 1.2925 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9150 - loss: 1.2940  \n",
      "Epoch 5: val_accuracy improved from 0.97401 to 0.97583, saving model to autosaveP48_3_05.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9150 - loss: 1.2939 - val_accuracy: 0.9758 - val_loss: 1.0106 - learning_rate: 0.0250\n",
      "Run 3, Epoch 6/30\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8012 - loss: 1.5674  \n",
      "Epoch 6: val_accuracy improved from 0.86305 to 0.86833, saving model to autosaveAdult_3_06.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8012 - loss: 1.5673 - val_accuracy: 0.8683 - val_loss: 1.4496 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8274 - loss: 1.4003  \n",
      "Epoch 6: val_accuracy improved from 0.89750 to 0.90305, saving model to autosaveP24_3_06.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8274 - loss: 1.4002 - val_accuracy: 0.9031 - val_loss: 1.2097 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9270 - loss: 1.1687  \n",
      "Epoch 6: val_accuracy improved from 0.97583 to 0.98096, saving model to autosaveP48_3_06.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9270 - loss: 1.1686 - val_accuracy: 0.9810 - val_loss: 0.9091 - learning_rate: 0.0125\n",
      "Run 3, Epoch 7/30\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8170 - loss: 1.4544  \n",
      "Epoch 7: val_accuracy improved from 0.86833 to 0.87044, saving model to autosaveAdult_3_07.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8170 - loss: 1.4545 - val_accuracy: 0.8704 - val_loss: 1.3917 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8344 - loss: 1.3166  \n",
      "Epoch 7: val_accuracy improved from 0.90305 to 0.90428, saving model to autosaveP24_3_07.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8344 - loss: 1.3165 - val_accuracy: 0.9043 - val_loss: 1.1655 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9334 - loss: 1.0700  \n",
      "Epoch 7: val_accuracy improved from 0.98096 to 0.98163, saving model to autosaveP48_3_07.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9334 - loss: 1.0699 - val_accuracy: 0.9816 - val_loss: 0.8685 - learning_rate: 0.0125\n",
      "Run 3, Epoch 8/30\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8189 - loss: 1.3985  \n",
      "Epoch 8: val_accuracy did not improve from 0.87044\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8189 - loss: 1.3985 - val_accuracy: 0.8673 - val_loss: 1.3655 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8390 - loss: 1.2624  \n",
      "Epoch 8: val_accuracy improved from 0.90428 to 0.91030, saving model to autosaveP24_3_08.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8390 - loss: 1.2624 - val_accuracy: 0.9103 - val_loss: 1.1476 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9354 - loss: 1.0299  \n",
      "Epoch 8: val_accuracy improved from 0.98163 to 0.98179, saving model to autosaveP48_3_08.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9354 - loss: 1.0299 - val_accuracy: 0.9818 - val_loss: 0.8392 - learning_rate: 0.0125\n",
      "Run 3, Epoch 9/30\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8262 - loss: 1.3585  \n",
      "Epoch 9: val_accuracy improved from 0.87044 to 0.87677, saving model to autosaveAdult_3_09.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8262 - loss: 1.3584 - val_accuracy: 0.8768 - val_loss: 1.3309 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8451 - loss: 1.2281  \n",
      "Epoch 9: val_accuracy did not improve from 0.91030\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8451 - loss: 1.2281 - val_accuracy: 0.9083 - val_loss: 1.1210 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9407 - loss: 0.9941  \n",
      "Epoch 9: val_accuracy did not improve from 0.98179\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9407 - loss: 0.9941 - val_accuracy: 0.9815 - val_loss: 0.8228 - learning_rate: 0.0063\n",
      "Run 3, Epoch 10/30\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8276 - loss: 1.3180  \n",
      "Epoch 10: val_accuracy did not improve from 0.87677\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8276 - loss: 1.3181 - val_accuracy: 0.8740 - val_loss: 1.3084 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8493 - loss: 1.1977  \n",
      "Epoch 10: val_accuracy improved from 0.91030 to 0.91091, saving model to autosaveP24_3_10.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8493 - loss: 1.1977 - val_accuracy: 0.9109 - val_loss: 1.1052 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9424 - loss: 0.9757  \n",
      "Epoch 10: val_accuracy did not improve from 0.98179\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9424 - loss: 0.9757 - val_accuracy: 0.9818 - val_loss: 0.8113 - learning_rate: 0.0063\n",
      "Run 3, Epoch 11/30\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8318 - loss: 1.2934  \n",
      "Epoch 11: val_accuracy did not improve from 0.87677\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8318 - loss: 1.2935 - val_accuracy: 0.8749 - val_loss: 1.2971 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8487 - loss: 1.1926  \n",
      "Epoch 11: val_accuracy did not improve from 0.91091\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8487 - loss: 1.1926 - val_accuracy: 0.9081 - val_loss: 1.0992 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9448 - loss: 0.9508  \n",
      "Epoch 11: val_accuracy did not improve from 0.98179\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9448 - loss: 0.9508 - val_accuracy: 0.9811 - val_loss: 0.7961 - learning_rate: 0.0063\n",
      "Run 3, Epoch 12/30\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8338 - loss: 1.2707  \n",
      "Epoch 12: val_accuracy did not improve from 0.87677\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8338 - loss: 1.2708 - val_accuracy: 0.8751 - val_loss: 1.2836 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8518 - loss: 1.1619  \n",
      "Epoch 12: val_accuracy did not improve from 0.91091\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.8517 - loss: 1.1619 - val_accuracy: 0.9058 - val_loss: 1.0901 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9431 - loss: 0.9399  \n",
      "Epoch 12: val_accuracy improved from 0.98179 to 0.98245, saving model to autosaveP48_3_12.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9431 - loss: 0.9399 - val_accuracy: 0.9825 - val_loss: 0.7859 - learning_rate: 0.0031\n",
      "Run 3, Epoch 13/30\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8347 - loss: 1.2577  \n",
      "Epoch 13: val_accuracy improved from 0.87677 to 0.87782, saving model to autosaveAdult_3_13.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8347 - loss: 1.2577 - val_accuracy: 0.8778 - val_loss: 1.2831 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8516 - loss: 1.1679  \n",
      "Epoch 13: val_accuracy did not improve from 0.91091\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8516 - loss: 1.1678 - val_accuracy: 0.9108 - val_loss: 1.0836 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9442 - loss: 0.9333  \n",
      "Epoch 13: val_accuracy improved from 0.98245 to 0.98262, saving model to autosaveP48_3_13.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9442 - loss: 0.9333 - val_accuracy: 0.9826 - val_loss: 0.7808 - learning_rate: 0.0031\n",
      "Run 3, Epoch 14/30\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8341 - loss: 1.2628  \n",
      "Epoch 14: val_accuracy did not improve from 0.87782\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8341 - loss: 1.2628 - val_accuracy: 0.8753 - val_loss: 1.2678 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8545 - loss: 1.1561  \n",
      "Epoch 14: val_accuracy improved from 0.91091 to 0.91122, saving model to autosaveP24_3_14.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8545 - loss: 1.1560 - val_accuracy: 0.9112 - val_loss: 1.0816 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9457 - loss: 0.9284  \n",
      "Epoch 14: val_accuracy did not improve from 0.98262\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9457 - loss: 0.9284 - val_accuracy: 0.9826 - val_loss: 0.7782 - learning_rate: 0.0031\n",
      "Run 3, Epoch 15/30\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8322 - loss: 1.2620  \n",
      "Epoch 15: val_accuracy did not improve from 0.87782\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8322 - loss: 1.2620 - val_accuracy: 0.8761 - val_loss: 1.2660 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8555 - loss: 1.1490  \n",
      "Epoch 15: val_accuracy improved from 0.91122 to 0.91215, saving model to autosaveP24_3_15.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8555 - loss: 1.1490 - val_accuracy: 0.9121 - val_loss: 1.0746 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9444 - loss: 0.9215  \n",
      "Epoch 15: val_accuracy improved from 0.98262 to 0.98295, saving model to autosaveP48_3_15.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9444 - loss: 0.9215 - val_accuracy: 0.9829 - val_loss: 0.7736 - learning_rate: 0.0016\n",
      "Run 3, Epoch 16/30\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8379 - loss: 1.2292  \n",
      "Epoch 16: val_accuracy did not improve from 0.87782\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8379 - loss: 1.2293 - val_accuracy: 0.8770 - val_loss: 1.2599 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8574 - loss: 1.1340  \n",
      "Epoch 16: val_accuracy did not improve from 0.91215\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8574 - loss: 1.1340 - val_accuracy: 0.9112 - val_loss: 1.0727 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9462 - loss: 0.9110  \n",
      "Epoch 16: val_accuracy did not improve from 0.98295\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9462 - loss: 0.9111 - val_accuracy: 0.9826 - val_loss: 0.7714 - learning_rate: 0.0016\n",
      "Run 3, Epoch 17/30\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8389 - loss: 1.2388  \n",
      "Epoch 17: val_accuracy did not improve from 0.87782\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8389 - loss: 1.2388 - val_accuracy: 0.8776 - val_loss: 1.2557 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8550 - loss: 1.1246  \n",
      "Epoch 17: val_accuracy did not improve from 0.91215\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8550 - loss: 1.1246 - val_accuracy: 0.9114 - val_loss: 1.0696 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9449 - loss: 0.9223  \n",
      "Epoch 17: val_accuracy did not improve from 0.98295\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9449 - loss: 0.9222 - val_accuracy: 0.9821 - val_loss: 0.7689 - learning_rate: 0.0016\n",
      "Run 3, Epoch 18/30\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8366 - loss: 1.2341  \n",
      "Epoch 18: val_accuracy did not improve from 0.87782\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8366 - loss: 1.2341 - val_accuracy: 0.8776 - val_loss: 1.2545 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8520 - loss: 1.1355  \n",
      "Epoch 18: val_accuracy did not improve from 0.91215\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8520 - loss: 1.1355 - val_accuracy: 0.9103 - val_loss: 1.0675 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9499 - loss: 0.9056  \n",
      "Epoch 18: val_accuracy did not improve from 0.98295\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9499 - loss: 0.9056 - val_accuracy: 0.9821 - val_loss: 0.7662 - learning_rate: 7.8125e-04\n",
      "Run 3, Epoch 19/30\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8373 - loss: 1.2282  \n",
      "Epoch 19: val_accuracy did not improve from 0.87782\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8373 - loss: 1.2282 - val_accuracy: 0.8778 - val_loss: 1.2532 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8566 - loss: 1.1155  \n",
      "Epoch 19: val_accuracy did not improve from 0.91215\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8566 - loss: 1.1156 - val_accuracy: 0.9111 - val_loss: 1.0675 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9468 - loss: 0.9133  \n",
      "Epoch 19: val_accuracy did not improve from 0.98295\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9468 - loss: 0.9133 - val_accuracy: 0.9825 - val_loss: 0.7648 - learning_rate: 7.8125e-04\n",
      "Run 3, Epoch 20/30\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8414 - loss: 1.2255  \n",
      "Epoch 20: val_accuracy did not improve from 0.87782\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8413 - loss: 1.2255 - val_accuracy: 0.8778 - val_loss: 1.2518 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8584 - loss: 1.1180  \n",
      "Epoch 20: val_accuracy did not improve from 0.91215\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8584 - loss: 1.1180 - val_accuracy: 0.9114 - val_loss: 1.0658 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9483 - loss: 0.9024  \n",
      "Epoch 20: val_accuracy did not improve from 0.98295\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9483 - loss: 0.9024 - val_accuracy: 0.9826 - val_loss: 0.7634 - learning_rate: 7.8125e-04\n",
      "Run 3, Epoch 21/30\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8374 - loss: 1.2256  \n",
      "Epoch 21: val_accuracy improved from 0.87782 to 0.87867, saving model to autosaveAdult_3_21.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8374 - loss: 1.2256 - val_accuracy: 0.8787 - val_loss: 1.2497 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8536 - loss: 1.1296  \n",
      "Epoch 21: val_accuracy did not improve from 0.91215\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8536 - loss: 1.1296 - val_accuracy: 0.9118 - val_loss: 1.0646 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9466 - loss: 0.9102  \n",
      "Epoch 21: val_accuracy did not improve from 0.98295\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9466 - loss: 0.9102 - val_accuracy: 0.9826 - val_loss: 0.7630 - learning_rate: 3.9063e-04\n",
      "Run 3, Epoch 22/30\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8382 - loss: 1.2347  \n",
      "Epoch 22: val_accuracy improved from 0.87867 to 0.87888, saving model to autosaveAdult_3_22.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8382 - loss: 1.2347 - val_accuracy: 0.8789 - val_loss: 1.2494 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8528 - loss: 1.1309  \n",
      "Epoch 22: val_accuracy improved from 0.91215 to 0.91276, saving model to autosaveP24_3_22.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8528 - loss: 1.1309 - val_accuracy: 0.9128 - val_loss: 1.0640 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9472 - loss: 0.9039  \n",
      "Epoch 22: val_accuracy did not improve from 0.98295\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9472 - loss: 0.9039 - val_accuracy: 0.9826 - val_loss: 0.7624 - learning_rate: 3.9063e-04\n",
      "Run 3, Epoch 23/30\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8414 - loss: 1.2175  \n",
      "Epoch 23: val_accuracy did not improve from 0.87888\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8414 - loss: 1.2176 - val_accuracy: 0.8782 - val_loss: 1.2479 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8591 - loss: 1.1175  \n",
      "Epoch 23: val_accuracy did not improve from 0.91276\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8591 - loss: 1.1175 - val_accuracy: 0.9125 - val_loss: 1.0627 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9486 - loss: 0.8983  \n",
      "Epoch 23: val_accuracy did not improve from 0.98295\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9486 - loss: 0.8983 - val_accuracy: 0.9826 - val_loss: 0.7615 - learning_rate: 3.9063e-04\n",
      "Run 3, Epoch 24/30\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8370 - loss: 1.2300  \n",
      "Epoch 24: val_accuracy did not improve from 0.87888\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8370 - loss: 1.2300 - val_accuracy: 0.8785 - val_loss: 1.2478 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8591 - loss: 1.1145  \n",
      "Epoch 24: val_accuracy did not improve from 0.91276\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8591 - loss: 1.1145 - val_accuracy: 0.9123 - val_loss: 1.0624 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9467 - loss: 0.9101  \n",
      "Epoch 24: val_accuracy did not improve from 0.98295\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9467 - loss: 0.9101 - val_accuracy: 0.9826 - val_loss: 0.7611 - learning_rate: 1.9531e-04\n",
      "Run 3, Epoch 25/30\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8393 - loss: 1.2273  \n",
      "Epoch 25: val_accuracy did not improve from 0.87888\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8392 - loss: 1.2273 - val_accuracy: 0.8782 - val_loss: 1.2480 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8592 - loss: 1.1096  \n",
      "Epoch 25: val_accuracy did not improve from 0.91276\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8592 - loss: 1.1096 - val_accuracy: 0.9120 - val_loss: 1.0622 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9484 - loss: 0.8953  \n",
      "Epoch 25: val_accuracy did not improve from 0.98295\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9484 - loss: 0.8953 - val_accuracy: 0.9826 - val_loss: 0.7606 - learning_rate: 1.9531e-04\n",
      "Run 3, Epoch 26/30\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8416 - loss: 1.2192  \n",
      "Epoch 26: val_accuracy did not improve from 0.87888\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8416 - loss: 1.2192 - val_accuracy: 0.8787 - val_loss: 1.2468 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8568 - loss: 1.1228  \n",
      "Epoch 26: val_accuracy did not improve from 0.91276\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8568 - loss: 1.1228 - val_accuracy: 0.9121 - val_loss: 1.0620 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9477 - loss: 0.9055  \n",
      "Epoch 26: val_accuracy did not improve from 0.98295\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9477 - loss: 0.9055 - val_accuracy: 0.9826 - val_loss: 0.7606 - learning_rate: 1.9531e-04\n",
      "Run 3, Epoch 27/30\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8353 - loss: 1.2333  \n",
      "Epoch 27: val_accuracy did not improve from 0.87888\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8354 - loss: 1.2333 - val_accuracy: 0.8787 - val_loss: 1.2470 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8574 - loss: 1.1230  \n",
      "Epoch 27: val_accuracy did not improve from 0.91276\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8574 - loss: 1.1230 - val_accuracy: 0.9118 - val_loss: 1.0619 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9488 - loss: 0.9031  \n",
      "Epoch 27: val_accuracy did not improve from 0.98295\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9488 - loss: 0.9031 - val_accuracy: 0.9826 - val_loss: 0.7603 - learning_rate: 9.7656e-05\n",
      "Run 3, Epoch 28/30\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8375 - loss: 1.2267  \n",
      "Epoch 28: val_accuracy did not improve from 0.87888\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8375 - loss: 1.2267 - val_accuracy: 0.8785 - val_loss: 1.2469 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8580 - loss: 1.1232  \n",
      "Epoch 28: val_accuracy did not improve from 0.91276\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8579 - loss: 1.1232 - val_accuracy: 0.9123 - val_loss: 1.0618 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9459 - loss: 0.9099  \n",
      "Epoch 28: val_accuracy did not improve from 0.98295\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9459 - loss: 0.9098 - val_accuracy: 0.9826 - val_loss: 0.7601 - learning_rate: 9.7656e-05\n",
      "Run 3, Epoch 29/30\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8372 - loss: 1.2237  \n",
      "Epoch 29: val_accuracy did not improve from 0.87888\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8372 - loss: 1.2237 - val_accuracy: 0.8787 - val_loss: 1.2467 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8586 - loss: 1.1254  \n",
      "Epoch 29: val_accuracy did not improve from 0.91276\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8586 - loss: 1.1254 - val_accuracy: 0.9120 - val_loss: 1.0618 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9465 - loss: 0.8981  \n",
      "Epoch 29: val_accuracy did not improve from 0.98295\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9465 - loss: 0.8981 - val_accuracy: 0.9828 - val_loss: 0.7597 - learning_rate: 9.7656e-05\n",
      "Run 3, Epoch 30/30\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8397 - loss: 1.2175  \n",
      "Epoch 30: val_accuracy did not improve from 0.87888\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8397 - loss: 1.2176 - val_accuracy: 0.8787 - val_loss: 1.2466 - learning_rate: 4.8828e-05\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8572 - loss: 1.1272  \n",
      "Epoch 30: val_accuracy did not improve from 0.91276\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8572 - loss: 1.1272 - val_accuracy: 0.9120 - val_loss: 1.0616 - learning_rate: 4.8828e-05\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9486 - loss: 0.9005  \n",
      "Epoch 30: val_accuracy did not improve from 0.98295\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9486 - loss: 0.9005 - val_accuracy: 0.9828 - val_loss: 0.7596 - learning_rate: 4.8828e-05\n",
      "Completed run 3 with 30 epochs\n",
      "autosaveAdult_3_22.keras\n",
      "\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 798us/step - accuracy: 0.8833 - loss: 1.2397\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8788 - loss: 1.2526\n",
      "autosaveP24_3_22.keras\n",
      "\u001b[1m1825/1825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 749us/step - accuracy: 0.9096 - loss: 1.0735\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9112 - loss: 1.0857\n",
      "autosaveP48_3_15.keras\n",
      "\u001b[1m1699/1699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - accuracy: 0.9811 - loss: 0.7833\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9822 - loss: 0.7822\n",
      "New best model saved: best_model_P48_run_3.keras\n",
      "Starting run 4\n",
      "Run 4, Epoch 1/30\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7586 - loss: 1.7850  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.82908, saving model to autosaveAdult_4_01.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7585 - loss: 1.7864 - val_accuracy: 0.8291 - val_loss: 2.3057 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7752 - loss: 1.7249  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.86606, saving model to autosaveP24_4_01.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7751 - loss: 1.7256 - val_accuracy: 0.8661 - val_loss: 1.9966 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8701 - loss: 1.6976  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.93064, saving model to autosaveP48_4_01.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8700 - loss: 1.6993 - val_accuracy: 0.9306 - val_loss: 2.8832 - learning_rate: 0.0500\n",
      "Run 4, Epoch 2/30\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6825 - loss: 2.8241  \n",
      "Epoch 2: val_accuracy did not improve from 0.82908\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6824 - loss: 2.8247 - val_accuracy: 0.8232 - val_loss: 2.6969 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7176 - loss: 2.6002  \n",
      "Epoch 2: val_accuracy did not improve from 0.86606\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7176 - loss: 2.6004 - val_accuracy: 0.8554 - val_loss: 2.1045 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7606 - loss: 3.9407  \n",
      "Epoch 2: val_accuracy improved from 0.93064 to 0.93461, saving model to autosaveP48_4_02.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7605 - loss: 3.9410 - val_accuracy: 0.9346 - val_loss: 3.1113 - learning_rate: 0.0500\n",
      "Run 4, Epoch 3/30\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6999 - loss: 2.8942  \n",
      "Epoch 3: val_accuracy improved from 0.82908 to 0.86769, saving model to autosaveAdult_4_03.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7000 - loss: 2.8934 - val_accuracy: 0.8677 - val_loss: 1.9546 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7672 - loss: 2.2063  \n",
      "Epoch 3: val_accuracy improved from 0.86606 to 0.89396, saving model to autosaveP24_4_03.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7673 - loss: 2.2059 - val_accuracy: 0.8940 - val_loss: 1.5001 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8292 - loss: 3.1584  \n",
      "Epoch 3: val_accuracy improved from 0.93461 to 0.96987, saving model to autosaveP48_4_03.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8293 - loss: 3.1574 - val_accuracy: 0.9699 - val_loss: 1.7110 - learning_rate: 0.0250\n",
      "Run 4, Epoch 4/30\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7736 - loss: 2.0006  \n",
      "Epoch 4: val_accuracy did not improve from 0.86769\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.7736 - loss: 2.0004 - val_accuracy: 0.8508 - val_loss: 1.6609 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8053 - loss: 1.6464  \n",
      "Epoch 4: val_accuracy improved from 0.89396 to 0.89704, saving model to autosaveP24_4_04.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8053 - loss: 1.6464 - val_accuracy: 0.8970 - val_loss: 1.3300 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9029 - loss: 1.7836  \n",
      "Epoch 4: val_accuracy improved from 0.96987 to 0.97153, saving model to autosaveP48_4_04.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9029 - loss: 1.7834 - val_accuracy: 0.9715 - val_loss: 1.1954 - learning_rate: 0.0250\n",
      "Run 4, Epoch 5/30\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7903 - loss: 1.7186  \n",
      "Epoch 5: val_accuracy improved from 0.86769 to 0.87276, saving model to autosaveAdult_4_05.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7903 - loss: 1.7186 - val_accuracy: 0.8728 - val_loss: 1.5212 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8181 - loss: 1.4753  \n",
      "Epoch 5: val_accuracy did not improve from 0.89704\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8181 - loss: 1.4753 - val_accuracy: 0.8886 - val_loss: 1.2820 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9151 - loss: 1.3660  \n",
      "Epoch 5: val_accuracy improved from 0.97153 to 0.97798, saving model to autosaveP48_4_05.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9151 - loss: 1.3660 - val_accuracy: 0.9780 - val_loss: 1.0282 - learning_rate: 0.0250\n",
      "Run 4, Epoch 6/30\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8072 - loss: 1.5461  \n",
      "Epoch 6: val_accuracy improved from 0.87276 to 0.87318, saving model to autosaveAdult_4_06.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8072 - loss: 1.5461 - val_accuracy: 0.8732 - val_loss: 1.4249 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8277 - loss: 1.3839  \n",
      "Epoch 6: val_accuracy improved from 0.89704 to 0.90413, saving model to autosaveP24_4_06.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8277 - loss: 1.3839 - val_accuracy: 0.9041 - val_loss: 1.1987 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9251 - loss: 1.1969  \n",
      "Epoch 6: val_accuracy did not improve from 0.97798\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9251 - loss: 1.1969 - val_accuracy: 0.9727 - val_loss: 0.9379 - learning_rate: 0.0125\n",
      "Run 4, Epoch 7/30\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8220 - loss: 1.4305  \n",
      "Epoch 7: val_accuracy did not improve from 0.87318\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8220 - loss: 1.4305 - val_accuracy: 0.8614 - val_loss: 1.3975 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8408 - loss: 1.2670  \n",
      "Epoch 7: val_accuracy improved from 0.90413 to 0.90660, saving model to autosaveP24_4_07.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8408 - loss: 1.2670 - val_accuracy: 0.9066 - val_loss: 1.1511 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9343 - loss: 1.0916  \n",
      "Epoch 7: val_accuracy improved from 0.97798 to 0.98096, saving model to autosaveP48_4_07.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9343 - loss: 1.0916 - val_accuracy: 0.9810 - val_loss: 0.8814 - learning_rate: 0.0125\n",
      "Run 4, Epoch 8/30\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8169 - loss: 1.3994  \n",
      "Epoch 8: val_accuracy improved from 0.87318 to 0.87466, saving model to autosaveAdult_4_08.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8169 - loss: 1.3994 - val_accuracy: 0.8747 - val_loss: 1.3390 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8404 - loss: 1.2513  \n",
      "Epoch 8: val_accuracy did not improve from 0.90660\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8404 - loss: 1.2513 - val_accuracy: 0.9031 - val_loss: 1.1428 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9348 - loss: 1.0491  \n",
      "Epoch 8: val_accuracy did not improve from 0.98096\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9348 - loss: 1.0491 - val_accuracy: 0.9805 - val_loss: 0.8502 - learning_rate: 0.0125\n",
      "Run 4, Epoch 9/30\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8252 - loss: 1.3588  \n",
      "Epoch 9: val_accuracy improved from 0.87466 to 0.87930, saving model to autosaveAdult_4_09.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8252 - loss: 1.3588 - val_accuracy: 0.8793 - val_loss: 1.3138 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8450 - loss: 1.2347  \n",
      "Epoch 9: val_accuracy improved from 0.90660 to 0.90968, saving model to autosaveP24_4_09.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8450 - loss: 1.2346 - val_accuracy: 0.9097 - val_loss: 1.1177 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9396 - loss: 1.0012  \n",
      "Epoch 9: val_accuracy improved from 0.98096 to 0.98312, saving model to autosaveP48_4_09.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9396 - loss: 1.0012 - val_accuracy: 0.9831 - val_loss: 0.8256 - learning_rate: 0.0063\n",
      "Run 4, Epoch 10/30\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8283 - loss: 1.3129  \n",
      "Epoch 10: val_accuracy did not improve from 0.87930\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8283 - loss: 1.3129 - val_accuracy: 0.8763 - val_loss: 1.3038 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8473 - loss: 1.1996  \n",
      "Epoch 10: val_accuracy did not improve from 0.90968\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8473 - loss: 1.1996 - val_accuracy: 0.9054 - val_loss: 1.1052 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9411 - loss: 0.9808  \n",
      "Epoch 10: val_accuracy improved from 0.98312 to 0.98328, saving model to autosaveP48_4_10.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9411 - loss: 0.9808 - val_accuracy: 0.9833 - val_loss: 0.8134 - learning_rate: 0.0063\n",
      "Run 4, Epoch 11/30\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8299 - loss: 1.2946  \n",
      "Epoch 11: val_accuracy did not improve from 0.87930\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8299 - loss: 1.2946 - val_accuracy: 0.8755 - val_loss: 1.2826 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8499 - loss: 1.1762  \n",
      "Epoch 11: val_accuracy did not improve from 0.90968\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8499 - loss: 1.1762 - val_accuracy: 0.9072 - val_loss: 1.0941 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9451 - loss: 0.9588  \n",
      "Epoch 11: val_accuracy improved from 0.98328 to 0.98394, saving model to autosaveP48_4_11.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9451 - loss: 0.9588 - val_accuracy: 0.9839 - val_loss: 0.7956 - learning_rate: 0.0063\n",
      "Run 4, Epoch 12/30\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8346 - loss: 1.2774  \n",
      "Epoch 12: val_accuracy improved from 0.87930 to 0.88141, saving model to autosaveAdult_4_12.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8346 - loss: 1.2774 - val_accuracy: 0.8814 - val_loss: 1.2672 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8516 - loss: 1.1613  \n",
      "Epoch 12: val_accuracy improved from 0.90968 to 0.91014, saving model to autosaveP24_4_12.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8516 - loss: 1.1613 - val_accuracy: 0.9101 - val_loss: 1.0855 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9440 - loss: 0.9484  \n",
      "Epoch 12: val_accuracy did not improve from 0.98394\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9440 - loss: 0.9484 - val_accuracy: 0.9821 - val_loss: 0.7920 - learning_rate: 0.0031\n",
      "Run 4, Epoch 13/30\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8339 - loss: 1.2563  \n",
      "Epoch 13: val_accuracy did not improve from 0.88141\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8339 - loss: 1.2563 - val_accuracy: 0.8780 - val_loss: 1.2636 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8554 - loss: 1.1529  \n",
      "Epoch 13: val_accuracy did not improve from 0.91014\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8554 - loss: 1.1529 - val_accuracy: 0.9091 - val_loss: 1.0797 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9448 - loss: 0.9345  \n",
      "Epoch 13: val_accuracy did not improve from 0.98394\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9448 - loss: 0.9345 - val_accuracy: 0.9811 - val_loss: 0.7851 - learning_rate: 0.0031\n",
      "Run 4, Epoch 14/30\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8332 - loss: 1.2613  \n",
      "Epoch 14: val_accuracy did not improve from 0.88141\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8332 - loss: 1.2613 - val_accuracy: 0.8755 - val_loss: 1.2627 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8543 - loss: 1.1510  \n",
      "Epoch 14: val_accuracy improved from 0.91014 to 0.91107, saving model to autosaveP24_4_14.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8543 - loss: 1.1510 - val_accuracy: 0.9111 - val_loss: 1.0736 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9472 - loss: 0.9260  \n",
      "Epoch 14: val_accuracy did not improve from 0.98394\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9472 - loss: 0.9260 - val_accuracy: 0.9831 - val_loss: 0.7786 - learning_rate: 0.0031\n",
      "Run 4, Epoch 15/30\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8339 - loss: 1.2378  \n",
      "Epoch 15: val_accuracy did not improve from 0.88141\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8339 - loss: 1.2378 - val_accuracy: 0.8789 - val_loss: 1.2528 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8547 - loss: 1.1400  \n",
      "Epoch 15: val_accuracy did not improve from 0.91107\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8547 - loss: 1.1400 - val_accuracy: 0.9097 - val_loss: 1.0693 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9459 - loss: 0.9271  \n",
      "Epoch 15: val_accuracy did not improve from 0.98394\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9459 - loss: 0.9271 - val_accuracy: 0.9833 - val_loss: 0.7743 - learning_rate: 0.0016\n",
      "Run 4, Epoch 16/30\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8416 - loss: 1.2272  \n",
      "Epoch 16: val_accuracy did not improve from 0.88141\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8416 - loss: 1.2272 - val_accuracy: 0.8808 - val_loss: 1.2474 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8562 - loss: 1.1266  \n",
      "Epoch 16: val_accuracy did not improve from 0.91107\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8562 - loss: 1.1266 - val_accuracy: 0.9095 - val_loss: 1.0670 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9462 - loss: 0.9215  \n",
      "Epoch 16: val_accuracy did not improve from 0.98394\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9462 - loss: 0.9215 - val_accuracy: 0.9829 - val_loss: 0.7719 - learning_rate: 0.0016\n",
      "Run 4, Epoch 17/30\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8384 - loss: 1.2359  \n",
      "Epoch 17: val_accuracy did not improve from 0.88141\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8384 - loss: 1.2359 - val_accuracy: 0.8812 - val_loss: 1.2416 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8565 - loss: 1.1176  \n",
      "Epoch 17: val_accuracy did not improve from 0.91107\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8565 - loss: 1.1176 - val_accuracy: 0.9095 - val_loss: 1.0645 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9464 - loss: 0.9119  \n",
      "Epoch 17: val_accuracy did not improve from 0.98394\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9464 - loss: 0.9119 - val_accuracy: 0.9826 - val_loss: 0.7700 - learning_rate: 0.0016\n",
      "Run 4, Epoch 18/30\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8381 - loss: 1.2276  \n",
      "Epoch 18: val_accuracy did not improve from 0.88141\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8381 - loss: 1.2276 - val_accuracy: 0.8814 - val_loss: 1.2429 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8576 - loss: 1.1239  \n",
      "Epoch 18: val_accuracy did not improve from 0.91107\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8576 - loss: 1.1239 - val_accuracy: 0.9106 - val_loss: 1.0633 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9462 - loss: 0.9141  \n",
      "Epoch 18: val_accuracy did not improve from 0.98394\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9462 - loss: 0.9141 - val_accuracy: 0.9839 - val_loss: 0.7676 - learning_rate: 7.8125e-04\n",
      "Run 4, Epoch 19/30\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8364 - loss: 1.2219  \n",
      "Epoch 19: val_accuracy did not improve from 0.88141\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8364 - loss: 1.2219 - val_accuracy: 0.8801 - val_loss: 1.2401 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8578 - loss: 1.1386  \n",
      "Epoch 19: val_accuracy did not improve from 0.91107\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8578 - loss: 1.1385 - val_accuracy: 0.9108 - val_loss: 1.0614 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9479 - loss: 0.9132  \n",
      "Epoch 19: val_accuracy did not improve from 0.98394\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9479 - loss: 0.9132 - val_accuracy: 0.9831 - val_loss: 0.7673 - learning_rate: 7.8125e-04\n",
      "Run 4, Epoch 20/30\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8374 - loss: 1.2242  \n",
      "Epoch 20: val_accuracy did not improve from 0.88141\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8374 - loss: 1.2242 - val_accuracy: 0.8810 - val_loss: 1.2387 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8595 - loss: 1.1191  \n",
      "Epoch 20: val_accuracy did not improve from 0.91107\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8595 - loss: 1.1191 - val_accuracy: 0.9097 - val_loss: 1.0605 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9475 - loss: 0.9054  \n",
      "Epoch 20: val_accuracy did not improve from 0.98394\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9475 - loss: 0.9055 - val_accuracy: 0.9831 - val_loss: 0.7654 - learning_rate: 7.8125e-04\n",
      "Run 4, Epoch 21/30\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8407 - loss: 1.2195  \n",
      "Epoch 21: val_accuracy improved from 0.88141 to 0.88183, saving model to autosaveAdult_4_21.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8407 - loss: 1.2195 - val_accuracy: 0.8818 - val_loss: 1.2377 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8543 - loss: 1.1138  \n",
      "Epoch 21: val_accuracy did not improve from 0.91107\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8544 - loss: 1.1138 - val_accuracy: 0.9111 - val_loss: 1.0595 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9480 - loss: 0.9132  \n",
      "Epoch 21: val_accuracy did not improve from 0.98394\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9480 - loss: 0.9132 - val_accuracy: 0.9829 - val_loss: 0.7645 - learning_rate: 3.9063e-04\n",
      "Run 4, Epoch 22/30\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8417 - loss: 1.2199  \n",
      "Epoch 22: val_accuracy did not improve from 0.88183\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8417 - loss: 1.2199 - val_accuracy: 0.8814 - val_loss: 1.2379 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8565 - loss: 1.1225  \n",
      "Epoch 22: val_accuracy did not improve from 0.91107\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8565 - loss: 1.1225 - val_accuracy: 0.9106 - val_loss: 1.0583 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9474 - loss: 0.9039  \n",
      "Epoch 22: val_accuracy did not improve from 0.98394\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9474 - loss: 0.9039 - val_accuracy: 0.9828 - val_loss: 0.7640 - learning_rate: 3.9063e-04\n",
      "Run 4, Epoch 23/30\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8403 - loss: 1.2140  \n",
      "Epoch 23: val_accuracy improved from 0.88183 to 0.88225, saving model to autosaveAdult_4_23.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8403 - loss: 1.2140 - val_accuracy: 0.8823 - val_loss: 1.2364 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8582 - loss: 1.1094  \n",
      "Epoch 23: val_accuracy did not improve from 0.91107\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8582 - loss: 1.1094 - val_accuracy: 0.9109 - val_loss: 1.0579 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9486 - loss: 0.9044  \n",
      "Epoch 23: val_accuracy did not improve from 0.98394\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9486 - loss: 0.9044 - val_accuracy: 0.9829 - val_loss: 0.7633 - learning_rate: 3.9063e-04\n",
      "Run 4, Epoch 24/30\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8404 - loss: 1.2124  \n",
      "Epoch 24: val_accuracy did not improve from 0.88225\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8404 - loss: 1.2124 - val_accuracy: 0.8823 - val_loss: 1.2356 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8582 - loss: 1.1155  \n",
      "Epoch 24: val_accuracy did not improve from 0.91107\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8582 - loss: 1.1155 - val_accuracy: 0.9111 - val_loss: 1.0577 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9467 - loss: 0.9081  \n",
      "Epoch 24: val_accuracy did not improve from 0.98394\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9467 - loss: 0.9081 - val_accuracy: 0.9828 - val_loss: 0.7631 - learning_rate: 1.9531e-04\n",
      "Run 4, Epoch 25/30\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8401 - loss: 1.2052  \n",
      "Epoch 25: val_accuracy did not improve from 0.88225\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8401 - loss: 1.2052 - val_accuracy: 0.8820 - val_loss: 1.2357 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8572 - loss: 1.1120  \n",
      "Epoch 25: val_accuracy improved from 0.91107 to 0.91153, saving model to autosaveP24_4_25.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8572 - loss: 1.1120 - val_accuracy: 0.9115 - val_loss: 1.0576 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9475 - loss: 0.9045  \n",
      "Epoch 25: val_accuracy did not improve from 0.98394\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9475 - loss: 0.9045 - val_accuracy: 0.9829 - val_loss: 0.7630 - learning_rate: 1.9531e-04\n",
      "Run 4, Epoch 26/30\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8399 - loss: 1.2194  \n",
      "Epoch 26: val_accuracy did not improve from 0.88225\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8399 - loss: 1.2194 - val_accuracy: 0.8820 - val_loss: 1.2357 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8574 - loss: 1.1008  \n",
      "Epoch 26: val_accuracy did not improve from 0.91153\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8574 - loss: 1.1009 - val_accuracy: 0.9108 - val_loss: 1.0572 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9475 - loss: 0.9074  \n",
      "Epoch 26: val_accuracy did not improve from 0.98394\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9475 - loss: 0.9074 - val_accuracy: 0.9828 - val_loss: 0.7626 - learning_rate: 1.9531e-04\n",
      "Run 4, Epoch 27/30\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8391 - loss: 1.2149  \n",
      "Epoch 27: val_accuracy did not improve from 0.88225\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8391 - loss: 1.2149 - val_accuracy: 0.8814 - val_loss: 1.2357 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8546 - loss: 1.1164  \n",
      "Epoch 27: val_accuracy did not improve from 0.91153\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8546 - loss: 1.1164 - val_accuracy: 0.9112 - val_loss: 1.0571 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9474 - loss: 0.8997  \n",
      "Epoch 27: val_accuracy did not improve from 0.98394\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9474 - loss: 0.8996 - val_accuracy: 0.9828 - val_loss: 0.7623 - learning_rate: 9.7656e-05\n",
      "Run 4, Epoch 28/30\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8375 - loss: 1.2215  \n",
      "Epoch 28: val_accuracy did not improve from 0.88225\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8375 - loss: 1.2215 - val_accuracy: 0.8816 - val_loss: 1.2352 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8567 - loss: 1.1235  \n",
      "Epoch 28: val_accuracy did not improve from 0.91153\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8567 - loss: 1.1235 - val_accuracy: 0.9112 - val_loss: 1.0569 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9492 - loss: 0.8953  \n",
      "Epoch 28: val_accuracy did not improve from 0.98394\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9492 - loss: 0.8953 - val_accuracy: 0.9829 - val_loss: 0.7620 - learning_rate: 9.7656e-05\n",
      "Run 4, Epoch 29/30\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8399 - loss: 1.2184  \n",
      "Epoch 29: val_accuracy did not improve from 0.88225\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8399 - loss: 1.2184 - val_accuracy: 0.8820 - val_loss: 1.2351 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8580 - loss: 1.1063  \n",
      "Epoch 29: val_accuracy did not improve from 0.91153\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8580 - loss: 1.1063 - val_accuracy: 0.9114 - val_loss: 1.0568 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9486 - loss: 0.9017  \n",
      "Epoch 29: val_accuracy did not improve from 0.98394\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9486 - loss: 0.9017 - val_accuracy: 0.9828 - val_loss: 0.7619 - learning_rate: 9.7656e-05\n",
      "Run 4, Epoch 30/30\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8364 - loss: 1.2089  \n",
      "Epoch 30: val_accuracy did not improve from 0.88225\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8364 - loss: 1.2089 - val_accuracy: 0.8823 - val_loss: 1.2347 - learning_rate: 4.8828e-05\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8600 - loss: 1.1003  \n",
      "Epoch 30: val_accuracy improved from 0.91153 to 0.91168, saving model to autosaveP24_4_30.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8600 - loss: 1.1003 - val_accuracy: 0.9117 - val_loss: 1.0567 - learning_rate: 4.8828e-05\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9478 - loss: 0.9085  \n",
      "Epoch 30: val_accuracy did not improve from 0.98394\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9478 - loss: 0.9085 - val_accuracy: 0.9828 - val_loss: 0.7618 - learning_rate: 4.8828e-05\n",
      "Completed run 4 with 30 epochs\n",
      "autosaveAdult_4_23.keras\n",
      "\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 796us/step - accuracy: 0.8844 - loss: 1.2290\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8818 - loss: 1.2395\n",
      "autosaveP24_4_30.keras\n",
      "\u001b[1m1825/1825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 747us/step - accuracy: 0.9099 - loss: 1.0671\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9089 - loss: 1.0769\n",
      "autosaveP48_4_11.keras\n",
      "\u001b[1m1699/1699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 626us/step - accuracy: 0.9817 - loss: 0.8040\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9827 - loss: 0.8049\n",
      "Starting run 5\n",
      "Run 5, Epoch 1/30\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7550 - loss: 1.8302  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.82971, saving model to autosaveAdult_5_01.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7548 - loss: 1.8315 - val_accuracy: 0.8297 - val_loss: 2.3800 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7716 - loss: 1.7929  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.87408, saving model to autosaveP24_5_01.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7715 - loss: 1.7935 - val_accuracy: 0.8741 - val_loss: 1.9660 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8747 - loss: 1.6318  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.91260, saving model to autosaveP48_5_01.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8745 - loss: 1.6337 - val_accuracy: 0.9126 - val_loss: 3.3443 - learning_rate: 0.0500\n",
      "Run 5, Epoch 2/30\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6563 - loss: 3.1601  \n",
      "Epoch 2: val_accuracy did not improve from 0.82971\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6563 - loss: 3.1607 - val_accuracy: 0.8291 - val_loss: 2.8591 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7152 - loss: 2.6007  \n",
      "Epoch 2: val_accuracy did not improve from 0.87408\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7152 - loss: 2.6009 - val_accuracy: 0.8531 - val_loss: 2.1354 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7179 - loss: 5.1064  \n",
      "Epoch 2: val_accuracy improved from 0.91260 to 0.93975, saving model to autosaveP48_5_02.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7179 - loss: 5.1068 - val_accuracy: 0.9397 - val_loss: 3.8328 - learning_rate: 0.0500\n",
      "Run 5, Epoch 3/30\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6980 - loss: 3.0150  \n",
      "Epoch 3: val_accuracy improved from 0.82971 to 0.86411, saving model to autosaveAdult_5_03.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6980 - loss: 3.0142 - val_accuracy: 0.8641 - val_loss: 2.0261 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7660 - loss: 2.2172  \n",
      "Epoch 3: val_accuracy improved from 0.87408 to 0.89581, saving model to autosaveP24_5_03.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7660 - loss: 2.2169 - val_accuracy: 0.8958 - val_loss: 1.5107 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8121 - loss: 3.8684  \n",
      "Epoch 3: val_accuracy improved from 0.93975 to 0.97219, saving model to autosaveP48_5_03.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8122 - loss: 3.8671 - val_accuracy: 0.9722 - val_loss: 1.9703 - learning_rate: 0.0250\n",
      "Run 5, Epoch 4/30\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7713 - loss: 2.0712  \n",
      "Epoch 4: val_accuracy improved from 0.86411 to 0.86748, saving model to autosaveAdult_5_04.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7713 - loss: 2.0710 - val_accuracy: 0.8675 - val_loss: 1.6925 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8115 - loss: 1.6237  \n",
      "Epoch 4: val_accuracy improved from 0.89581 to 0.90290, saving model to autosaveP24_5_04.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8115 - loss: 1.6236 - val_accuracy: 0.9029 - val_loss: 1.3249 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8927 - loss: 2.0496  \n",
      "Epoch 4: val_accuracy did not improve from 0.97219\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8927 - loss: 2.0492 - val_accuracy: 0.9681 - val_loss: 1.3244 - learning_rate: 0.0250\n",
      "Run 5, Epoch 5/30\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7860 - loss: 1.7690  \n",
      "Epoch 5: val_accuracy did not improve from 0.86748\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7860 - loss: 1.7689 - val_accuracy: 0.8654 - val_loss: 1.5517 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8167 - loss: 1.4894  \n",
      "Epoch 5: val_accuracy did not improve from 0.90290\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8167 - loss: 1.4894 - val_accuracy: 0.8927 - val_loss: 1.2834 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9094 - loss: 1.4527  \n",
      "Epoch 5: val_accuracy improved from 0.97219 to 0.97782, saving model to autosaveP48_5_05.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9095 - loss: 1.4526 - val_accuracy: 0.9778 - val_loss: 1.0816 - learning_rate: 0.0250\n",
      "Run 5, Epoch 6/30\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7996 - loss: 1.5800  \n",
      "Epoch 6: val_accuracy improved from 0.86748 to 0.87360, saving model to autosaveAdult_5_06.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7996 - loss: 1.5800 - val_accuracy: 0.8736 - val_loss: 1.4501 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8294 - loss: 1.3714  \n",
      "Epoch 6: val_accuracy did not improve from 0.90290\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8294 - loss: 1.3713 - val_accuracy: 0.9021 - val_loss: 1.1966 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9258 - loss: 1.2438  \n",
      "Epoch 6: val_accuracy did not improve from 0.97782\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9258 - loss: 1.2437 - val_accuracy: 0.9773 - val_loss: 0.9727 - learning_rate: 0.0125\n",
      "Run 5, Epoch 7/30\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8151 - loss: 1.4520  \n",
      "Epoch 7: val_accuracy did not improve from 0.87360\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8151 - loss: 1.4520 - val_accuracy: 0.8730 - val_loss: 1.3978 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8372 - loss: 1.2928  \n",
      "Epoch 7: val_accuracy improved from 0.90290 to 0.90382, saving model to autosaveP24_5_07.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8372 - loss: 1.2928 - val_accuracy: 0.9038 - val_loss: 1.1680 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9323 - loss: 1.1196  \n",
      "Epoch 7: val_accuracy improved from 0.97782 to 0.98262, saving model to autosaveP48_5_07.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9323 - loss: 1.1196 - val_accuracy: 0.9826 - val_loss: 0.9041 - learning_rate: 0.0125\n",
      "Run 5, Epoch 8/30\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8166 - loss: 1.4137  \n",
      "Epoch 8: val_accuracy improved from 0.87360 to 0.87635, saving model to autosaveAdult_5_08.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8166 - loss: 1.4137 - val_accuracy: 0.8763 - val_loss: 1.3466 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8394 - loss: 1.2486  \n",
      "Epoch 8: val_accuracy did not improve from 0.90382\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8393 - loss: 1.2486 - val_accuracy: 0.9032 - val_loss: 1.1427 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9372 - loss: 1.0639  \n",
      "Epoch 8: val_accuracy did not improve from 0.98262\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9372 - loss: 1.0639 - val_accuracy: 0.9811 - val_loss: 0.8673 - learning_rate: 0.0125\n",
      "Run 5, Epoch 9/30\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8228 - loss: 1.3431  \n",
      "Epoch 9: val_accuracy improved from 0.87635 to 0.87930, saving model to autosaveAdult_5_09.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8228 - loss: 1.3431 - val_accuracy: 0.8793 - val_loss: 1.3246 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8458 - loss: 1.2089  \n",
      "Epoch 9: val_accuracy improved from 0.90382 to 0.90983, saving model to autosaveP24_5_09.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8458 - loss: 1.2089 - val_accuracy: 0.9098 - val_loss: 1.1211 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9401 - loss: 1.0194  \n",
      "Epoch 9: val_accuracy did not improve from 0.98262\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9401 - loss: 1.0194 - val_accuracy: 0.9818 - val_loss: 0.8436 - learning_rate: 0.0063\n",
      "Run 5, Epoch 10/30\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8294 - loss: 1.3100  \n",
      "Epoch 10: val_accuracy did not improve from 0.87930\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8294 - loss: 1.3100 - val_accuracy: 0.8740 - val_loss: 1.3081 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8477 - loss: 1.1907  \n",
      "Epoch 10: val_accuracy did not improve from 0.90983\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8477 - loss: 1.1907 - val_accuracy: 0.9060 - val_loss: 1.1043 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9410 - loss: 0.9956  \n",
      "Epoch 10: val_accuracy did not improve from 0.98262\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9410 - loss: 0.9956 - val_accuracy: 0.9808 - val_loss: 0.8286 - learning_rate: 0.0063\n",
      "Run 5, Epoch 11/30\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8316 - loss: 1.2841  \n",
      "Epoch 11: val_accuracy did not improve from 0.87930\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8315 - loss: 1.2841 - val_accuracy: 0.8789 - val_loss: 1.2852 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8493 - loss: 1.1710  \n",
      "Epoch 11: val_accuracy improved from 0.90983 to 0.91014, saving model to autosaveP24_5_11.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8493 - loss: 1.1710 - val_accuracy: 0.9101 - val_loss: 1.0974 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9385 - loss: 0.9881  \n",
      "Epoch 11: val_accuracy did not improve from 0.98262\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9385 - loss: 0.9881 - val_accuracy: 0.9826 - val_loss: 0.8142 - learning_rate: 0.0063\n",
      "Run 5, Epoch 12/30\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8366 - loss: 1.2751  \n",
      "Epoch 12: val_accuracy did not improve from 0.87930\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8366 - loss: 1.2751 - val_accuracy: 0.8766 - val_loss: 1.2793 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8518 - loss: 1.1531  \n",
      "Epoch 12: val_accuracy improved from 0.91014 to 0.91060, saving model to autosaveP24_5_12.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8518 - loss: 1.1531 - val_accuracy: 0.9106 - val_loss: 1.0840 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9437 - loss: 0.9531  \n",
      "Epoch 12: val_accuracy did not improve from 0.98262\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9437 - loss: 0.9531 - val_accuracy: 0.9823 - val_loss: 0.8032 - learning_rate: 0.0031\n",
      "Run 5, Epoch 13/30\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8335 - loss: 1.2648  \n",
      "Epoch 13: val_accuracy did not improve from 0.87930\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8335 - loss: 1.2648 - val_accuracy: 0.8744 - val_loss: 1.2711 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8541 - loss: 1.1591  \n",
      "Epoch 13: val_accuracy improved from 0.91060 to 0.91307, saving model to autosaveP24_5_13.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8541 - loss: 1.1591 - val_accuracy: 0.9131 - val_loss: 1.0772 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9434 - loss: 0.9499  \n",
      "Epoch 13: val_accuracy improved from 0.98262 to 0.98345, saving model to autosaveP48_5_13.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9434 - loss: 0.9500 - val_accuracy: 0.9834 - val_loss: 0.7948 - learning_rate: 0.0031\n",
      "Run 5, Epoch 14/30\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8378 - loss: 1.2635  \n",
      "Epoch 14: val_accuracy did not improve from 0.87930\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8378 - loss: 1.2635 - val_accuracy: 0.8757 - val_loss: 1.2626 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8544 - loss: 1.1435  \n",
      "Epoch 14: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8544 - loss: 1.1435 - val_accuracy: 0.9083 - val_loss: 1.0759 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9468 - loss: 0.9492  \n",
      "Epoch 14: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9468 - loss: 0.9492 - val_accuracy: 0.9828 - val_loss: 0.7909 - learning_rate: 0.0031\n",
      "Run 5, Epoch 15/30\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8391 - loss: 1.2383  \n",
      "Epoch 15: val_accuracy improved from 0.87930 to 0.88014, saving model to autosaveAdult_5_15.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8391 - loss: 1.2383 - val_accuracy: 0.8801 - val_loss: 1.2582 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8555 - loss: 1.1431  \n",
      "Epoch 15: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8555 - loss: 1.1431 - val_accuracy: 0.9125 - val_loss: 1.0705 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9452 - loss: 0.9388  \n",
      "Epoch 15: val_accuracy improved from 0.98345 to 0.98378, saving model to autosaveP48_5_15.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9452 - loss: 0.9388 - val_accuracy: 0.9838 - val_loss: 0.7874 - learning_rate: 0.0016\n",
      "Run 5, Epoch 16/30\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8419 - loss: 1.2173  \n",
      "Epoch 16: val_accuracy did not improve from 0.88014\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8419 - loss: 1.2173 - val_accuracy: 0.8793 - val_loss: 1.2512 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8566 - loss: 1.1332  \n",
      "Epoch 16: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8566 - loss: 1.1332 - val_accuracy: 0.9123 - val_loss: 1.0664 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9452 - loss: 0.9311  \n",
      "Epoch 16: val_accuracy did not improve from 0.98378\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9452 - loss: 0.9311 - val_accuracy: 0.9829 - val_loss: 0.7844 - learning_rate: 0.0016\n",
      "Run 5, Epoch 17/30\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8371 - loss: 1.2216  \n",
      "Epoch 17: val_accuracy did not improve from 0.88014\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8371 - loss: 1.2217 - val_accuracy: 0.8778 - val_loss: 1.2495 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8560 - loss: 1.1273  \n",
      "Epoch 17: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8560 - loss: 1.1273 - val_accuracy: 0.9120 - val_loss: 1.0650 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9442 - loss: 0.9233  \n",
      "Epoch 17: val_accuracy did not improve from 0.98378\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9442 - loss: 0.9233 - val_accuracy: 0.9823 - val_loss: 0.7832 - learning_rate: 0.0016\n",
      "Run 5, Epoch 18/30\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8390 - loss: 1.2222  \n",
      "Epoch 18: val_accuracy did not improve from 0.88014\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8390 - loss: 1.2222 - val_accuracy: 0.8789 - val_loss: 1.2469 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8550 - loss: 1.1231  \n",
      "Epoch 18: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8550 - loss: 1.1231 - val_accuracy: 0.9123 - val_loss: 1.0630 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9443 - loss: 0.9242  \n",
      "Epoch 18: val_accuracy did not improve from 0.98378\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9443 - loss: 0.9242 - val_accuracy: 0.9834 - val_loss: 0.7792 - learning_rate: 7.8125e-04\n",
      "Run 5, Epoch 19/30\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8416 - loss: 1.2213  \n",
      "Epoch 19: val_accuracy did not improve from 0.88014\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8416 - loss: 1.2213 - val_accuracy: 0.8797 - val_loss: 1.2435 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8555 - loss: 1.1208  \n",
      "Epoch 19: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8555 - loss: 1.1208 - val_accuracy: 0.9118 - val_loss: 1.0620 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9469 - loss: 0.9207  \n",
      "Epoch 19: val_accuracy did not improve from 0.98378\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9469 - loss: 0.9207 - val_accuracy: 0.9834 - val_loss: 0.7775 - learning_rate: 7.8125e-04\n",
      "Run 5, Epoch 20/30\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8416 - loss: 1.2096  \n",
      "Epoch 20: val_accuracy improved from 0.88014 to 0.88035, saving model to autosaveAdult_5_20.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8416 - loss: 1.2096 - val_accuracy: 0.8804 - val_loss: 1.2465 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8573 - loss: 1.1238  \n",
      "Epoch 20: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8573 - loss: 1.1238 - val_accuracy: 0.9120 - val_loss: 1.0616 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9463 - loss: 0.9202  \n",
      "Epoch 20: val_accuracy did not improve from 0.98378\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9463 - loss: 0.9202 - val_accuracy: 0.9829 - val_loss: 0.7779 - learning_rate: 7.8125e-04\n",
      "Run 5, Epoch 21/30\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8369 - loss: 1.2260  \n",
      "Epoch 21: val_accuracy did not improve from 0.88035\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8369 - loss: 1.2260 - val_accuracy: 0.8797 - val_loss: 1.2442 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8585 - loss: 1.1094  \n",
      "Epoch 21: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8585 - loss: 1.1094 - val_accuracy: 0.9117 - val_loss: 1.0604 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9450 - loss: 0.9220  \n",
      "Epoch 21: val_accuracy did not improve from 0.98378\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9450 - loss: 0.9220 - val_accuracy: 0.9834 - val_loss: 0.7766 - learning_rate: 3.9063e-04\n",
      "Run 5, Epoch 22/30\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8392 - loss: 1.2151  \n",
      "Epoch 22: val_accuracy did not improve from 0.88035\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8392 - loss: 1.2152 - val_accuracy: 0.8799 - val_loss: 1.2431 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8558 - loss: 1.1159  \n",
      "Epoch 22: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8558 - loss: 1.1158 - val_accuracy: 0.9118 - val_loss: 1.0595 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9479 - loss: 0.9185  \n",
      "Epoch 22: val_accuracy did not improve from 0.98378\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9479 - loss: 0.9186 - val_accuracy: 0.9834 - val_loss: 0.7757 - learning_rate: 3.9063e-04\n",
      "Run 5, Epoch 23/30\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8410 - loss: 1.2189  \n",
      "Epoch 23: val_accuracy did not improve from 0.88035\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8410 - loss: 1.2189 - val_accuracy: 0.8789 - val_loss: 1.2422 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8586 - loss: 1.1057  \n",
      "Epoch 23: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8586 - loss: 1.1058 - val_accuracy: 0.9118 - val_loss: 1.0585 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9460 - loss: 0.9234  \n",
      "Epoch 23: val_accuracy did not improve from 0.98378\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9460 - loss: 0.9234 - val_accuracy: 0.9838 - val_loss: 0.7749 - learning_rate: 3.9063e-04\n",
      "Run 5, Epoch 24/30\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8370 - loss: 1.2191  \n",
      "Epoch 24: val_accuracy did not improve from 0.88035\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8370 - loss: 1.2191 - val_accuracy: 0.8801 - val_loss: 1.2416 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8561 - loss: 1.1213  \n",
      "Epoch 24: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8561 - loss: 1.1213 - val_accuracy: 0.9121 - val_loss: 1.0582 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9497 - loss: 0.9115  \n",
      "Epoch 24: val_accuracy did not improve from 0.98378\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9497 - loss: 0.9115 - val_accuracy: 0.9838 - val_loss: 0.7742 - learning_rate: 1.9531e-04\n",
      "Run 5, Epoch 25/30\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8395 - loss: 1.2200  \n",
      "Epoch 25: val_accuracy did not improve from 0.88035\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8395 - loss: 1.2200 - val_accuracy: 0.8795 - val_loss: 1.2408 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8597 - loss: 1.1194  \n",
      "Epoch 25: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8597 - loss: 1.1194 - val_accuracy: 0.9121 - val_loss: 1.0581 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9458 - loss: 0.9221  \n",
      "Epoch 25: val_accuracy did not improve from 0.98378\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9458 - loss: 0.9221 - val_accuracy: 0.9834 - val_loss: 0.7736 - learning_rate: 1.9531e-04\n",
      "Run 5, Epoch 26/30\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8397 - loss: 1.2097  \n",
      "Epoch 26: val_accuracy did not improve from 0.88035\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8397 - loss: 1.2098 - val_accuracy: 0.8799 - val_loss: 1.2405 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8572 - loss: 1.1070  \n",
      "Epoch 26: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8572 - loss: 1.1070 - val_accuracy: 0.9120 - val_loss: 1.0576 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9468 - loss: 0.9205  \n",
      "Epoch 26: val_accuracy did not improve from 0.98378\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9468 - loss: 0.9205 - val_accuracy: 0.9833 - val_loss: 0.7734 - learning_rate: 1.9531e-04\n",
      "Run 5, Epoch 27/30\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8404 - loss: 1.2212  \n",
      "Epoch 27: val_accuracy did not improve from 0.88035\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8404 - loss: 1.2212 - val_accuracy: 0.8795 - val_loss: 1.2406 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8558 - loss: 1.1091  \n",
      "Epoch 27: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8558 - loss: 1.1091 - val_accuracy: 0.9117 - val_loss: 1.0574 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9443 - loss: 0.9147  \n",
      "Epoch 27: val_accuracy did not improve from 0.98378\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9443 - loss: 0.9147 - val_accuracy: 0.9833 - val_loss: 0.7731 - learning_rate: 9.7656e-05\n",
      "Run 5, Epoch 28/30\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8423 - loss: 1.2156  \n",
      "Epoch 28: val_accuracy did not improve from 0.88035\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8423 - loss: 1.2156 - val_accuracy: 0.8799 - val_loss: 1.2399 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8583 - loss: 1.1219  \n",
      "Epoch 28: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8584 - loss: 1.1219 - val_accuracy: 0.9115 - val_loss: 1.0575 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9474 - loss: 0.9138  \n",
      "Epoch 28: val_accuracy did not improve from 0.98378\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9474 - loss: 0.9138 - val_accuracy: 0.9833 - val_loss: 0.7730 - learning_rate: 9.7656e-05\n",
      "Run 5, Epoch 29/30\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8418 - loss: 1.2162  \n",
      "Epoch 29: val_accuracy did not improve from 0.88035\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8418 - loss: 1.2162 - val_accuracy: 0.8797 - val_loss: 1.2394 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8585 - loss: 1.1126  \n",
      "Epoch 29: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8585 - loss: 1.1126 - val_accuracy: 0.9115 - val_loss: 1.0573 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9458 - loss: 0.9134  \n",
      "Epoch 29: val_accuracy did not improve from 0.98378\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9458 - loss: 0.9134 - val_accuracy: 0.9833 - val_loss: 0.7726 - learning_rate: 9.7656e-05\n",
      "Run 5, Epoch 30/30\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8402 - loss: 1.2231  \n",
      "Epoch 30: val_accuracy did not improve from 0.88035\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8402 - loss: 1.2230 - val_accuracy: 0.8797 - val_loss: 1.2393 - learning_rate: 4.8828e-05\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8573 - loss: 1.1040  \n",
      "Epoch 30: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8573 - loss: 1.1040 - val_accuracy: 0.9117 - val_loss: 1.0572 - learning_rate: 4.8828e-05\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9479 - loss: 0.9135  \n",
      "Epoch 30: val_accuracy did not improve from 0.98378\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9479 - loss: 0.9135 - val_accuracy: 0.9833 - val_loss: 0.7726 - learning_rate: 4.8828e-05\n",
      "Completed run 5 with 30 epochs\n",
      "autosaveAdult_5_20.keras\n",
      "\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 800us/step - accuracy: 0.8835 - loss: 1.2372\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8803 - loss: 1.2485\n",
      "autosaveP24_5_13.keras\n",
      "\u001b[1m1825/1825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 754us/step - accuracy: 0.9099 - loss: 1.0871\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 1.0981\n",
      "autosaveP48_5_15.keras\n",
      "\u001b[1m1699/1699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - accuracy: 0.9803 - loss: 0.7977\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9843 - loss: 0.7949\n",
      "Starting run 6\n",
      "Run 6, Epoch 1/30\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7570 - loss: 1.7848  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.84005, saving model to autosaveAdult_6_01.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7569 - loss: 1.7861 - val_accuracy: 0.8401 - val_loss: 2.3711 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7777 - loss: 1.6934  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.85018, saving model to autosaveP24_6_01.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7777 - loss: 1.6942 - val_accuracy: 0.8502 - val_loss: 1.9729 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8716 - loss: 1.6161  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.95547, saving model to autosaveP48_6_01.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8715 - loss: 1.6174 - val_accuracy: 0.9555 - val_loss: 2.2881 - learning_rate: 0.0500\n",
      "Run 6, Epoch 2/30\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6572 - loss: 3.2048  \n",
      "Epoch 2: val_accuracy did not improve from 0.84005\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6572 - loss: 3.2056 - val_accuracy: 0.8316 - val_loss: 2.9789 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7227 - loss: 2.4998  \n",
      "Epoch 2: val_accuracy improved from 0.85018 to 0.87007, saving model to autosaveP24_6_02.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7227 - loss: 2.5000 - val_accuracy: 0.8701 - val_loss: 2.0426 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7690 - loss: 3.5779  \n",
      "Epoch 2: val_accuracy did not improve from 0.95547\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7690 - loss: 3.5790 - val_accuracy: 0.9252 - val_loss: 3.5855 - learning_rate: 0.0500\n",
      "Run 6, Epoch 3/30\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6934 - loss: 3.1679  \n",
      "Epoch 3: val_accuracy improved from 0.84005 to 0.85989, saving model to autosaveAdult_6_03.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.6935 - loss: 3.1670 - val_accuracy: 0.8599 - val_loss: 2.0778 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7649 - loss: 2.1746  \n",
      "Epoch 3: val_accuracy improved from 0.87007 to 0.89303, saving model to autosaveP24_6_03.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7649 - loss: 2.1742 - val_accuracy: 0.8930 - val_loss: 1.4662 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8045 - loss: 3.7128  \n",
      "Epoch 3: val_accuracy improved from 0.95547 to 0.97368, saving model to autosaveP48_6_03.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8046 - loss: 3.7115 - val_accuracy: 0.9737 - val_loss: 1.8848 - learning_rate: 0.0250\n",
      "Run 6, Epoch 4/30\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7693 - loss: 2.1079  \n",
      "Epoch 4: val_accuracy did not improve from 0.85989\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7693 - loss: 2.1076 - val_accuracy: 0.8584 - val_loss: 1.7373 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8093 - loss: 1.5991  \n",
      "Epoch 4: val_accuracy improved from 0.89303 to 0.89535, saving model to autosaveP24_6_04.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8093 - loss: 1.5990 - val_accuracy: 0.8953 - val_loss: 1.3181 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8908 - loss: 1.9545  \n",
      "Epoch 4: val_accuracy improved from 0.97368 to 0.97980, saving model to autosaveP48_6_04.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8908 - loss: 1.9541 - val_accuracy: 0.9798 - val_loss: 1.2544 - learning_rate: 0.0250\n",
      "Run 6, Epoch 5/30\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7877 - loss: 1.7436  \n",
      "Epoch 5: val_accuracy improved from 0.85989 to 0.86664, saving model to autosaveAdult_6_05.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7877 - loss: 1.7436 - val_accuracy: 0.8666 - val_loss: 1.5755 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8149 - loss: 1.4869  \n",
      "Epoch 5: val_accuracy improved from 0.89535 to 0.89781, saving model to autosaveP24_6_05.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8149 - loss: 1.4870 - val_accuracy: 0.8978 - val_loss: 1.2860 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9116 - loss: 1.4292  \n",
      "Epoch 5: val_accuracy did not improve from 0.97980\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9116 - loss: 1.4291 - val_accuracy: 0.9652 - val_loss: 1.0790 - learning_rate: 0.0250\n",
      "Run 6, Epoch 6/30\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8022 - loss: 1.5959  \n",
      "Epoch 6: val_accuracy improved from 0.86664 to 0.87424, saving model to autosaveAdult_6_06.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8022 - loss: 1.5958 - val_accuracy: 0.8742 - val_loss: 1.4511 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8301 - loss: 1.3975  \n",
      "Epoch 6: val_accuracy improved from 0.89781 to 0.90660, saving model to autosaveP24_6_06.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8301 - loss: 1.3974 - val_accuracy: 0.9066 - val_loss: 1.1914 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9207 - loss: 1.2256  \n",
      "Epoch 6: val_accuracy did not improve from 0.97980\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9207 - loss: 1.2255 - val_accuracy: 0.9763 - val_loss: 0.9495 - learning_rate: 0.0125\n",
      "Run 6, Epoch 7/30\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8160 - loss: 1.4567  \n",
      "Epoch 7: val_accuracy did not improve from 0.87424\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8160 - loss: 1.4567 - val_accuracy: 0.8725 - val_loss: 1.4095 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8415 - loss: 1.2685  \n",
      "Epoch 7: val_accuracy did not improve from 0.90660\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8415 - loss: 1.2685 - val_accuracy: 0.9015 - val_loss: 1.1559 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9340 - loss: 1.1006  \n",
      "Epoch 7: val_accuracy improved from 0.97980 to 0.98196, saving model to autosaveP48_6_07.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9340 - loss: 1.1006 - val_accuracy: 0.9820 - val_loss: 0.8854 - learning_rate: 0.0125\n",
      "Run 6, Epoch 8/30\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8225 - loss: 1.4017  \n",
      "Epoch 8: val_accuracy did not improve from 0.87424\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8225 - loss: 1.4017 - val_accuracy: 0.8723 - val_loss: 1.3500 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8383 - loss: 1.2554  \n",
      "Epoch 8: val_accuracy improved from 0.90660 to 0.90691, saving model to autosaveP24_6_08.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8383 - loss: 1.2554 - val_accuracy: 0.9069 - val_loss: 1.1373 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9341 - loss: 1.0444  \n",
      "Epoch 8: val_accuracy did not improve from 0.98196\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9341 - loss: 1.0444 - val_accuracy: 0.9820 - val_loss: 0.8555 - learning_rate: 0.0125\n",
      "Run 6, Epoch 9/30\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8255 - loss: 1.3578  \n",
      "Epoch 9: val_accuracy improved from 0.87424 to 0.87824, saving model to autosaveAdult_6_09.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8255 - loss: 1.3578 - val_accuracy: 0.8782 - val_loss: 1.3219 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8450 - loss: 1.2180  \n",
      "Epoch 9: val_accuracy improved from 0.90691 to 0.91030, saving model to autosaveP24_6_09.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8450 - loss: 1.2180 - val_accuracy: 0.9103 - val_loss: 1.1097 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9372 - loss: 1.0161  \n",
      "Epoch 9: val_accuracy did not improve from 0.98196\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9373 - loss: 1.0161 - val_accuracy: 0.9818 - val_loss: 0.8337 - learning_rate: 0.0063\n",
      "Run 6, Epoch 10/30\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8266 - loss: 1.3189  \n",
      "Epoch 10: val_accuracy did not improve from 0.87824\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8266 - loss: 1.3190 - val_accuracy: 0.8753 - val_loss: 1.3155 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8486 - loss: 1.1932  \n",
      "Epoch 10: val_accuracy improved from 0.91030 to 0.91384, saving model to autosaveP24_6_10.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8486 - loss: 1.1932 - val_accuracy: 0.9138 - val_loss: 1.0976 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9418 - loss: 0.9883  \n",
      "Epoch 10: val_accuracy did not improve from 0.98196\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9418 - loss: 0.9883 - val_accuracy: 0.9816 - val_loss: 0.8140 - learning_rate: 0.0063\n",
      "Run 6, Epoch 11/30\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8258 - loss: 1.3024  \n",
      "Epoch 11: val_accuracy did not improve from 0.87824\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8258 - loss: 1.3024 - val_accuracy: 0.8730 - val_loss: 1.2922 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8510 - loss: 1.1810  \n",
      "Epoch 11: val_accuracy did not improve from 0.91384\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8510 - loss: 1.1810 - val_accuracy: 0.9072 - val_loss: 1.0913 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9428 - loss: 0.9666  \n",
      "Epoch 11: val_accuracy improved from 0.98196 to 0.98229, saving model to autosaveP48_6_11.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9428 - loss: 0.9666 - val_accuracy: 0.9823 - val_loss: 0.8029 - learning_rate: 0.0063\n",
      "Run 6, Epoch 12/30\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8351 - loss: 1.2740  \n",
      "Epoch 12: val_accuracy did not improve from 0.87824\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8351 - loss: 1.2740 - val_accuracy: 0.8772 - val_loss: 1.2784 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8519 - loss: 1.1598  \n",
      "Epoch 12: val_accuracy did not improve from 0.91384\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8519 - loss: 1.1597 - val_accuracy: 0.9123 - val_loss: 1.0766 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9433 - loss: 0.9457  \n",
      "Epoch 12: val_accuracy improved from 0.98229 to 0.98245, saving model to autosaveP48_6_12.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9433 - loss: 0.9457 - val_accuracy: 0.9825 - val_loss: 0.7917 - learning_rate: 0.0031\n",
      "Run 6, Epoch 13/30\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8330 - loss: 1.2659  \n",
      "Epoch 13: val_accuracy improved from 0.87824 to 0.87909, saving model to autosaveAdult_6_13.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8330 - loss: 1.2659 - val_accuracy: 0.8791 - val_loss: 1.2667 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8517 - loss: 1.1441  \n",
      "Epoch 13: val_accuracy did not improve from 0.91384\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8517 - loss: 1.1441 - val_accuracy: 0.9091 - val_loss: 1.0746 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9430 - loss: 0.9448  \n",
      "Epoch 13: val_accuracy improved from 0.98245 to 0.98345, saving model to autosaveP48_6_13.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9430 - loss: 0.9448 - val_accuracy: 0.9834 - val_loss: 0.7839 - learning_rate: 0.0031\n",
      "Run 6, Epoch 14/30\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8327 - loss: 1.2626  \n",
      "Epoch 14: val_accuracy improved from 0.87909 to 0.87993, saving model to autosaveAdult_6_14.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8327 - loss: 1.2625 - val_accuracy: 0.8799 - val_loss: 1.2569 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8560 - loss: 1.1282  \n",
      "Epoch 14: val_accuracy did not improve from 0.91384\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8560 - loss: 1.1282 - val_accuracy: 0.9120 - val_loss: 1.0696 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9466 - loss: 0.9238  \n",
      "Epoch 14: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9466 - loss: 0.9238 - val_accuracy: 0.9828 - val_loss: 0.7808 - learning_rate: 0.0031\n",
      "Run 6, Epoch 15/30\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8408 - loss: 1.2375  \n",
      "Epoch 15: val_accuracy did not improve from 0.87993\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8408 - loss: 1.2375 - val_accuracy: 0.8768 - val_loss: 1.2568 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8568 - loss: 1.1231  \n",
      "Epoch 15: val_accuracy did not improve from 0.91384\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8568 - loss: 1.1231 - val_accuracy: 0.9135 - val_loss: 1.0644 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9447 - loss: 0.9300  \n",
      "Epoch 15: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9447 - loss: 0.9300 - val_accuracy: 0.9828 - val_loss: 0.7764 - learning_rate: 0.0016\n",
      "Run 6, Epoch 16/30\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8361 - loss: 1.2260  \n",
      "Epoch 16: val_accuracy did not improve from 0.87993\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8361 - loss: 1.2261 - val_accuracy: 0.8789 - val_loss: 1.2534 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8593 - loss: 1.1291  \n",
      "Epoch 16: val_accuracy did not improve from 0.91384\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8593 - loss: 1.1291 - val_accuracy: 0.9117 - val_loss: 1.0631 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9469 - loss: 0.9256  \n",
      "Epoch 16: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9469 - loss: 0.9256 - val_accuracy: 0.9828 - val_loss: 0.7729 - learning_rate: 0.0016\n",
      "Run 6, Epoch 17/30\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8363 - loss: 1.2377  \n",
      "Epoch 17: val_accuracy did not improve from 0.87993\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.8363 - loss: 1.2377 - val_accuracy: 0.8780 - val_loss: 1.2484 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8545 - loss: 1.1195  \n",
      "Epoch 17: val_accuracy did not improve from 0.91384\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8545 - loss: 1.1195 - val_accuracy: 0.9132 - val_loss: 1.0598 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9441 - loss: 0.9272  \n",
      "Epoch 17: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9441 - loss: 0.9272 - val_accuracy: 0.9831 - val_loss: 0.7711 - learning_rate: 0.0016\n",
      "Run 6, Epoch 18/30\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8399 - loss: 1.2268  \n",
      "Epoch 18: val_accuracy did not improve from 0.87993\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8399 - loss: 1.2268 - val_accuracy: 0.8799 - val_loss: 1.2463 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8576 - loss: 1.1158  \n",
      "Epoch 18: val_accuracy did not improve from 0.91384\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8576 - loss: 1.1158 - val_accuracy: 0.9132 - val_loss: 1.0575 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9479 - loss: 0.9095  \n",
      "Epoch 18: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9479 - loss: 0.9095 - val_accuracy: 0.9831 - val_loss: 0.7691 - learning_rate: 7.8125e-04\n",
      "Run 6, Epoch 19/30\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8372 - loss: 1.2449  \n",
      "Epoch 19: val_accuracy did not improve from 0.87993\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8372 - loss: 1.2448 - val_accuracy: 0.8795 - val_loss: 1.2448 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8593 - loss: 1.1264  \n",
      "Epoch 19: val_accuracy improved from 0.91384 to 0.91415, saving model to autosaveP24_6_19.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8593 - loss: 1.1264 - val_accuracy: 0.9141 - val_loss: 1.0563 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9482 - loss: 0.9139  \n",
      "Epoch 19: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9482 - loss: 0.9139 - val_accuracy: 0.9833 - val_loss: 0.7676 - learning_rate: 7.8125e-04\n",
      "Run 6, Epoch 20/30\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8397 - loss: 1.2253  \n",
      "Epoch 20: val_accuracy did not improve from 0.87993\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8397 - loss: 1.2253 - val_accuracy: 0.8795 - val_loss: 1.2426 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8611 - loss: 1.1126  \n",
      "Epoch 20: val_accuracy did not improve from 0.91415\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8610 - loss: 1.1126 - val_accuracy: 0.9128 - val_loss: 1.0558 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9452 - loss: 0.9183  \n",
      "Epoch 20: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9452 - loss: 0.9183 - val_accuracy: 0.9826 - val_loss: 0.7675 - learning_rate: 7.8125e-04\n",
      "Run 6, Epoch 21/30\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8379 - loss: 1.2218  \n",
      "Epoch 21: val_accuracy did not improve from 0.87993\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8379 - loss: 1.2218 - val_accuracy: 0.8797 - val_loss: 1.2425 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8572 - loss: 1.1183  \n",
      "Epoch 21: val_accuracy improved from 0.91415 to 0.91446, saving model to autosaveP24_6_21.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8572 - loss: 1.1183 - val_accuracy: 0.9145 - val_loss: 1.0550 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9467 - loss: 0.9132  \n",
      "Epoch 21: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9467 - loss: 0.9131 - val_accuracy: 0.9826 - val_loss: 0.7664 - learning_rate: 3.9063e-04\n",
      "Run 6, Epoch 22/30\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8365 - loss: 1.2237  \n",
      "Epoch 22: val_accuracy did not improve from 0.87993\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8365 - loss: 1.2237 - val_accuracy: 0.8791 - val_loss: 1.2425 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8581 - loss: 1.1161  \n",
      "Epoch 22: val_accuracy did not improve from 0.91446\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8581 - loss: 1.1161 - val_accuracy: 0.9143 - val_loss: 1.0542 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9477 - loss: 0.9055  \n",
      "Epoch 22: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9477 - loss: 0.9055 - val_accuracy: 0.9833 - val_loss: 0.7656 - learning_rate: 3.9063e-04\n",
      "Run 6, Epoch 23/30\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8406 - loss: 1.2256  \n",
      "Epoch 23: val_accuracy did not improve from 0.87993\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8406 - loss: 1.2256 - val_accuracy: 0.8795 - val_loss: 1.2413 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8573 - loss: 1.1077  \n",
      "Epoch 23: val_accuracy did not improve from 0.91446\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8573 - loss: 1.1077 - val_accuracy: 0.9138 - val_loss: 1.0538 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9449 - loss: 0.9089  \n",
      "Epoch 23: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9449 - loss: 0.9089 - val_accuracy: 0.9829 - val_loss: 0.7651 - learning_rate: 3.9063e-04\n",
      "Run 6, Epoch 24/30\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8341 - loss: 1.2185  \n",
      "Epoch 24: val_accuracy did not improve from 0.87993\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8341 - loss: 1.2185 - val_accuracy: 0.8793 - val_loss: 1.2409 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8597 - loss: 1.1045  \n",
      "Epoch 24: val_accuracy did not improve from 0.91446\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8597 - loss: 1.1045 - val_accuracy: 0.9134 - val_loss: 1.0533 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9482 - loss: 0.9108  \n",
      "Epoch 24: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9482 - loss: 0.9108 - val_accuracy: 0.9829 - val_loss: 0.7646 - learning_rate: 1.9531e-04\n",
      "Run 6, Epoch 25/30\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8404 - loss: 1.2240  \n",
      "Epoch 25: val_accuracy did not improve from 0.87993\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8404 - loss: 1.2240 - val_accuracy: 0.8787 - val_loss: 1.2401 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8577 - loss: 1.1144  \n",
      "Epoch 25: val_accuracy did not improve from 0.91446\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8577 - loss: 1.1144 - val_accuracy: 0.9145 - val_loss: 1.0527 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9472 - loss: 0.9081  \n",
      "Epoch 25: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9472 - loss: 0.9081 - val_accuracy: 0.9831 - val_loss: 0.7641 - learning_rate: 1.9531e-04\n",
      "Run 6, Epoch 26/30\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8409 - loss: 1.2234  \n",
      "Epoch 26: val_accuracy did not improve from 0.87993\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8409 - loss: 1.2234 - val_accuracy: 0.8793 - val_loss: 1.2399 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8578 - loss: 1.1004  \n",
      "Epoch 26: val_accuracy improved from 0.91446 to 0.91461, saving model to autosaveP24_6_26.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8578 - loss: 1.1004 - val_accuracy: 0.9146 - val_loss: 1.0524 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9472 - loss: 0.9085  \n",
      "Epoch 26: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9472 - loss: 0.9084 - val_accuracy: 0.9828 - val_loss: 0.7637 - learning_rate: 1.9531e-04\n",
      "Run 6, Epoch 27/30\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8398 - loss: 1.2270  \n",
      "Epoch 27: val_accuracy did not improve from 0.87993\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8398 - loss: 1.2270 - val_accuracy: 0.8791 - val_loss: 1.2396 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8604 - loss: 1.1118  \n",
      "Epoch 27: val_accuracy did not improve from 0.91461\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8604 - loss: 1.1118 - val_accuracy: 0.9143 - val_loss: 1.0522 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9491 - loss: 0.9065  \n",
      "Epoch 27: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.9065 - val_accuracy: 0.9828 - val_loss: 0.7635 - learning_rate: 9.7656e-05\n",
      "Run 6, Epoch 28/30\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8400 - loss: 1.2126  \n",
      "Epoch 28: val_accuracy did not improve from 0.87993\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8400 - loss: 1.2126 - val_accuracy: 0.8791 - val_loss: 1.2390 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8598 - loss: 1.1110  \n",
      "Epoch 28: val_accuracy did not improve from 0.91461\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8598 - loss: 1.1110 - val_accuracy: 0.9140 - val_loss: 1.0520 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9488 - loss: 0.9030  \n",
      "Epoch 28: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9488 - loss: 0.9030 - val_accuracy: 0.9829 - val_loss: 0.7633 - learning_rate: 9.7656e-05\n",
      "Run 6, Epoch 29/30\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8410 - loss: 1.2178  \n",
      "Epoch 29: val_accuracy did not improve from 0.87993\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8410 - loss: 1.2178 - val_accuracy: 0.8793 - val_loss: 1.2389 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8582 - loss: 1.1030  \n",
      "Epoch 29: val_accuracy did not improve from 0.91461\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8582 - loss: 1.1030 - val_accuracy: 0.9141 - val_loss: 1.0519 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9501 - loss: 0.9081  \n",
      "Epoch 29: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9501 - loss: 0.9081 - val_accuracy: 0.9829 - val_loss: 0.7631 - learning_rate: 9.7656e-05\n",
      "Run 6, Epoch 30/30\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8381 - loss: 1.2267  \n",
      "Epoch 30: val_accuracy did not improve from 0.87993\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8381 - loss: 1.2266 - val_accuracy: 0.8791 - val_loss: 1.2386 - learning_rate: 4.8828e-05\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8601 - loss: 1.1089  \n",
      "Epoch 30: val_accuracy did not improve from 0.91461\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8601 - loss: 1.1089 - val_accuracy: 0.9143 - val_loss: 1.0517 - learning_rate: 4.8828e-05\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9475 - loss: 0.9087  \n",
      "Epoch 30: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9475 - loss: 0.9087 - val_accuracy: 0.9831 - val_loss: 0.7630 - learning_rate: 4.8828e-05\n",
      "Completed run 6 with 30 epochs\n",
      "autosaveAdult_6_14.keras\n",
      "\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 795us/step - accuracy: 0.8830 - loss: 1.2482\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8763 - loss: 1.2599\n",
      "autosaveP24_6_26.keras\n",
      "\u001b[1m1825/1825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 742us/step - accuracy: 0.9102 - loss: 1.0629\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 1.0738\n",
      "autosaveP48_6_13.keras\n",
      "\u001b[1m1699/1699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619us/step - accuracy: 0.9819 - loss: 0.7927\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9822 - loss: 0.7916\n",
      "Starting run 7\n",
      "Run 7, Epoch 1/30\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7632 - loss: 1.7872  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.83625, saving model to autosaveAdult_7_01.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7631 - loss: 1.7884 - val_accuracy: 0.8363 - val_loss: 2.2563 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7727 - loss: 1.7475  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.88055, saving model to autosaveP24_7_01.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7726 - loss: 1.7482 - val_accuracy: 0.8805 - val_loss: 1.8878 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8718 - loss: 1.6852  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.93478, saving model to autosaveP48_7_01.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8716 - loss: 1.6872 - val_accuracy: 0.9348 - val_loss: 3.0166 - learning_rate: 0.0500\n",
      "Run 7, Epoch 2/30\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6686 - loss: 2.9559  \n",
      "Epoch 2: val_accuracy did not improve from 0.83625\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6685 - loss: 2.9567 - val_accuracy: 0.7995 - val_loss: 2.8835 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7276 - loss: 2.4309  \n",
      "Epoch 2: val_accuracy improved from 0.88055 to 0.88194, saving model to autosaveP24_7_02.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7275 - loss: 2.4312 - val_accuracy: 0.8819 - val_loss: 2.0557 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7576 - loss: 3.9200  \n",
      "Epoch 2: val_accuracy improved from 0.93478 to 0.93610, saving model to autosaveP48_7_02.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7577 - loss: 3.9201 - val_accuracy: 0.9361 - val_loss: 2.9334 - learning_rate: 0.0500\n",
      "Run 7, Epoch 3/30\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7064 - loss: 2.8868  \n",
      "Epoch 3: val_accuracy improved from 0.83625 to 0.86622, saving model to autosaveAdult_7_03.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7065 - loss: 2.8860 - val_accuracy: 0.8662 - val_loss: 1.9469 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7712 - loss: 2.2305  \n",
      "Epoch 3: val_accuracy improved from 0.88194 to 0.89257, saving model to autosaveP24_7_03.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7712 - loss: 2.2301 - val_accuracy: 0.8926 - val_loss: 1.4885 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8310 - loss: 3.0498  \n",
      "Epoch 3: val_accuracy improved from 0.93610 to 0.97186, saving model to autosaveP48_7_03.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8311 - loss: 3.0488 - val_accuracy: 0.9719 - val_loss: 1.6672 - learning_rate: 0.0250\n",
      "Run 7, Epoch 4/30\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7736 - loss: 1.9800  \n",
      "Epoch 4: val_accuracy did not improve from 0.86622\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7736 - loss: 1.9799 - val_accuracy: 0.8584 - val_loss: 1.6832 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8087 - loss: 1.6315  \n",
      "Epoch 4: val_accuracy improved from 0.89257 to 0.89365, saving model to autosaveP24_7_04.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8087 - loss: 1.6315 - val_accuracy: 0.8936 - val_loss: 1.3216 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9011 - loss: 1.7591  \n",
      "Epoch 4: val_accuracy improved from 0.97186 to 0.97815, saving model to autosaveP48_7_04.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9011 - loss: 1.7588 - val_accuracy: 0.9781 - val_loss: 1.1885 - learning_rate: 0.0250\n",
      "Run 7, Epoch 5/30\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7885 - loss: 1.7367  \n",
      "Epoch 5: val_accuracy did not improve from 0.86622\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7885 - loss: 1.7367 - val_accuracy: 0.8631 - val_loss: 1.5409 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8141 - loss: 1.4801  \n",
      "Epoch 5: val_accuracy improved from 0.89365 to 0.89812, saving model to autosaveP24_7_05.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8141 - loss: 1.4801 - val_accuracy: 0.8981 - val_loss: 1.2720 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9165 - loss: 1.3408  \n",
      "Epoch 5: val_accuracy did not improve from 0.97815\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9165 - loss: 1.3408 - val_accuracy: 0.9742 - val_loss: 1.0404 - learning_rate: 0.0250\n",
      "Run 7, Epoch 6/30\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7978 - loss: 1.5734  \n",
      "Epoch 6: val_accuracy improved from 0.86622 to 0.87339, saving model to autosaveAdult_7_06.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7978 - loss: 1.5733 - val_accuracy: 0.8734 - val_loss: 1.4354 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8307 - loss: 1.3734  \n",
      "Epoch 6: val_accuracy improved from 0.89812 to 0.90768, saving model to autosaveP24_7_06.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8307 - loss: 1.3733 - val_accuracy: 0.9077 - val_loss: 1.1974 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9239 - loss: 1.1921  \n",
      "Epoch 6: val_accuracy improved from 0.97815 to 0.97947, saving model to autosaveP48_7_06.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9239 - loss: 1.1920 - val_accuracy: 0.9795 - val_loss: 0.9352 - learning_rate: 0.0125\n",
      "Run 7, Epoch 7/30\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8202 - loss: 1.4279  \n",
      "Epoch 7: val_accuracy did not improve from 0.87339\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8202 - loss: 1.4279 - val_accuracy: 0.8675 - val_loss: 1.3870 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8344 - loss: 1.2925  \n",
      "Epoch 7: val_accuracy did not improve from 0.90768\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8344 - loss: 1.2925 - val_accuracy: 0.9066 - val_loss: 1.1529 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9339 - loss: 1.0827  \n",
      "Epoch 7: val_accuracy did not improve from 0.97947\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9339 - loss: 1.0827 - val_accuracy: 0.9778 - val_loss: 0.8808 - learning_rate: 0.0125\n",
      "Run 7, Epoch 8/30\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8201 - loss: 1.3859  \n",
      "Epoch 8: val_accuracy did not improve from 0.87339\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8201 - loss: 1.3859 - val_accuracy: 0.8626 - val_loss: 1.3763 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8360 - loss: 1.2683  \n",
      "Epoch 8: val_accuracy did not improve from 0.90768\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8360 - loss: 1.2683 - val_accuracy: 0.9058 - val_loss: 1.1391 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9370 - loss: 1.0287  \n",
      "Epoch 8: val_accuracy improved from 0.97947 to 0.98096, saving model to autosaveP48_7_08.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9370 - loss: 1.0287 - val_accuracy: 0.9810 - val_loss: 0.8430 - learning_rate: 0.0125\n",
      "Run 7, Epoch 9/30\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8253 - loss: 1.3374  \n",
      "Epoch 9: val_accuracy improved from 0.87339 to 0.87803, saving model to autosaveAdult_7_09.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8253 - loss: 1.3374 - val_accuracy: 0.8780 - val_loss: 1.3259 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8446 - loss: 1.2239  \n",
      "Epoch 9: val_accuracy did not improve from 0.90768\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8446 - loss: 1.2239 - val_accuracy: 0.9063 - val_loss: 1.1121 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9395 - loss: 0.9981  \n",
      "Epoch 9: val_accuracy did not improve from 0.98096\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9395 - loss: 0.9980 - val_accuracy: 0.9806 - val_loss: 0.8222 - learning_rate: 0.0063\n",
      "Run 7, Epoch 10/30\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8267 - loss: 1.3150  \n",
      "Epoch 10: val_accuracy did not improve from 0.87803\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8267 - loss: 1.3150 - val_accuracy: 0.8766 - val_loss: 1.2940 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8510 - loss: 1.1824  \n",
      "Epoch 10: val_accuracy improved from 0.90768 to 0.91369, saving model to autosaveP24_7_10.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8510 - loss: 1.1824 - val_accuracy: 0.9137 - val_loss: 1.0994 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9409 - loss: 0.9670  \n",
      "Epoch 10: val_accuracy improved from 0.98096 to 0.98179, saving model to autosaveP48_7_10.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9409 - loss: 0.9671 - val_accuracy: 0.9818 - val_loss: 0.8094 - learning_rate: 0.0063\n",
      "Run 7, Epoch 11/30\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8331 - loss: 1.2837  \n",
      "Epoch 11: val_accuracy did not improve from 0.87803\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8331 - loss: 1.2837 - val_accuracy: 0.8772 - val_loss: 1.2823 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8498 - loss: 1.1740  \n",
      "Epoch 11: val_accuracy did not improve from 0.91369\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8498 - loss: 1.1740 - val_accuracy: 0.9088 - val_loss: 1.0902 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9420 - loss: 0.9583  \n",
      "Epoch 11: val_accuracy did not improve from 0.98179\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9421 - loss: 0.9583 - val_accuracy: 0.9818 - val_loss: 0.7965 - learning_rate: 0.0063\n",
      "Run 7, Epoch 12/30\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8352 - loss: 1.2682  \n",
      "Epoch 12: val_accuracy improved from 0.87803 to 0.87888, saving model to autosaveAdult_7_12.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8352 - loss: 1.2682 - val_accuracy: 0.8789 - val_loss: 1.2769 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8537 - loss: 1.1528  \n",
      "Epoch 12: val_accuracy did not improve from 0.91369\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8537 - loss: 1.1528 - val_accuracy: 0.9129 - val_loss: 1.0786 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9426 - loss: 0.9371  \n",
      "Epoch 12: val_accuracy did not improve from 0.98179\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9426 - loss: 0.9371 - val_accuracy: 0.9816 - val_loss: 0.7872 - learning_rate: 0.0031\n",
      "Run 7, Epoch 13/30\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8391 - loss: 1.2499  \n",
      "Epoch 13: val_accuracy improved from 0.87888 to 0.87951, saving model to autosaveAdult_7_13.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8391 - loss: 1.2499 - val_accuracy: 0.8795 - val_loss: 1.2622 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8525 - loss: 1.1369  \n",
      "Epoch 13: val_accuracy improved from 0.91369 to 0.91384, saving model to autosaveP24_7_13.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8525 - loss: 1.1369 - val_accuracy: 0.9138 - val_loss: 1.0738 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9461 - loss: 0.9277  \n",
      "Epoch 13: val_accuracy improved from 0.98179 to 0.98245, saving model to autosaveP48_7_13.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9461 - loss: 0.9277 - val_accuracy: 0.9825 - val_loss: 0.7782 - learning_rate: 0.0031\n",
      "Run 7, Epoch 14/30\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8337 - loss: 1.2525  \n",
      "Epoch 14: val_accuracy did not improve from 0.87951\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8337 - loss: 1.2525 - val_accuracy: 0.8795 - val_loss: 1.2548 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8546 - loss: 1.1414  \n",
      "Epoch 14: val_accuracy did not improve from 0.91384\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8546 - loss: 1.1414 - val_accuracy: 0.9132 - val_loss: 1.0660 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9470 - loss: 0.9164  \n",
      "Epoch 14: val_accuracy did not improve from 0.98245\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.9470 - loss: 0.9165 - val_accuracy: 0.9825 - val_loss: 0.7732 - learning_rate: 0.0031\n",
      "Run 7, Epoch 15/30\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8362 - loss: 1.2446  \n",
      "Epoch 15: val_accuracy did not improve from 0.87951\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8362 - loss: 1.2446 - val_accuracy: 0.8789 - val_loss: 1.2517 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8560 - loss: 1.1294  \n",
      "Epoch 15: val_accuracy improved from 0.91384 to 0.91461, saving model to autosaveP24_7_15.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8560 - loss: 1.1294 - val_accuracy: 0.9146 - val_loss: 1.0652 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9451 - loss: 0.9272  \n",
      "Epoch 15: val_accuracy improved from 0.98245 to 0.98278, saving model to autosaveP48_7_15.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9451 - loss: 0.9272 - val_accuracy: 0.9828 - val_loss: 0.7711 - learning_rate: 0.0016\n",
      "Run 7, Epoch 16/30\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8377 - loss: 1.2411  \n",
      "Epoch 16: val_accuracy improved from 0.87951 to 0.88099, saving model to autosaveAdult_7_16.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8377 - loss: 1.2411 - val_accuracy: 0.8810 - val_loss: 1.2442 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8585 - loss: 1.1200  \n",
      "Epoch 16: val_accuracy did not improve from 0.91461\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8585 - loss: 1.1200 - val_accuracy: 0.9141 - val_loss: 1.0628 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9468 - loss: 0.9142  \n",
      "Epoch 16: val_accuracy did not improve from 0.98278\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9468 - loss: 0.9142 - val_accuracy: 0.9828 - val_loss: 0.7671 - learning_rate: 0.0016\n",
      "Run 7, Epoch 17/30\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8406 - loss: 1.2393  \n",
      "Epoch 17: val_accuracy did not improve from 0.88099\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8406 - loss: 1.2393 - val_accuracy: 0.8801 - val_loss: 1.2431 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8559 - loss: 1.1231  \n",
      "Epoch 17: val_accuracy did not improve from 0.91461\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8559 - loss: 1.1231 - val_accuracy: 0.9129 - val_loss: 1.0624 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9470 - loss: 0.9148  \n",
      "Epoch 17: val_accuracy did not improve from 0.98278\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9470 - loss: 0.9148 - val_accuracy: 0.9826 - val_loss: 0.7643 - learning_rate: 0.0016\n",
      "Run 7, Epoch 18/30\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8400 - loss: 1.2199  \n",
      "Epoch 18: val_accuracy did not improve from 0.88099\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8400 - loss: 1.2199 - val_accuracy: 0.8808 - val_loss: 1.2426 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8610 - loss: 1.1180  \n",
      "Epoch 18: val_accuracy did not improve from 0.91461\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8609 - loss: 1.1180 - val_accuracy: 0.9145 - val_loss: 1.0579 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9467 - loss: 0.9074  \n",
      "Epoch 18: val_accuracy improved from 0.98278 to 0.98295, saving model to autosaveP48_7_18.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9467 - loss: 0.9074 - val_accuracy: 0.9829 - val_loss: 0.7633 - learning_rate: 7.8125e-04\n",
      "Run 7, Epoch 19/30\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8385 - loss: 1.2249  \n",
      "Epoch 19: val_accuracy did not improve from 0.88099\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8385 - loss: 1.2249 - val_accuracy: 0.8795 - val_loss: 1.2424 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8565 - loss: 1.1172  \n",
      "Epoch 19: val_accuracy did not improve from 0.91461\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8565 - loss: 1.1172 - val_accuracy: 0.9126 - val_loss: 1.0571 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9462 - loss: 0.9080  \n",
      "Epoch 19: val_accuracy did not improve from 0.98295\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9462 - loss: 0.9080 - val_accuracy: 0.9826 - val_loss: 0.7628 - learning_rate: 7.8125e-04\n",
      "Run 7, Epoch 20/30\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8409 - loss: 1.2264  \n",
      "Epoch 20: val_accuracy did not improve from 0.88099\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8409 - loss: 1.2264 - val_accuracy: 0.8806 - val_loss: 1.2395 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8597 - loss: 1.1136  \n",
      "Epoch 20: val_accuracy did not improve from 0.91461\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8597 - loss: 1.1136 - val_accuracy: 0.9135 - val_loss: 1.0559 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9460 - loss: 0.9168  \n",
      "Epoch 20: val_accuracy improved from 0.98295 to 0.98312, saving model to autosaveP48_7_20.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9460 - loss: 0.9168 - val_accuracy: 0.9831 - val_loss: 0.7612 - learning_rate: 7.8125e-04\n",
      "Run 7, Epoch 21/30\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8413 - loss: 1.2130  \n",
      "Epoch 21: val_accuracy did not improve from 0.88099\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8413 - loss: 1.2130 - val_accuracy: 0.8799 - val_loss: 1.2404 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8574 - loss: 1.1153  \n",
      "Epoch 21: val_accuracy did not improve from 0.91461\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8574 - loss: 1.1153 - val_accuracy: 0.9137 - val_loss: 1.0550 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9455 - loss: 0.9078  \n",
      "Epoch 21: val_accuracy did not improve from 0.98312\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.9078 - val_accuracy: 0.9831 - val_loss: 0.7605 - learning_rate: 3.9063e-04\n",
      "Run 7, Epoch 22/30\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8387 - loss: 1.2256  \n",
      "Epoch 22: val_accuracy did not improve from 0.88099\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8387 - loss: 1.2256 - val_accuracy: 0.8799 - val_loss: 1.2397 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8597 - loss: 1.1188  \n",
      "Epoch 22: val_accuracy did not improve from 0.91461\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8597 - loss: 1.1188 - val_accuracy: 0.9138 - val_loss: 1.0541 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9479 - loss: 0.9027  \n",
      "Epoch 22: val_accuracy did not improve from 0.98312\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9479 - loss: 0.9027 - val_accuracy: 0.9831 - val_loss: 0.7595 - learning_rate: 3.9063e-04\n",
      "Run 7, Epoch 23/30\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8400 - loss: 1.2084  \n",
      "Epoch 23: val_accuracy did not improve from 0.88099\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8400 - loss: 1.2084 - val_accuracy: 0.8801 - val_loss: 1.2394 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8549 - loss: 1.1135  \n",
      "Epoch 23: val_accuracy improved from 0.91461 to 0.91492, saving model to autosaveP24_7_23.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8549 - loss: 1.1135 - val_accuracy: 0.9149 - val_loss: 1.0535 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9489 - loss: 0.9003  \n",
      "Epoch 23: val_accuracy did not improve from 0.98312\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9489 - loss: 0.9003 - val_accuracy: 0.9828 - val_loss: 0.7593 - learning_rate: 3.9063e-04\n",
      "Run 7, Epoch 24/30\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8411 - loss: 1.1977  \n",
      "Epoch 24: val_accuracy did not improve from 0.88099\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8411 - loss: 1.1978 - val_accuracy: 0.8799 - val_loss: 1.2386 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8569 - loss: 1.1156  \n",
      "Epoch 24: val_accuracy did not improve from 0.91492\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8569 - loss: 1.1156 - val_accuracy: 0.9146 - val_loss: 1.0531 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9499 - loss: 0.8949  \n",
      "Epoch 24: val_accuracy did not improve from 0.98312\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9499 - loss: 0.8949 - val_accuracy: 0.9828 - val_loss: 0.7589 - learning_rate: 1.9531e-04\n",
      "Run 7, Epoch 25/30\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8410 - loss: 1.2141  \n",
      "Epoch 25: val_accuracy did not improve from 0.88099\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8410 - loss: 1.2142 - val_accuracy: 0.8804 - val_loss: 1.2377 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8598 - loss: 1.1018  \n",
      "Epoch 25: val_accuracy did not improve from 0.91492\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8598 - loss: 1.1018 - val_accuracy: 0.9141 - val_loss: 1.0528 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9456 - loss: 0.9098  \n",
      "Epoch 25: val_accuracy did not improve from 0.98312\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9456 - loss: 0.9097 - val_accuracy: 0.9826 - val_loss: 0.7585 - learning_rate: 1.9531e-04\n",
      "Run 7, Epoch 26/30\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8398 - loss: 1.2000  \n",
      "Epoch 26: val_accuracy did not improve from 0.88099\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8398 - loss: 1.2000 - val_accuracy: 0.8806 - val_loss: 1.2368 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8581 - loss: 1.1039  \n",
      "Epoch 26: val_accuracy did not improve from 0.91492\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8581 - loss: 1.1039 - val_accuracy: 0.9149 - val_loss: 1.0523 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9473 - loss: 0.8992  \n",
      "Epoch 26: val_accuracy did not improve from 0.98312\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9473 - loss: 0.8992 - val_accuracy: 0.9828 - val_loss: 0.7583 - learning_rate: 1.9531e-04\n",
      "Run 7, Epoch 27/30\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8352 - loss: 1.2345  \n",
      "Epoch 27: val_accuracy did not improve from 0.88099\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8352 - loss: 1.2345 - val_accuracy: 0.8804 - val_loss: 1.2369 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8560 - loss: 1.1047  \n",
      "Epoch 27: val_accuracy did not improve from 0.91492\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8560 - loss: 1.1047 - val_accuracy: 0.9143 - val_loss: 1.0523 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9497 - loss: 0.8939  \n",
      "Epoch 27: val_accuracy did not improve from 0.98312\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9497 - loss: 0.8939 - val_accuracy: 0.9828 - val_loss: 0.7580 - learning_rate: 9.7656e-05\n",
      "Run 7, Epoch 28/30\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8388 - loss: 1.2151  \n",
      "Epoch 28: val_accuracy did not improve from 0.88099\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8388 - loss: 1.2151 - val_accuracy: 0.8804 - val_loss: 1.2363 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8589 - loss: 1.1191  \n",
      "Epoch 28: val_accuracy did not improve from 0.91492\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8589 - loss: 1.1191 - val_accuracy: 0.9141 - val_loss: 1.0520 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9496 - loss: 0.9015  \n",
      "Epoch 28: val_accuracy did not improve from 0.98312\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9496 - loss: 0.9015 - val_accuracy: 0.9826 - val_loss: 0.7581 - learning_rate: 9.7656e-05\n",
      "Run 7, Epoch 29/30\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8387 - loss: 1.2104  \n",
      "Epoch 29: val_accuracy did not improve from 0.88099\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8388 - loss: 1.2104 - val_accuracy: 0.8801 - val_loss: 1.2360 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8589 - loss: 1.1119  \n",
      "Epoch 29: val_accuracy did not improve from 0.91492\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8589 - loss: 1.1119 - val_accuracy: 0.9140 - val_loss: 1.0519 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9477 - loss: 0.9022  \n",
      "Epoch 29: val_accuracy did not improve from 0.98312\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9477 - loss: 0.9022 - val_accuracy: 0.9828 - val_loss: 0.7579 - learning_rate: 9.7656e-05\n",
      "Run 7, Epoch 30/30\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8379 - loss: 1.2136  \n",
      "Epoch 30: val_accuracy did not improve from 0.88099\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8379 - loss: 1.2136 - val_accuracy: 0.8801 - val_loss: 1.2359 - learning_rate: 4.8828e-05\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8585 - loss: 1.1055  \n",
      "Epoch 30: val_accuracy did not improve from 0.91492\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8585 - loss: 1.1055 - val_accuracy: 0.9140 - val_loss: 1.0519 - learning_rate: 4.8828e-05\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9479 - loss: 0.8959  \n",
      "Epoch 30: val_accuracy did not improve from 0.98312\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9479 - loss: 0.8959 - val_accuracy: 0.9828 - val_loss: 0.7578 - learning_rate: 4.8828e-05\n",
      "Completed run 7 with 30 epochs\n",
      "autosaveAdult_7_16.keras\n",
      "\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 791us/step - accuracy: 0.8845 - loss: 1.2343\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8775 - loss: 1.2478\n",
      "autosaveP24_7_23.keras\n",
      "\u001b[1m1825/1825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 746us/step - accuracy: 0.9101 - loss: 1.0640\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 1.0758\n",
      "autosaveP48_7_20.keras\n",
      "\u001b[1m1699/1699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - accuracy: 0.9811 - loss: 0.7716\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9834 - loss: 0.7693\n",
      "New best model saved: best_model_P48_run_7.keras\n",
      "Starting run 8\n",
      "Run 8, Epoch 1/30\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7484 - loss: 1.8738  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.83224, saving model to autosaveAdult_8_01.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7483 - loss: 1.8751 - val_accuracy: 0.8322 - val_loss: 2.3524 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7706 - loss: 1.7726  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.87284, saving model to autosaveP24_8_01.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7705 - loss: 1.7733 - val_accuracy: 0.8728 - val_loss: 1.9043 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8658 - loss: 1.7104  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.94223, saving model to autosaveP48_8_01.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8657 - loss: 1.7124 - val_accuracy: 0.9422 - val_loss: 3.1029 - learning_rate: 0.0500\n",
      "Run 8, Epoch 2/30\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6716 - loss: 3.0321  \n",
      "Epoch 2: val_accuracy did not improve from 0.83224\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6716 - loss: 3.0326 - val_accuracy: 0.8171 - val_loss: 2.9645 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7222 - loss: 2.5219  \n",
      "Epoch 2: val_accuracy did not improve from 0.87284\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7222 - loss: 2.5220 - val_accuracy: 0.8710 - val_loss: 1.9803 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7615 - loss: 4.0377  \n",
      "Epoch 2: val_accuracy improved from 0.94223 to 0.94620, saving model to autosaveP48_8_02.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7615 - loss: 4.0375 - val_accuracy: 0.9462 - val_loss: 2.7967 - learning_rate: 0.0500\n",
      "Run 8, Epoch 3/30\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7091 - loss: 2.8684  \n",
      "Epoch 3: val_accuracy improved from 0.83224 to 0.86347, saving model to autosaveAdult_8_03.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7092 - loss: 2.8677 - val_accuracy: 0.8635 - val_loss: 1.9689 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7732 - loss: 2.0788  \n",
      "Epoch 3: val_accuracy improved from 0.87284 to 0.88502, saving model to autosaveP24_8_03.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7732 - loss: 2.0785 - val_accuracy: 0.8850 - val_loss: 1.4482 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8349 - loss: 2.9408  \n",
      "Epoch 3: val_accuracy improved from 0.94620 to 0.96656, saving model to autosaveP48_8_03.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8349 - loss: 2.9399 - val_accuracy: 0.9666 - val_loss: 1.6379 - learning_rate: 0.0250\n",
      "Run 8, Epoch 4/30\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7785 - loss: 1.9605  \n",
      "Epoch 4: val_accuracy improved from 0.86347 to 0.87297, saving model to autosaveAdult_8_04.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7785 - loss: 1.9604 - val_accuracy: 0.8730 - val_loss: 1.6389 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8082 - loss: 1.6039  \n",
      "Epoch 4: val_accuracy improved from 0.88502 to 0.89303, saving model to autosaveP24_8_04.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8083 - loss: 1.6039 - val_accuracy: 0.8930 - val_loss: 1.3191 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9026 - loss: 1.6933  \n",
      "Epoch 4: val_accuracy did not improve from 0.96656\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9026 - loss: 1.6930 - val_accuracy: 0.9618 - val_loss: 1.1817 - learning_rate: 0.0250\n",
      "Run 8, Epoch 5/30\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7955 - loss: 1.6903  \n",
      "Epoch 5: val_accuracy did not improve from 0.87297\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7954 - loss: 1.6903 - val_accuracy: 0.8614 - val_loss: 1.5569 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8128 - loss: 1.4850  \n",
      "Epoch 5: val_accuracy improved from 0.89303 to 0.90074, saving model to autosaveP24_8_05.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8128 - loss: 1.4850 - val_accuracy: 0.9007 - val_loss: 1.2678 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9164 - loss: 1.3261  \n",
      "Epoch 5: val_accuracy improved from 0.96656 to 0.97633, saving model to autosaveP48_8_05.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9164 - loss: 1.3260 - val_accuracy: 0.9763 - val_loss: 1.0119 - learning_rate: 0.0250\n",
      "Run 8, Epoch 6/30\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8061 - loss: 1.5386  \n",
      "Epoch 6: val_accuracy did not improve from 0.87297\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8061 - loss: 1.5385 - val_accuracy: 0.8681 - val_loss: 1.4196 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8279 - loss: 1.3690  \n",
      "Epoch 6: val_accuracy improved from 0.90074 to 0.90459, saving model to autosaveP24_8_06.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8279 - loss: 1.3689 - val_accuracy: 0.9046 - val_loss: 1.1805 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9259 - loss: 1.1667  \n",
      "Epoch 6: val_accuracy improved from 0.97633 to 0.97964, saving model to autosaveP48_8_06.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9259 - loss: 1.1666 - val_accuracy: 0.9796 - val_loss: 0.9199 - learning_rate: 0.0125\n",
      "Run 8, Epoch 7/30\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8190 - loss: 1.4354  \n",
      "Epoch 7: val_accuracy improved from 0.87297 to 0.87466, saving model to autosaveAdult_8_07.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8190 - loss: 1.4354 - val_accuracy: 0.8747 - val_loss: 1.3631 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8387 - loss: 1.2763  \n",
      "Epoch 7: val_accuracy improved from 0.90459 to 0.90521, saving model to autosaveP24_8_07.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8387 - loss: 1.2763 - val_accuracy: 0.9052 - val_loss: 1.1534 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9351 - loss: 1.0741  \n",
      "Epoch 7: val_accuracy improved from 0.97964 to 0.97997, saving model to autosaveP48_8_07.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9351 - loss: 1.0740 - val_accuracy: 0.9800 - val_loss: 0.8655 - learning_rate: 0.0125\n",
      "Run 8, Epoch 8/30\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8244 - loss: 1.3766  \n",
      "Epoch 8: val_accuracy improved from 0.87466 to 0.87508, saving model to autosaveAdult_8_08.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8244 - loss: 1.3767 - val_accuracy: 0.8751 - val_loss: 1.3402 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8401 - loss: 1.2474  \n",
      "Epoch 8: val_accuracy did not improve from 0.90521\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8401 - loss: 1.2474 - val_accuracy: 0.8997 - val_loss: 1.1419 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9364 - loss: 1.0307  \n",
      "Epoch 8: val_accuracy improved from 0.97997 to 0.98146, saving model to autosaveP48_8_08.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9364 - loss: 1.0307 - val_accuracy: 0.9815 - val_loss: 0.8363 - learning_rate: 0.0125\n",
      "Run 8, Epoch 9/30\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8272 - loss: 1.3467  \n",
      "Epoch 9: val_accuracy improved from 0.87508 to 0.87656, saving model to autosaveAdult_8_09.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8272 - loss: 1.3466 - val_accuracy: 0.8766 - val_loss: 1.3052 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8446 - loss: 1.2130  \n",
      "Epoch 9: val_accuracy improved from 0.90521 to 0.90999, saving model to autosaveP24_8_09.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8446 - loss: 1.2130 - val_accuracy: 0.9100 - val_loss: 1.1067 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9425 - loss: 0.9840  \n",
      "Epoch 9: val_accuracy improved from 0.98146 to 0.98345, saving model to autosaveP48_8_09.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9425 - loss: 0.9840 - val_accuracy: 0.9834 - val_loss: 0.8132 - learning_rate: 0.0063\n",
      "Run 8, Epoch 10/30\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8323 - loss: 1.3090  \n",
      "Epoch 10: val_accuracy improved from 0.87656 to 0.87761, saving model to autosaveAdult_8_10.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8323 - loss: 1.3090 - val_accuracy: 0.8776 - val_loss: 1.2972 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8507 - loss: 1.1782  \n",
      "Epoch 10: val_accuracy did not improve from 0.90999\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8507 - loss: 1.1782 - val_accuracy: 0.9094 - val_loss: 1.0978 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9444 - loss: 0.9617  \n",
      "Epoch 10: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9444 - loss: 0.9617 - val_accuracy: 0.9826 - val_loss: 0.7991 - learning_rate: 0.0063\n",
      "Run 8, Epoch 11/30\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8324 - loss: 1.2764  \n",
      "Epoch 11: val_accuracy did not improve from 0.87761\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8324 - loss: 1.2764 - val_accuracy: 0.8768 - val_loss: 1.2754 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8486 - loss: 1.1813  \n",
      "Epoch 11: val_accuracy did not improve from 0.90999\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8487 - loss: 1.1813 - val_accuracy: 0.9088 - val_loss: 1.0883 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9447 - loss: 0.9472  \n",
      "Epoch 11: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9447 - loss: 0.9472 - val_accuracy: 0.9823 - val_loss: 0.7863 - learning_rate: 0.0063\n",
      "Run 8, Epoch 12/30\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8338 - loss: 1.2667  \n",
      "Epoch 12: val_accuracy did not improve from 0.87761\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8338 - loss: 1.2667 - val_accuracy: 0.8772 - val_loss: 1.2660 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8519 - loss: 1.1536  \n",
      "Epoch 12: val_accuracy did not improve from 0.90999\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8519 - loss: 1.1536 - val_accuracy: 0.9084 - val_loss: 1.0793 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9461 - loss: 0.9293  \n",
      "Epoch 12: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9461 - loss: 0.9293 - val_accuracy: 0.9829 - val_loss: 0.7811 - learning_rate: 0.0031\n",
      "Run 8, Epoch 13/30\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8348 - loss: 1.2677  \n",
      "Epoch 13: val_accuracy improved from 0.87761 to 0.87803, saving model to autosaveAdult_8_13.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8348 - loss: 1.2677 - val_accuracy: 0.8780 - val_loss: 1.2568 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8541 - loss: 1.1451  \n",
      "Epoch 13: val_accuracy improved from 0.90999 to 0.91014, saving model to autosaveP24_8_13.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8541 - loss: 1.1451 - val_accuracy: 0.9101 - val_loss: 1.0727 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9456 - loss: 0.9316  \n",
      "Epoch 13: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9456 - loss: 0.9316 - val_accuracy: 0.9826 - val_loss: 0.7742 - learning_rate: 0.0031\n",
      "Run 8, Epoch 14/30\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8400 - loss: 1.2595  \n",
      "Epoch 14: val_accuracy did not improve from 0.87803\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8400 - loss: 1.2595 - val_accuracy: 0.8772 - val_loss: 1.2521 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8554 - loss: 1.1294  \n",
      "Epoch 14: val_accuracy did not improve from 0.91014\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8554 - loss: 1.1294 - val_accuracy: 0.9074 - val_loss: 1.0666 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9455 - loss: 0.9213  \n",
      "Epoch 14: val_accuracy improved from 0.98345 to 0.98361, saving model to autosaveP48_8_14.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.9213 - val_accuracy: 0.9836 - val_loss: 0.7722 - learning_rate: 0.0031\n",
      "Run 8, Epoch 15/30\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8410 - loss: 1.2298  \n",
      "Epoch 15: val_accuracy improved from 0.87803 to 0.87930, saving model to autosaveAdult_8_15.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8410 - loss: 1.2298 - val_accuracy: 0.8793 - val_loss: 1.2458 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8553 - loss: 1.1279  \n",
      "Epoch 15: val_accuracy improved from 0.91014 to 0.91045, saving model to autosaveP24_8_15.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8553 - loss: 1.1279 - val_accuracy: 0.9105 - val_loss: 1.0641 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9438 - loss: 0.9206  \n",
      "Epoch 15: val_accuracy improved from 0.98361 to 0.98378, saving model to autosaveP48_8_15.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9438 - loss: 0.9206 - val_accuracy: 0.9838 - val_loss: 0.7659 - learning_rate: 0.0016\n",
      "Run 8, Epoch 16/30\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8358 - loss: 1.2397  \n",
      "Epoch 16: val_accuracy did not improve from 0.87930\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8358 - loss: 1.2397 - val_accuracy: 0.8789 - val_loss: 1.2452 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8575 - loss: 1.1213  \n",
      "Epoch 16: val_accuracy improved from 0.91045 to 0.91076, saving model to autosaveP24_8_16.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8575 - loss: 1.1213 - val_accuracy: 0.9108 - val_loss: 1.0623 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9470 - loss: 0.9118  \n",
      "Epoch 16: val_accuracy did not improve from 0.98378\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9470 - loss: 0.9118 - val_accuracy: 0.9836 - val_loss: 0.7648 - learning_rate: 0.0016\n",
      "Run 8, Epoch 17/30\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8364 - loss: 1.2308  \n",
      "Epoch 17: val_accuracy improved from 0.87930 to 0.87972, saving model to autosaveAdult_8_17.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8364 - loss: 1.2308 - val_accuracy: 0.8797 - val_loss: 1.2393 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8521 - loss: 1.1238  \n",
      "Epoch 17: val_accuracy improved from 0.91076 to 0.91091, saving model to autosaveP24_8_17.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.8521 - loss: 1.1238 - val_accuracy: 0.9109 - val_loss: 1.0601 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9469 - loss: 0.9042  \n",
      "Epoch 17: val_accuracy did not improve from 0.98378\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9469 - loss: 0.9042 - val_accuracy: 0.9833 - val_loss: 0.7612 - learning_rate: 0.0016\n",
      "Run 8, Epoch 18/30\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8405 - loss: 1.2125  \n",
      "Epoch 18: val_accuracy did not improve from 0.87972\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8405 - loss: 1.2126 - val_accuracy: 0.8793 - val_loss: 1.2417 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8559 - loss: 1.1191  \n",
      "Epoch 18: val_accuracy improved from 0.91091 to 0.91153, saving model to autosaveP24_8_18.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8559 - loss: 1.1191 - val_accuracy: 0.9115 - val_loss: 1.0589 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9455 - loss: 0.9033  \n",
      "Epoch 18: val_accuracy did not improve from 0.98378\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.9033 - val_accuracy: 0.9834 - val_loss: 0.7604 - learning_rate: 7.8125e-04\n",
      "Run 8, Epoch 19/30\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8377 - loss: 1.2224  \n",
      "Epoch 19: val_accuracy did not improve from 0.87972\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8377 - loss: 1.2224 - val_accuracy: 0.8780 - val_loss: 1.2385 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8553 - loss: 1.1141  \n",
      "Epoch 19: val_accuracy did not improve from 0.91153\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8553 - loss: 1.1141 - val_accuracy: 0.9108 - val_loss: 1.0575 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9467 - loss: 0.8974  \n",
      "Epoch 19: val_accuracy did not improve from 0.98378\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9467 - loss: 0.8974 - val_accuracy: 0.9836 - val_loss: 0.7580 - learning_rate: 7.8125e-04\n",
      "Run 8, Epoch 20/30\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8416 - loss: 1.2125  \n",
      "Epoch 20: val_accuracy did not improve from 0.87972\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8416 - loss: 1.2125 - val_accuracy: 0.8772 - val_loss: 1.2349 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8566 - loss: 1.1164  \n",
      "Epoch 20: val_accuracy did not improve from 0.91153\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8566 - loss: 1.1164 - val_accuracy: 0.9114 - val_loss: 1.0564 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9473 - loss: 0.8943  \n",
      "Epoch 20: val_accuracy did not improve from 0.98378\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9473 - loss: 0.8944 - val_accuracy: 0.9833 - val_loss: 0.7583 - learning_rate: 7.8125e-04\n",
      "Run 8, Epoch 21/30\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8438 - loss: 1.2145  \n",
      "Epoch 21: val_accuracy did not improve from 0.87972\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8438 - loss: 1.2146 - val_accuracy: 0.8787 - val_loss: 1.2351 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8557 - loss: 1.1185  \n",
      "Epoch 21: val_accuracy did not improve from 0.91153\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8557 - loss: 1.1185 - val_accuracy: 0.9105 - val_loss: 1.0553 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9480 - loss: 0.8993  \n",
      "Epoch 21: val_accuracy did not improve from 0.98378\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9480 - loss: 0.8993 - val_accuracy: 0.9836 - val_loss: 0.7564 - learning_rate: 3.9063e-04\n",
      "Run 8, Epoch 22/30\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8401 - loss: 1.2186  \n",
      "Epoch 22: val_accuracy did not improve from 0.87972\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8401 - loss: 1.2186 - val_accuracy: 0.8785 - val_loss: 1.2344 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8569 - loss: 1.1157  \n",
      "Epoch 22: val_accuracy did not improve from 0.91153\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8569 - loss: 1.1157 - val_accuracy: 0.9112 - val_loss: 1.0543 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9492 - loss: 0.8930  \n",
      "Epoch 22: val_accuracy improved from 0.98378 to 0.98394, saving model to autosaveP48_8_22.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9492 - loss: 0.8930 - val_accuracy: 0.9839 - val_loss: 0.7562 - learning_rate: 3.9063e-04\n",
      "Run 8, Epoch 23/30\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8422 - loss: 1.2079  \n",
      "Epoch 23: val_accuracy did not improve from 0.87972\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8422 - loss: 1.2079 - val_accuracy: 0.8780 - val_loss: 1.2336 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8574 - loss: 1.1103  \n",
      "Epoch 23: val_accuracy did not improve from 0.91153\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8574 - loss: 1.1103 - val_accuracy: 0.9109 - val_loss: 1.0537 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9477 - loss: 0.8967  \n",
      "Epoch 23: val_accuracy did not improve from 0.98394\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9477 - loss: 0.8967 - val_accuracy: 0.9838 - val_loss: 0.7559 - learning_rate: 3.9063e-04\n",
      "Run 8, Epoch 24/30\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8423 - loss: 1.2067  \n",
      "Epoch 24: val_accuracy did not improve from 0.87972\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8423 - loss: 1.2067 - val_accuracy: 0.8793 - val_loss: 1.2326 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8581 - loss: 1.1135  \n",
      "Epoch 24: val_accuracy did not improve from 0.91153\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8581 - loss: 1.1135 - val_accuracy: 0.9109 - val_loss: 1.0533 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9491 - loss: 0.8883  \n",
      "Epoch 24: val_accuracy did not improve from 0.98394\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.8883 - val_accuracy: 0.9839 - val_loss: 0.7553 - learning_rate: 1.9531e-04\n",
      "Run 8, Epoch 25/30\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8408 - loss: 1.2137  \n",
      "Epoch 25: val_accuracy did not improve from 0.87972\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8408 - loss: 1.2137 - val_accuracy: 0.8795 - val_loss: 1.2329 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8590 - loss: 1.1028  \n",
      "Epoch 25: val_accuracy improved from 0.91153 to 0.91184, saving model to autosaveP24_8_25.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8590 - loss: 1.1028 - val_accuracy: 0.9118 - val_loss: 1.0527 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9481 - loss: 0.8932  \n",
      "Epoch 25: val_accuracy did not improve from 0.98394\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9481 - loss: 0.8932 - val_accuracy: 0.9839 - val_loss: 0.7550 - learning_rate: 1.9531e-04\n",
      "Run 8, Epoch 26/30\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8420 - loss: 1.2044  \n",
      "Epoch 26: val_accuracy did not improve from 0.87972\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8420 - loss: 1.2044 - val_accuracy: 0.8795 - val_loss: 1.2328 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8576 - loss: 1.1160  \n",
      "Epoch 26: val_accuracy did not improve from 0.91184\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8576 - loss: 1.1160 - val_accuracy: 0.9115 - val_loss: 1.0526 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9487 - loss: 0.8979  \n",
      "Epoch 26: val_accuracy improved from 0.98394 to 0.98411, saving model to autosaveP48_8_26.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9487 - loss: 0.8979 - val_accuracy: 0.9841 - val_loss: 0.7546 - learning_rate: 1.9531e-04\n",
      "Run 8, Epoch 27/30\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8431 - loss: 1.2023  \n",
      "Epoch 27: val_accuracy did not improve from 0.87972\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8431 - loss: 1.2023 - val_accuracy: 0.8797 - val_loss: 1.2323 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8565 - loss: 1.1169  \n",
      "Epoch 27: val_accuracy did not improve from 0.91184\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8565 - loss: 1.1169 - val_accuracy: 0.9114 - val_loss: 1.0525 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9492 - loss: 0.8908  \n",
      "Epoch 27: val_accuracy did not improve from 0.98411\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9492 - loss: 0.8908 - val_accuracy: 0.9841 - val_loss: 0.7543 - learning_rate: 9.7656e-05\n",
      "Run 8, Epoch 28/30\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8396 - loss: 1.2162  \n",
      "Epoch 28: val_accuracy did not improve from 0.87972\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8396 - loss: 1.2162 - val_accuracy: 0.8793 - val_loss: 1.2321 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8580 - loss: 1.1100  \n",
      "Epoch 28: val_accuracy did not improve from 0.91184\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8580 - loss: 1.1100 - val_accuracy: 0.9115 - val_loss: 1.0525 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9498 - loss: 0.8923  \n",
      "Epoch 28: val_accuracy improved from 0.98411 to 0.98427, saving model to autosaveP48_8_28.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9498 - loss: 0.8923 - val_accuracy: 0.9843 - val_loss: 0.7541 - learning_rate: 9.7656e-05\n",
      "Run 8, Epoch 29/30\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8398 - loss: 1.2038  \n",
      "Epoch 29: val_accuracy did not improve from 0.87972\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8398 - loss: 1.2038 - val_accuracy: 0.8793 - val_loss: 1.2320 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8570 - loss: 1.1095  \n",
      "Epoch 29: val_accuracy did not improve from 0.91184\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8570 - loss: 1.1095 - val_accuracy: 0.9114 - val_loss: 1.0522 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9477 - loss: 0.8940  \n",
      "Epoch 29: val_accuracy did not improve from 0.98427\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9477 - loss: 0.8940 - val_accuracy: 0.9843 - val_loss: 0.7539 - learning_rate: 9.7656e-05\n",
      "Run 8, Epoch 30/30\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8371 - loss: 1.2094  \n",
      "Epoch 30: val_accuracy did not improve from 0.87972\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8371 - loss: 1.2094 - val_accuracy: 0.8793 - val_loss: 1.2318 - learning_rate: 4.8828e-05\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8586 - loss: 1.1139  \n",
      "Epoch 30: val_accuracy did not improve from 0.91184\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8586 - loss: 1.1139 - val_accuracy: 0.9115 - val_loss: 1.0522 - learning_rate: 4.8828e-05\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9470 - loss: 0.8945  \n",
      "Epoch 30: val_accuracy did not improve from 0.98427\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9470 - loss: 0.8945 - val_accuracy: 0.9843 - val_loss: 0.7538 - learning_rate: 4.8828e-05\n",
      "Completed run 8 with 30 epochs\n",
      "autosaveAdult_8_17.keras\n",
      "\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 800us/step - accuracy: 0.8846 - loss: 1.2296\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8791 - loss: 1.2410\n",
      "autosaveP24_8_25.keras\n",
      "\u001b[1m1825/1825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 753us/step - accuracy: 0.9094 - loss: 1.0631\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9105 - loss: 1.0745\n",
      "autosaveP48_8_28.keras\n",
      "\u001b[1m1699/1699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - accuracy: 0.9821 - loss: 0.7639\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9835 - loss: 0.7626\n",
      "New best model saved: best_model_P48_run_8.keras\n",
      "Starting run 9\n",
      "Run 9, Epoch 1/30\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7641 - loss: 1.7711  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.83878, saving model to autosaveAdult_9_01.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7640 - loss: 1.7726 - val_accuracy: 0.8388 - val_loss: 2.4006 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7790 - loss: 1.7085  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.87392, saving model to autosaveP24_9_01.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7789 - loss: 1.7093 - val_accuracy: 0.8739 - val_loss: 1.9657 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8653 - loss: 1.6480  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.94173, saving model to autosaveP48_9_01.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8652 - loss: 1.6494 - val_accuracy: 0.9417 - val_loss: 2.3985 - learning_rate: 0.0500\n",
      "Run 9, Epoch 2/30\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6670 - loss: 3.1023  \n",
      "Epoch 2: val_accuracy did not improve from 0.83878\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6670 - loss: 3.1029 - val_accuracy: 0.8016 - val_loss: 3.0891 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7303 - loss: 2.4669  \n",
      "Epoch 2: val_accuracy did not improve from 0.87392\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7303 - loss: 2.4670 - val_accuracy: 0.8505 - val_loss: 2.0499 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7855 - loss: 3.2458  \n",
      "Epoch 2: val_accuracy did not improve from 0.94173\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7854 - loss: 3.2467 - val_accuracy: 0.9162 - val_loss: 3.4486 - learning_rate: 0.0500\n",
      "Run 9, Epoch 3/30\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6975 - loss: 3.0077  \n",
      "Epoch 3: val_accuracy improved from 0.83878 to 0.85229, saving model to autosaveAdult_9_03.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6976 - loss: 3.0068 - val_accuracy: 0.8523 - val_loss: 2.0078 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7658 - loss: 2.2021  \n",
      "Epoch 3: val_accuracy improved from 0.87392 to 0.89149, saving model to autosaveP24_9_03.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7658 - loss: 2.2016 - val_accuracy: 0.8915 - val_loss: 1.4753 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8147 - loss: 3.4501  \n",
      "Epoch 3: val_accuracy improved from 0.94173 to 0.96474, saving model to autosaveP48_9_03.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8147 - loss: 3.4490 - val_accuracy: 0.9647 - val_loss: 1.7952 - learning_rate: 0.0250\n",
      "Run 9, Epoch 4/30\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7685 - loss: 2.0443  \n",
      "Epoch 4: val_accuracy improved from 0.85229 to 0.85820, saving model to autosaveAdult_9_04.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7685 - loss: 2.0441 - val_accuracy: 0.8582 - val_loss: 1.6650 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8098 - loss: 1.5888  \n",
      "Epoch 4: val_accuracy did not improve from 0.89149\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8098 - loss: 1.5888 - val_accuracy: 0.8815 - val_loss: 1.3359 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8957 - loss: 1.8564  \n",
      "Epoch 4: val_accuracy improved from 0.96474 to 0.97633, saving model to autosaveP48_9_04.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8957 - loss: 1.8561 - val_accuracy: 0.9763 - val_loss: 1.2127 - learning_rate: 0.0250\n",
      "Run 9, Epoch 5/30\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7953 - loss: 1.7232  \n",
      "Epoch 5: val_accuracy did not improve from 0.85820\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7953 - loss: 1.7232 - val_accuracy: 0.8576 - val_loss: 1.5670 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8169 - loss: 1.4603  \n",
      "Epoch 5: val_accuracy improved from 0.89149 to 0.89781, saving model to autosaveP24_9_05.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8169 - loss: 1.4604 - val_accuracy: 0.8978 - val_loss: 1.2734 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9135 - loss: 1.3695  \n",
      "Epoch 5: val_accuracy did not improve from 0.97633\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9135 - loss: 1.3695 - val_accuracy: 0.9699 - val_loss: 1.0431 - learning_rate: 0.0250\n",
      "Run 9, Epoch 6/30\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7973 - loss: 1.5890  \n",
      "Epoch 6: val_accuracy improved from 0.85820 to 0.86917, saving model to autosaveAdult_9_06.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7973 - loss: 1.5889 - val_accuracy: 0.8692 - val_loss: 1.4490 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8311 - loss: 1.3766  \n",
      "Epoch 6: val_accuracy improved from 0.89781 to 0.90413, saving model to autosaveP24_9_06.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8311 - loss: 1.3766 - val_accuracy: 0.9041 - val_loss: 1.1878 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9267 - loss: 1.1861  \n",
      "Epoch 6: val_accuracy improved from 0.97633 to 0.97997, saving model to autosaveP48_9_06.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9267 - loss: 1.1861 - val_accuracy: 0.9800 - val_loss: 0.9266 - learning_rate: 0.0125\n",
      "Run 9, Epoch 7/30\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8153 - loss: 1.4482  \n",
      "Epoch 7: val_accuracy did not improve from 0.86917\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8153 - loss: 1.4482 - val_accuracy: 0.8692 - val_loss: 1.3838 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8376 - loss: 1.2686  \n",
      "Epoch 7: val_accuracy improved from 0.90413 to 0.90613, saving model to autosaveP24_9_07.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8376 - loss: 1.2686 - val_accuracy: 0.9061 - val_loss: 1.1470 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9336 - loss: 1.0794  \n",
      "Epoch 7: val_accuracy improved from 0.97997 to 0.98030, saving model to autosaveP48_9_07.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9336 - loss: 1.0794 - val_accuracy: 0.9803 - val_loss: 0.8772 - learning_rate: 0.0125\n",
      "Run 9, Epoch 8/30\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8198 - loss: 1.3827  \n",
      "Epoch 8: val_accuracy improved from 0.86917 to 0.87149, saving model to autosaveAdult_9_08.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8198 - loss: 1.3827 - val_accuracy: 0.8715 - val_loss: 1.3586 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8386 - loss: 1.2607  \n",
      "Epoch 8: val_accuracy did not improve from 0.90613\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8386 - loss: 1.2607 - val_accuracy: 0.9055 - val_loss: 1.1387 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9359 - loss: 1.0454  \n",
      "Epoch 8: val_accuracy did not improve from 0.98030\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9359 - loss: 1.0454 - val_accuracy: 0.9801 - val_loss: 0.8433 - learning_rate: 0.0125\n",
      "Run 9, Epoch 9/30\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8261 - loss: 1.3396  \n",
      "Epoch 9: val_accuracy improved from 0.87149 to 0.87719, saving model to autosaveAdult_9_09.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8261 - loss: 1.3397 - val_accuracy: 0.8772 - val_loss: 1.3168 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8467 - loss: 1.2129  \n",
      "Epoch 9: val_accuracy improved from 0.90613 to 0.90922, saving model to autosaveP24_9_09.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8467 - loss: 1.2129 - val_accuracy: 0.9092 - val_loss: 1.1121 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9399 - loss: 1.0007  \n",
      "Epoch 9: val_accuracy improved from 0.98030 to 0.98146, saving model to autosaveP48_9_09.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9399 - loss: 1.0007 - val_accuracy: 0.9815 - val_loss: 0.8189 - learning_rate: 0.0063\n",
      "Run 9, Epoch 10/30\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8246 - loss: 1.3306  \n",
      "Epoch 10: val_accuracy improved from 0.87719 to 0.87740, saving model to autosaveAdult_9_10.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8247 - loss: 1.3306 - val_accuracy: 0.8774 - val_loss: 1.2939 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8505 - loss: 1.1885  \n",
      "Epoch 10: val_accuracy improved from 0.90922 to 0.90999, saving model to autosaveP24_9_10.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8505 - loss: 1.1885 - val_accuracy: 0.9100 - val_loss: 1.0915 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9432 - loss: 0.9657  \n",
      "Epoch 10: val_accuracy improved from 0.98146 to 0.98196, saving model to autosaveP48_9_10.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9432 - loss: 0.9657 - val_accuracy: 0.9820 - val_loss: 0.7997 - learning_rate: 0.0063\n",
      "Run 9, Epoch 11/30\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8314 - loss: 1.2905  \n",
      "Epoch 11: val_accuracy did not improve from 0.87740\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8314 - loss: 1.2905 - val_accuracy: 0.8766 - val_loss: 1.2928 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8518 - loss: 1.1737  \n",
      "Epoch 11: val_accuracy improved from 0.90999 to 0.91091, saving model to autosaveP24_9_11.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8518 - loss: 1.1737 - val_accuracy: 0.9109 - val_loss: 1.0915 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9421 - loss: 0.9520  \n",
      "Epoch 11: val_accuracy did not improve from 0.98196\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9421 - loss: 0.9520 - val_accuracy: 0.9816 - val_loss: 0.7926 - learning_rate: 0.0063\n",
      "Run 9, Epoch 12/30\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8330 - loss: 1.2684  \n",
      "Epoch 12: val_accuracy improved from 0.87740 to 0.87888, saving model to autosaveAdult_9_12.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8330 - loss: 1.2683 - val_accuracy: 0.8789 - val_loss: 1.2753 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8498 - loss: 1.1612  \n",
      "Epoch 12: val_accuracy did not improve from 0.91091\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8498 - loss: 1.1612 - val_accuracy: 0.9081 - val_loss: 1.0799 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9441 - loss: 0.9382  \n",
      "Epoch 12: val_accuracy improved from 0.98196 to 0.98262, saving model to autosaveP48_9_12.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9441 - loss: 0.9382 - val_accuracy: 0.9826 - val_loss: 0.7843 - learning_rate: 0.0031\n",
      "Run 9, Epoch 13/30\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8366 - loss: 1.2587  \n",
      "Epoch 13: val_accuracy did not improve from 0.87888\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8366 - loss: 1.2587 - val_accuracy: 0.8757 - val_loss: 1.2726 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8529 - loss: 1.1452  \n",
      "Epoch 13: val_accuracy did not improve from 0.91091\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8529 - loss: 1.1452 - val_accuracy: 0.9103 - val_loss: 1.0759 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9460 - loss: 0.9260  \n",
      "Epoch 13: val_accuracy did not improve from 0.98262\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9460 - loss: 0.9260 - val_accuracy: 0.9825 - val_loss: 0.7774 - learning_rate: 0.0031\n",
      "Run 9, Epoch 14/30\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8375 - loss: 1.2358  \n",
      "Epoch 14: val_accuracy did not improve from 0.87888\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8375 - loss: 1.2359 - val_accuracy: 0.8768 - val_loss: 1.2631 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8552 - loss: 1.1334  \n",
      "Epoch 14: val_accuracy improved from 0.91091 to 0.91168, saving model to autosaveP24_9_14.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8552 - loss: 1.1335 - val_accuracy: 0.9117 - val_loss: 1.0699 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9480 - loss: 0.9170  \n",
      "Epoch 14: val_accuracy did not improve from 0.98262\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9480 - loss: 0.9170 - val_accuracy: 0.9825 - val_loss: 0.7707 - learning_rate: 0.0031\n",
      "Run 9, Epoch 15/30\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8346 - loss: 1.2401  \n",
      "Epoch 15: val_accuracy did not improve from 0.87888\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8346 - loss: 1.2402 - val_accuracy: 0.8780 - val_loss: 1.2590 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8544 - loss: 1.1320  \n",
      "Epoch 15: val_accuracy did not improve from 0.91168\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8544 - loss: 1.1320 - val_accuracy: 0.9109 - val_loss: 1.0661 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9472 - loss: 0.9149  \n",
      "Epoch 15: val_accuracy improved from 0.98262 to 0.98278, saving model to autosaveP48_9_15.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9472 - loss: 0.9149 - val_accuracy: 0.9828 - val_loss: 0.7672 - learning_rate: 0.0016\n",
      "Run 9, Epoch 16/30\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8420 - loss: 1.2233  \n",
      "Epoch 16: val_accuracy did not improve from 0.87888\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8420 - loss: 1.2234 - val_accuracy: 0.8789 - val_loss: 1.2541 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8564 - loss: 1.1215  \n",
      "Epoch 16: val_accuracy did not improve from 0.91168\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8564 - loss: 1.1215 - val_accuracy: 0.9101 - val_loss: 1.0646 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9478 - loss: 0.9129  \n",
      "Epoch 16: val_accuracy did not improve from 0.98278\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9478 - loss: 0.9129 - val_accuracy: 0.9826 - val_loss: 0.7646 - learning_rate: 0.0016\n",
      "Run 9, Epoch 17/30\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8381 - loss: 1.2259  \n",
      "Epoch 17: val_accuracy improved from 0.87888 to 0.87993, saving model to autosaveAdult_9_17.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8380 - loss: 1.2259 - val_accuracy: 0.8799 - val_loss: 1.2486 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8547 - loss: 1.1143  \n",
      "Epoch 17: val_accuracy improved from 0.91168 to 0.91215, saving model to autosaveP24_9_17.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8547 - loss: 1.1143 - val_accuracy: 0.9121 - val_loss: 1.0595 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9466 - loss: 0.9098  \n",
      "Epoch 17: val_accuracy did not improve from 0.98278\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9466 - loss: 0.9098 - val_accuracy: 0.9828 - val_loss: 0.7613 - learning_rate: 0.0016\n",
      "Run 9, Epoch 18/30\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8354 - loss: 1.2305  \n",
      "Epoch 18: val_accuracy improved from 0.87993 to 0.88078, saving model to autosaveAdult_9_18.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8354 - loss: 1.2304 - val_accuracy: 0.8808 - val_loss: 1.2462 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8561 - loss: 1.1200  \n",
      "Epoch 18: val_accuracy did not improve from 0.91215\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8561 - loss: 1.1200 - val_accuracy: 0.9103 - val_loss: 1.0588 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9472 - loss: 0.9019  \n",
      "Epoch 18: val_accuracy did not improve from 0.98278\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9472 - loss: 0.9019 - val_accuracy: 0.9826 - val_loss: 0.7624 - learning_rate: 7.8125e-04\n",
      "Run 9, Epoch 19/30\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8397 - loss: 1.2294  \n",
      "Epoch 19: val_accuracy did not improve from 0.88078\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8397 - loss: 1.2294 - val_accuracy: 0.8793 - val_loss: 1.2447 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8584 - loss: 1.1127  \n",
      "Epoch 19: val_accuracy did not improve from 0.91215\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8584 - loss: 1.1127 - val_accuracy: 0.9112 - val_loss: 1.0565 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9474 - loss: 0.9102  \n",
      "Epoch 19: val_accuracy improved from 0.98278 to 0.98295, saving model to autosaveP48_9_19.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9474 - loss: 0.9102 - val_accuracy: 0.9829 - val_loss: 0.7596 - learning_rate: 7.8125e-04\n",
      "Run 9, Epoch 20/30\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8385 - loss: 1.2235  \n",
      "Epoch 20: val_accuracy did not improve from 0.88078\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8385 - loss: 1.2235 - val_accuracy: 0.8795 - val_loss: 1.2417 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8585 - loss: 1.1164  \n",
      "Epoch 20: val_accuracy improved from 0.91215 to 0.91230, saving model to autosaveP24_9_20.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8585 - loss: 1.1164 - val_accuracy: 0.9123 - val_loss: 1.0564 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9475 - loss: 0.9026  \n",
      "Epoch 20: val_accuracy did not improve from 0.98295\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9475 - loss: 0.9026 - val_accuracy: 0.9828 - val_loss: 0.7585 - learning_rate: 7.8125e-04\n",
      "Run 9, Epoch 21/30\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8370 - loss: 1.2248  \n",
      "Epoch 21: val_accuracy did not improve from 0.88078\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8370 - loss: 1.2248 - val_accuracy: 0.8793 - val_loss: 1.2415 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8588 - loss: 1.1054  \n",
      "Epoch 21: val_accuracy did not improve from 0.91230\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8588 - loss: 1.1054 - val_accuracy: 0.9109 - val_loss: 1.0549 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9493 - loss: 0.9015  \n",
      "Epoch 21: val_accuracy did not improve from 0.98295\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9493 - loss: 0.9015 - val_accuracy: 0.9829 - val_loss: 0.7576 - learning_rate: 3.9063e-04\n",
      "Run 9, Epoch 22/30\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8403 - loss: 1.2128  \n",
      "Epoch 22: val_accuracy did not improve from 0.88078\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8403 - loss: 1.2128 - val_accuracy: 0.8795 - val_loss: 1.2396 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8585 - loss: 1.1075  \n",
      "Epoch 22: val_accuracy did not improve from 0.91230\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8585 - loss: 1.1075 - val_accuracy: 0.9106 - val_loss: 1.0545 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9474 - loss: 0.9066  \n",
      "Epoch 22: val_accuracy did not improve from 0.98295\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9474 - loss: 0.9066 - val_accuracy: 0.9829 - val_loss: 0.7571 - learning_rate: 3.9063e-04\n",
      "Run 9, Epoch 23/30\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8414 - loss: 1.2175  \n",
      "Epoch 23: val_accuracy did not improve from 0.88078\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8414 - loss: 1.2175 - val_accuracy: 0.8804 - val_loss: 1.2397 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8574 - loss: 1.1033  \n",
      "Epoch 23: val_accuracy did not improve from 0.91230\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8574 - loss: 1.1033 - val_accuracy: 0.9115 - val_loss: 1.0542 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9477 - loss: 0.9025  \n",
      "Epoch 23: val_accuracy did not improve from 0.98295\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9477 - loss: 0.9025 - val_accuracy: 0.9826 - val_loss: 0.7565 - learning_rate: 3.9063e-04\n",
      "Run 9, Epoch 24/30\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8384 - loss: 1.2182  \n",
      "Epoch 24: val_accuracy did not improve from 0.88078\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8384 - loss: 1.2182 - val_accuracy: 0.8797 - val_loss: 1.2396 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8583 - loss: 1.0993  \n",
      "Epoch 24: val_accuracy did not improve from 0.91230\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8583 - loss: 1.0993 - val_accuracy: 0.9112 - val_loss: 1.0535 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9475 - loss: 0.9011  \n",
      "Epoch 24: val_accuracy did not improve from 0.98295\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9475 - loss: 0.9011 - val_accuracy: 0.9826 - val_loss: 0.7562 - learning_rate: 1.9531e-04\n",
      "Run 9, Epoch 25/30\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8418 - loss: 1.2174  \n",
      "Epoch 25: val_accuracy did not improve from 0.88078\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.8417 - loss: 1.2174 - val_accuracy: 0.8797 - val_loss: 1.2392 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8567 - loss: 1.1057  \n",
      "Epoch 25: val_accuracy did not improve from 0.91230\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8567 - loss: 1.1057 - val_accuracy: 0.9114 - val_loss: 1.0535 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9496 - loss: 0.8953  \n",
      "Epoch 25: val_accuracy did not improve from 0.98295\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9496 - loss: 0.8953 - val_accuracy: 0.9826 - val_loss: 0.7558 - learning_rate: 1.9531e-04\n",
      "Run 9, Epoch 26/30\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8391 - loss: 1.2161  \n",
      "Epoch 26: val_accuracy did not improve from 0.88078\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8391 - loss: 1.2161 - val_accuracy: 0.8799 - val_loss: 1.2381 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8593 - loss: 1.1033  \n",
      "Epoch 26: val_accuracy did not improve from 0.91230\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8593 - loss: 1.1034 - val_accuracy: 0.9112 - val_loss: 1.0531 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9499 - loss: 0.8884  \n",
      "Epoch 26: val_accuracy did not improve from 0.98295\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9499 - loss: 0.8885 - val_accuracy: 0.9826 - val_loss: 0.7556 - learning_rate: 1.9531e-04\n",
      "Run 9, Epoch 27/30\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8380 - loss: 1.2230  \n",
      "Epoch 27: val_accuracy did not improve from 0.88078\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8380 - loss: 1.2229 - val_accuracy: 0.8795 - val_loss: 1.2379 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8564 - loss: 1.1000  \n",
      "Epoch 27: val_accuracy did not improve from 0.91230\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8564 - loss: 1.1000 - val_accuracy: 0.9118 - val_loss: 1.0528 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9469 - loss: 0.8918  \n",
      "Epoch 27: val_accuracy did not improve from 0.98295\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9469 - loss: 0.8918 - val_accuracy: 0.9826 - val_loss: 0.7554 - learning_rate: 9.7656e-05\n",
      "Run 9, Epoch 28/30\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8420 - loss: 1.2121  \n",
      "Epoch 28: val_accuracy did not improve from 0.88078\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8420 - loss: 1.2121 - val_accuracy: 0.8795 - val_loss: 1.2376 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8554 - loss: 1.1081  \n",
      "Epoch 28: val_accuracy did not improve from 0.91230\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8554 - loss: 1.1081 - val_accuracy: 0.9117 - val_loss: 1.0525 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9468 - loss: 0.8959  \n",
      "Epoch 28: val_accuracy did not improve from 0.98295\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9468 - loss: 0.8959 - val_accuracy: 0.9826 - val_loss: 0.7551 - learning_rate: 9.7656e-05\n",
      "Run 9, Epoch 29/30\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8410 - loss: 1.2065  \n",
      "Epoch 29: val_accuracy did not improve from 0.88078\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8410 - loss: 1.2066 - val_accuracy: 0.8795 - val_loss: 1.2376 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8591 - loss: 1.1149  \n",
      "Epoch 29: val_accuracy did not improve from 0.91230\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8591 - loss: 1.1149 - val_accuracy: 0.9115 - val_loss: 1.0523 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9485 - loss: 0.8906  \n",
      "Epoch 29: val_accuracy did not improve from 0.98295\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9485 - loss: 0.8906 - val_accuracy: 0.9826 - val_loss: 0.7551 - learning_rate: 9.7656e-05\n",
      "Run 9, Epoch 30/30\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8397 - loss: 1.2174  \n",
      "Epoch 30: val_accuracy did not improve from 0.88078\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8397 - loss: 1.2174 - val_accuracy: 0.8797 - val_loss: 1.2375 - learning_rate: 4.8828e-05\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8611 - loss: 1.1084  \n",
      "Epoch 30: val_accuracy did not improve from 0.91230\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8611 - loss: 1.1083 - val_accuracy: 0.9117 - val_loss: 1.0523 - learning_rate: 4.8828e-05\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9484 - loss: 0.8914  \n",
      "Epoch 30: val_accuracy did not improve from 0.98295\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9484 - loss: 0.8914 - val_accuracy: 0.9828 - val_loss: 0.7550 - learning_rate: 4.8828e-05\n",
      "Completed run 9 with 30 epochs\n",
      "autosaveAdult_9_18.keras\n",
      "\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 807us/step - accuracy: 0.8846 - loss: 1.2336\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8802 - loss: 1.2496\n",
      "autosaveP24_9_20.keras\n",
      "\u001b[1m1825/1825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 761us/step - accuracy: 0.9096 - loss: 1.0665\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9108 - loss: 1.0787\n",
      "autosaveP48_9_19.keras\n",
      "\u001b[1m1699/1699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 633us/step - accuracy: 0.9813 - loss: 0.7671\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9830 - loss: 0.7679\n",
      "Starting run 10\n",
      "Run 10, Epoch 1/30\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7582 - loss: 1.8241  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.83098, saving model to autosaveAdult_10_01.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.7581 - loss: 1.8254 - val_accuracy: 0.8310 - val_loss: 2.3859 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7748 - loss: 1.7379  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.87315, saving model to autosaveP24_10_01.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7747 - loss: 1.7387 - val_accuracy: 0.8732 - val_loss: 1.9407 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8708 - loss: 1.6261  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.94670, saving model to autosaveP48_10_01.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8707 - loss: 1.6275 - val_accuracy: 0.9467 - val_loss: 2.2873 - learning_rate: 0.0500\n",
      "Run 10, Epoch 2/30\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6639 - loss: 3.1663  \n",
      "Epoch 2: val_accuracy improved from 0.83098 to 0.83203, saving model to autosaveAdult_10_02.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6639 - loss: 3.1667 - val_accuracy: 0.8320 - val_loss: 2.7158 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7279 - loss: 2.4586  \n",
      "Epoch 2: val_accuracy did not improve from 0.87315\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7279 - loss: 2.4587 - val_accuracy: 0.8624 - val_loss: 1.9819 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7899 - loss: 3.1216  \n",
      "Epoch 2: val_accuracy improved from 0.94670 to 0.94951, saving model to autosaveP48_10_02.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7899 - loss: 3.1221 - val_accuracy: 0.9495 - val_loss: 2.6136 - learning_rate: 0.0500\n",
      "Run 10, Epoch 3/30\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7059 - loss: 2.8781  \n",
      "Epoch 3: val_accuracy improved from 0.83203 to 0.86601, saving model to autosaveAdult_10_03.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7059 - loss: 2.8774 - val_accuracy: 0.8660 - val_loss: 1.9567 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7720 - loss: 2.1124  \n",
      "Epoch 3: val_accuracy improved from 0.87315 to 0.88656, saving model to autosaveP24_10_03.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7720 - loss: 2.1120 - val_accuracy: 0.8866 - val_loss: 1.4487 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8479 - loss: 2.7261  \n",
      "Epoch 3: val_accuracy improved from 0.94951 to 0.96673, saving model to autosaveP48_10_03.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8479 - loss: 2.7253 - val_accuracy: 0.9667 - val_loss: 1.5439 - learning_rate: 0.0250\n",
      "Run 10, Epoch 4/30\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7741 - loss: 1.9808  \n",
      "Epoch 4: val_accuracy improved from 0.86601 to 0.86769, saving model to autosaveAdult_10_04.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7741 - loss: 1.9807 - val_accuracy: 0.8677 - val_loss: 1.6536 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8109 - loss: 1.5607  \n",
      "Epoch 4: val_accuracy improved from 0.88656 to 0.89427, saving model to autosaveP24_10_04.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8109 - loss: 1.5606 - val_accuracy: 0.8943 - val_loss: 1.3160 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9036 - loss: 1.6273  \n",
      "Epoch 4: val_accuracy improved from 0.96673 to 0.97351, saving model to autosaveP48_10_04.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9036 - loss: 1.6271 - val_accuracy: 0.9735 - val_loss: 1.1443 - learning_rate: 0.0250\n",
      "Run 10, Epoch 5/30\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7854 - loss: 1.7320  \n",
      "Epoch 5: val_accuracy did not improve from 0.86769\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7854 - loss: 1.7319 - val_accuracy: 0.8654 - val_loss: 1.5598 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8146 - loss: 1.4701  \n",
      "Epoch 5: val_accuracy did not improve from 0.89427\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8146 - loss: 1.4701 - val_accuracy: 0.8924 - val_loss: 1.2697 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9154 - loss: 1.3232  \n",
      "Epoch 5: val_accuracy improved from 0.97351 to 0.97517, saving model to autosaveP48_10_05.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9154 - loss: 1.3231 - val_accuracy: 0.9752 - val_loss: 0.9999 - learning_rate: 0.0250\n",
      "Run 10, Epoch 6/30\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8031 - loss: 1.5423  \n",
      "Epoch 6: val_accuracy improved from 0.86769 to 0.87191, saving model to autosaveAdult_10_06.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8031 - loss: 1.5423 - val_accuracy: 0.8719 - val_loss: 1.4374 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8296 - loss: 1.3629  \n",
      "Epoch 6: val_accuracy improved from 0.89427 to 0.90459, saving model to autosaveP24_10_06.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8296 - loss: 1.3629 - val_accuracy: 0.9046 - val_loss: 1.1809 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9292 - loss: 1.1360  \n",
      "Epoch 6: val_accuracy improved from 0.97517 to 0.97782, saving model to autosaveP48_10_06.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9292 - loss: 1.1360 - val_accuracy: 0.9778 - val_loss: 0.8999 - learning_rate: 0.0125\n",
      "Run 10, Epoch 7/30\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8153 - loss: 1.4462  \n",
      "Epoch 7: val_accuracy did not improve from 0.87191\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8153 - loss: 1.4462 - val_accuracy: 0.8692 - val_loss: 1.3930 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8368 - loss: 1.2604  \n",
      "Epoch 7: val_accuracy improved from 0.90459 to 0.90490, saving model to autosaveP24_10_07.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8368 - loss: 1.2604 - val_accuracy: 0.9049 - val_loss: 1.1446 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9369 - loss: 1.0516  \n",
      "Epoch 7: val_accuracy improved from 0.97782 to 0.97964, saving model to autosaveP48_10_07.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9369 - loss: 1.0516 - val_accuracy: 0.9796 - val_loss: 0.8571 - learning_rate: 0.0125\n",
      "Run 10, Epoch 8/30\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8206 - loss: 1.3927  \n",
      "Epoch 8: val_accuracy did not improve from 0.87191\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8206 - loss: 1.3927 - val_accuracy: 0.8719 - val_loss: 1.3470 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8373 - loss: 1.2566  \n",
      "Epoch 8: val_accuracy improved from 0.90490 to 0.90983, saving model to autosaveP24_10_08.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8373 - loss: 1.2566 - val_accuracy: 0.9098 - val_loss: 1.1245 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9377 - loss: 1.0083  \n",
      "Epoch 8: val_accuracy improved from 0.97964 to 0.98129, saving model to autosaveP48_10_08.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9377 - loss: 1.0083 - val_accuracy: 0.9813 - val_loss: 0.8252 - learning_rate: 0.0125\n",
      "Run 10, Epoch 9/30\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8313 - loss: 1.3402  \n",
      "Epoch 9: val_accuracy improved from 0.87191 to 0.87613, saving model to autosaveAdult_10_09.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8313 - loss: 1.3402 - val_accuracy: 0.8761 - val_loss: 1.3148 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8430 - loss: 1.2269  \n",
      "Epoch 9: val_accuracy did not improve from 0.90983\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8430 - loss: 1.2269 - val_accuracy: 0.9057 - val_loss: 1.1082 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9418 - loss: 0.9725  \n",
      "Epoch 9: val_accuracy did not improve from 0.98129\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9418 - loss: 0.9725 - val_accuracy: 0.9801 - val_loss: 0.8056 - learning_rate: 0.0063\n",
      "Run 10, Epoch 10/30\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8270 - loss: 1.3077  \n",
      "Epoch 10: val_accuracy did not improve from 0.87613\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8270 - loss: 1.3077 - val_accuracy: 0.8757 - val_loss: 1.2946 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8499 - loss: 1.1762  \n",
      "Epoch 10: val_accuracy improved from 0.90983 to 0.91292, saving model to autosaveP24_10_10.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8499 - loss: 1.1762 - val_accuracy: 0.9129 - val_loss: 1.0971 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9421 - loss: 0.9551  \n",
      "Epoch 10: val_accuracy improved from 0.98129 to 0.98179, saving model to autosaveP48_10_10.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9421 - loss: 0.9551 - val_accuracy: 0.9818 - val_loss: 0.7943 - learning_rate: 0.0063\n",
      "Run 10, Epoch 11/30\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8340 - loss: 1.2707  \n",
      "Epoch 11: val_accuracy did not improve from 0.87613\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8340 - loss: 1.2707 - val_accuracy: 0.8759 - val_loss: 1.2889 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8512 - loss: 1.1726  \n",
      "Epoch 11: val_accuracy did not improve from 0.91292\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8512 - loss: 1.1726 - val_accuracy: 0.9049 - val_loss: 1.0858 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9440 - loss: 0.9397  \n",
      "Epoch 11: val_accuracy improved from 0.98179 to 0.98196, saving model to autosaveP48_10_11.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9440 - loss: 0.9397 - val_accuracy: 0.9820 - val_loss: 0.7848 - learning_rate: 0.0063\n",
      "Run 10, Epoch 12/30\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8300 - loss: 1.2585  \n",
      "Epoch 12: val_accuracy improved from 0.87613 to 0.87824, saving model to autosaveAdult_10_12.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8300 - loss: 1.2585 - val_accuracy: 0.8782 - val_loss: 1.2725 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8533 - loss: 1.1431  \n",
      "Epoch 12: val_accuracy did not improve from 0.91292\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8533 - loss: 1.1431 - val_accuracy: 0.9106 - val_loss: 1.0759 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9440 - loss: 0.9243  \n",
      "Epoch 12: val_accuracy improved from 0.98196 to 0.98245, saving model to autosaveP48_10_12.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9440 - loss: 0.9243 - val_accuracy: 0.9825 - val_loss: 0.7748 - learning_rate: 0.0031\n",
      "Run 10, Epoch 13/30\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8339 - loss: 1.2626  \n",
      "Epoch 13: val_accuracy did not improve from 0.87824\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8339 - loss: 1.2626 - val_accuracy: 0.8751 - val_loss: 1.2654 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8530 - loss: 1.1361  \n",
      "Epoch 13: val_accuracy did not improve from 0.91292\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8530 - loss: 1.1361 - val_accuracy: 0.9115 - val_loss: 1.0719 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9477 - loss: 0.9224  \n",
      "Epoch 13: val_accuracy did not improve from 0.98245\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9477 - loss: 0.9223 - val_accuracy: 0.9825 - val_loss: 0.7681 - learning_rate: 0.0031\n",
      "Run 10, Epoch 14/30\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8339 - loss: 1.2615  \n",
      "Epoch 14: val_accuracy did not improve from 0.87824\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8339 - loss: 1.2614 - val_accuracy: 0.8776 - val_loss: 1.2534 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8530 - loss: 1.1400  \n",
      "Epoch 14: val_accuracy did not improve from 0.91292\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8530 - loss: 1.1400 - val_accuracy: 0.9103 - val_loss: 1.0659 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9472 - loss: 0.9109  \n",
      "Epoch 14: val_accuracy improved from 0.98245 to 0.98262, saving model to autosaveP48_10_14.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9472 - loss: 0.9109 - val_accuracy: 0.9826 - val_loss: 0.7631 - learning_rate: 0.0031\n",
      "Run 10, Epoch 15/30\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8401 - loss: 1.2299  \n",
      "Epoch 15: val_accuracy did not improve from 0.87824\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8401 - loss: 1.2299 - val_accuracy: 0.8759 - val_loss: 1.2513 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8527 - loss: 1.1376  \n",
      "Epoch 15: val_accuracy did not improve from 0.91292\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8527 - loss: 1.1376 - val_accuracy: 0.9112 - val_loss: 1.0596 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9486 - loss: 0.8970  \n",
      "Epoch 15: val_accuracy improved from 0.98262 to 0.98295, saving model to autosaveP48_10_15.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9486 - loss: 0.8970 - val_accuracy: 0.9829 - val_loss: 0.7608 - learning_rate: 0.0016\n",
      "Run 10, Epoch 16/30\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8403 - loss: 1.2365  \n",
      "Epoch 16: val_accuracy did not improve from 0.87824\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8403 - loss: 1.2365 - val_accuracy: 0.8770 - val_loss: 1.2490 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8584 - loss: 1.1169  \n",
      "Epoch 16: val_accuracy did not improve from 0.91292\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8584 - loss: 1.1169 - val_accuracy: 0.9118 - val_loss: 1.0574 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9481 - loss: 0.8954  \n",
      "Epoch 16: val_accuracy did not improve from 0.98295\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9481 - loss: 0.8955 - val_accuracy: 0.9826 - val_loss: 0.7573 - learning_rate: 0.0016\n",
      "Run 10, Epoch 17/30\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8379 - loss: 1.2332  \n",
      "Epoch 17: val_accuracy did not improve from 0.87824\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8379 - loss: 1.2332 - val_accuracy: 0.8778 - val_loss: 1.2453 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8547 - loss: 1.1167  \n",
      "Epoch 17: val_accuracy did not improve from 0.91292\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8547 - loss: 1.1167 - val_accuracy: 0.9103 - val_loss: 1.0567 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9480 - loss: 0.9060  \n",
      "Epoch 17: val_accuracy improved from 0.98295 to 0.98361, saving model to autosaveP48_10_17.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9480 - loss: 0.9060 - val_accuracy: 0.9836 - val_loss: 0.7542 - learning_rate: 0.0016\n",
      "Run 10, Epoch 18/30\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8389 - loss: 1.2146  \n",
      "Epoch 18: val_accuracy did not improve from 0.87824\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8389 - loss: 1.2146 - val_accuracy: 0.8774 - val_loss: 1.2430 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8544 - loss: 1.1236  \n",
      "Epoch 18: val_accuracy did not improve from 0.91292\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8544 - loss: 1.1236 - val_accuracy: 0.9126 - val_loss: 1.0544 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9482 - loss: 0.9063  \n",
      "Epoch 18: val_accuracy did not improve from 0.98361\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9482 - loss: 0.9062 - val_accuracy: 0.9834 - val_loss: 0.7532 - learning_rate: 7.8125e-04\n",
      "Run 10, Epoch 19/30\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8382 - loss: 1.2102  \n",
      "Epoch 19: val_accuracy did not improve from 0.87824\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8382 - loss: 1.2102 - val_accuracy: 0.8782 - val_loss: 1.2407 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8576 - loss: 1.1066  \n",
      "Epoch 19: val_accuracy improved from 0.91292 to 0.91307, saving model to autosaveP24_10_19.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8576 - loss: 1.1066 - val_accuracy: 0.9131 - val_loss: 1.0531 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9478 - loss: 0.8896  \n",
      "Epoch 19: val_accuracy did not improve from 0.98361\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9478 - loss: 0.8896 - val_accuracy: 0.9828 - val_loss: 0.7529 - learning_rate: 7.8125e-04\n",
      "Run 10, Epoch 20/30\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8436 - loss: 1.2212  \n",
      "Epoch 20: val_accuracy improved from 0.87824 to 0.87972, saving model to autosaveAdult_10_20.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8436 - loss: 1.2211 - val_accuracy: 0.8797 - val_loss: 1.2382 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8568 - loss: 1.1184  \n",
      "Epoch 20: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8568 - loss: 1.1183 - val_accuracy: 0.9109 - val_loss: 1.0520 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9481 - loss: 0.8956  \n",
      "Epoch 20: val_accuracy did not improve from 0.98361\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9481 - loss: 0.8956 - val_accuracy: 0.9831 - val_loss: 0.7512 - learning_rate: 7.8125e-04\n",
      "Run 10, Epoch 21/30\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8420 - loss: 1.2149  \n",
      "Epoch 21: val_accuracy improved from 0.87972 to 0.87993, saving model to autosaveAdult_10_21.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8419 - loss: 1.2149 - val_accuracy: 0.8799 - val_loss: 1.2381 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8564 - loss: 1.1123  \n",
      "Epoch 21: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8564 - loss: 1.1123 - val_accuracy: 0.9123 - val_loss: 1.0515 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9481 - loss: 0.8931  \n",
      "Epoch 21: val_accuracy did not improve from 0.98361\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9481 - loss: 0.8931 - val_accuracy: 0.9828 - val_loss: 0.7511 - learning_rate: 3.9063e-04\n",
      "Run 10, Epoch 22/30\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8351 - loss: 1.2245  \n",
      "Epoch 22: val_accuracy did not improve from 0.87993\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8351 - loss: 1.2245 - val_accuracy: 0.8787 - val_loss: 1.2376 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8591 - loss: 1.1170  \n",
      "Epoch 22: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8591 - loss: 1.1169 - val_accuracy: 0.9115 - val_loss: 1.0509 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9468 - loss: 0.8947  \n",
      "Epoch 22: val_accuracy did not improve from 0.98361\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9468 - loss: 0.8947 - val_accuracy: 0.9836 - val_loss: 0.7501 - learning_rate: 3.9063e-04\n",
      "Run 10, Epoch 23/30\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8412 - loss: 1.2120  \n",
      "Epoch 23: val_accuracy did not improve from 0.87993\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8412 - loss: 1.2120 - val_accuracy: 0.8772 - val_loss: 1.2370 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8588 - loss: 1.1062  \n",
      "Epoch 23: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8588 - loss: 1.1062 - val_accuracy: 0.9115 - val_loss: 1.0505 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9486 - loss: 0.8863  \n",
      "Epoch 23: val_accuracy did not improve from 0.98361\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9486 - loss: 0.8863 - val_accuracy: 0.9833 - val_loss: 0.7499 - learning_rate: 3.9063e-04\n",
      "Run 10, Epoch 24/30\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8358 - loss: 1.2245  \n",
      "Epoch 24: val_accuracy did not improve from 0.87993\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8358 - loss: 1.2245 - val_accuracy: 0.8774 - val_loss: 1.2366 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8580 - loss: 1.1082  \n",
      "Epoch 24: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8580 - loss: 1.1082 - val_accuracy: 0.9120 - val_loss: 1.0501 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9485 - loss: 0.8857  \n",
      "Epoch 24: val_accuracy did not improve from 0.98361\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9485 - loss: 0.8857 - val_accuracy: 0.9831 - val_loss: 0.7493 - learning_rate: 1.9531e-04\n",
      "Run 10, Epoch 25/30\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8424 - loss: 1.2014  \n",
      "Epoch 25: val_accuracy did not improve from 0.87993\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8424 - loss: 1.2014 - val_accuracy: 0.8782 - val_loss: 1.2355 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8580 - loss: 1.1016  \n",
      "Epoch 25: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8580 - loss: 1.1016 - val_accuracy: 0.9117 - val_loss: 1.0498 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9501 - loss: 0.8807  \n",
      "Epoch 25: val_accuracy did not improve from 0.98361\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9501 - loss: 0.8807 - val_accuracy: 0.9831 - val_loss: 0.7489 - learning_rate: 1.9531e-04\n",
      "Run 10, Epoch 26/30\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8385 - loss: 1.2150  \n",
      "Epoch 26: val_accuracy did not improve from 0.87993\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8385 - loss: 1.2150 - val_accuracy: 0.8782 - val_loss: 1.2348 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8582 - loss: 1.1146  \n",
      "Epoch 26: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8582 - loss: 1.1145 - val_accuracy: 0.9120 - val_loss: 1.0494 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9493 - loss: 0.8792  \n",
      "Epoch 26: val_accuracy did not improve from 0.98361\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9493 - loss: 0.8792 - val_accuracy: 0.9836 - val_loss: 0.7482 - learning_rate: 1.9531e-04\n",
      "Run 10, Epoch 27/30\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8397 - loss: 1.2034  \n",
      "Epoch 27: val_accuracy did not improve from 0.87993\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8397 - loss: 1.2034 - val_accuracy: 0.8787 - val_loss: 1.2345 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8604 - loss: 1.1040  \n",
      "Epoch 27: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8604 - loss: 1.1040 - val_accuracy: 0.9123 - val_loss: 1.0493 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9498 - loss: 0.8836  \n",
      "Epoch 27: val_accuracy did not improve from 0.98361\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9498 - loss: 0.8836 - val_accuracy: 0.9836 - val_loss: 0.7481 - learning_rate: 9.7656e-05\n",
      "Run 10, Epoch 28/30\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8398 - loss: 1.2207  \n",
      "Epoch 28: val_accuracy did not improve from 0.87993\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8398 - loss: 1.2207 - val_accuracy: 0.8787 - val_loss: 1.2342 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8552 - loss: 1.1097  \n",
      "Epoch 28: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8552 - loss: 1.1097 - val_accuracy: 0.9126 - val_loss: 1.0492 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9470 - loss: 0.8927  \n",
      "Epoch 28: val_accuracy did not improve from 0.98361\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9470 - loss: 0.8926 - val_accuracy: 0.9836 - val_loss: 0.7480 - learning_rate: 9.7656e-05\n",
      "Run 10, Epoch 29/30\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8390 - loss: 1.2090  \n",
      "Epoch 29: val_accuracy did not improve from 0.87993\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8390 - loss: 1.2090 - val_accuracy: 0.8787 - val_loss: 1.2341 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8560 - loss: 1.1111  \n",
      "Epoch 29: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8560 - loss: 1.1111 - val_accuracy: 0.9118 - val_loss: 1.0491 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9521 - loss: 0.8765  \n",
      "Epoch 29: val_accuracy did not improve from 0.98361\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9520 - loss: 0.8765 - val_accuracy: 0.9833 - val_loss: 0.7478 - learning_rate: 9.7656e-05\n",
      "Run 10, Epoch 30/30\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8416 - loss: 1.2161  \n",
      "Epoch 30: val_accuracy did not improve from 0.87993\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8416 - loss: 1.2160 - val_accuracy: 0.8787 - val_loss: 1.2340 - learning_rate: 4.8828e-05\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8573 - loss: 1.1031  \n",
      "Epoch 30: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8573 - loss: 1.1031 - val_accuracy: 0.9123 - val_loss: 1.0491 - learning_rate: 4.8828e-05\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9487 - loss: 0.8844  \n",
      "Epoch 30: val_accuracy did not improve from 0.98361\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9487 - loss: 0.8844 - val_accuracy: 0.9834 - val_loss: 0.7478 - learning_rate: 4.8828e-05\n",
      "Completed run 10 with 30 epochs\n",
      "autosaveAdult_10_21.keras\n",
      "\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 798us/step - accuracy: 0.8844 - loss: 1.2271\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8807 - loss: 1.2413\n",
      "autosaveP24_10_19.keras\n",
      "\u001b[1m1825/1825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 746us/step - accuracy: 0.9096 - loss: 1.0655\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 1.0740\n",
      "autosaveP48_10_17.keras\n",
      "\u001b[1m1699/1699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - accuracy: 0.9812 - loss: 0.7629\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9839 - loss: 0.7613\n",
      "Starting run 11\n",
      "Run 11, Epoch 1/30\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7569 - loss: 1.7896  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.84786, saving model to autosaveAdult_11_01.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7568 - loss: 1.7907 - val_accuracy: 0.8479 - val_loss: 2.1825 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7754 - loss: 1.7332  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.86174, saving model to autosaveP24_11_01.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7753 - loss: 1.7340 - val_accuracy: 0.8617 - val_loss: 1.9506 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8497 - loss: 2.0770  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.93792, saving model to autosaveP48_11_01.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8496 - loss: 2.0793 - val_accuracy: 0.9379 - val_loss: 3.1359 - learning_rate: 0.0500\n",
      "Run 11, Epoch 2/30\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6753 - loss: 2.9139  \n",
      "Epoch 2: val_accuracy did not improve from 0.84786\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6753 - loss: 2.9148 - val_accuracy: 0.8238 - val_loss: 2.8469 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7291 - loss: 2.4888  \n",
      "Epoch 2: val_accuracy did not improve from 0.86174\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7290 - loss: 2.4890 - val_accuracy: 0.8577 - val_loss: 2.0340 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7698 - loss: 3.8947  \n",
      "Epoch 2: val_accuracy did not improve from 0.93792\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7698 - loss: 3.8951 - val_accuracy: 0.9209 - val_loss: 3.3178 - learning_rate: 0.0500\n",
      "Run 11, Epoch 3/30\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7001 - loss: 2.9859  \n",
      "Epoch 3: val_accuracy improved from 0.84786 to 0.85946, saving model to autosaveAdult_11_03.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7002 - loss: 2.9850 - val_accuracy: 0.8595 - val_loss: 2.0023 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7673 - loss: 2.1739  \n",
      "Epoch 3: val_accuracy improved from 0.86174 to 0.89750, saving model to autosaveP24_11_03.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7673 - loss: 2.1735 - val_accuracy: 0.8975 - val_loss: 1.4539 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8277 - loss: 3.3286  \n",
      "Epoch 3: val_accuracy improved from 0.93792 to 0.97732, saving model to autosaveP48_11_03.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8278 - loss: 3.3275 - val_accuracy: 0.9773 - val_loss: 1.7430 - learning_rate: 0.0250\n",
      "Run 11, Epoch 4/30\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7732 - loss: 2.0647  \n",
      "Epoch 4: val_accuracy did not improve from 0.85946\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7732 - loss: 2.0644 - val_accuracy: 0.8578 - val_loss: 1.6804 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8099 - loss: 1.5947  \n",
      "Epoch 4: val_accuracy improved from 0.89750 to 0.90151, saving model to autosaveP24_11_04.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8099 - loss: 1.5946 - val_accuracy: 0.9015 - val_loss: 1.3096 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8957 - loss: 1.8565  \n",
      "Epoch 4: val_accuracy did not improve from 0.97732\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8957 - loss: 1.8562 - val_accuracy: 0.9671 - val_loss: 1.2298 - learning_rate: 0.0250\n",
      "Run 11, Epoch 5/30\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7931 - loss: 1.7321  \n",
      "Epoch 5: val_accuracy improved from 0.85946 to 0.86136, saving model to autosaveAdult_11_05.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7930 - loss: 1.7321 - val_accuracy: 0.8614 - val_loss: 1.5554 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8168 - loss: 1.4520  \n",
      "Epoch 5: val_accuracy did not improve from 0.90151\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8168 - loss: 1.4520 - val_accuracy: 0.8978 - val_loss: 1.2722 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9126 - loss: 1.3797  \n",
      "Epoch 5: val_accuracy did not improve from 0.97732\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9126 - loss: 1.3796 - val_accuracy: 0.9725 - val_loss: 1.0288 - learning_rate: 0.0250\n",
      "Run 11, Epoch 6/30\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7988 - loss: 1.5730  \n",
      "Epoch 6: val_accuracy improved from 0.86136 to 0.87381, saving model to autosaveAdult_11_06.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7989 - loss: 1.5729 - val_accuracy: 0.8738 - val_loss: 1.4263 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8298 - loss: 1.3708  \n",
      "Epoch 6: val_accuracy improved from 0.90151 to 0.90768, saving model to autosaveP24_11_06.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8299 - loss: 1.3708 - val_accuracy: 0.9077 - val_loss: 1.1812 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9241 - loss: 1.1942  \n",
      "Epoch 6: val_accuracy improved from 0.97732 to 0.98196, saving model to autosaveP48_11_06.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9241 - loss: 1.1941 - val_accuracy: 0.9820 - val_loss: 0.9273 - learning_rate: 0.0125\n",
      "Run 11, Epoch 7/30\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8201 - loss: 1.4356  \n",
      "Epoch 7: val_accuracy did not improve from 0.87381\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8200 - loss: 1.4356 - val_accuracy: 0.8656 - val_loss: 1.3823 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8366 - loss: 1.2841  \n",
      "Epoch 7: val_accuracy did not improve from 0.90768\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.8366 - loss: 1.2841 - val_accuracy: 0.9037 - val_loss: 1.1482 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9354 - loss: 1.0762  \n",
      "Epoch 7: val_accuracy did not improve from 0.98196\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9354 - loss: 1.0762 - val_accuracy: 0.9803 - val_loss: 0.8794 - learning_rate: 0.0125\n",
      "Run 11, Epoch 8/30\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8171 - loss: 1.3956  \n",
      "Epoch 8: val_accuracy did not improve from 0.87381\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8171 - loss: 1.3956 - val_accuracy: 0.8717 - val_loss: 1.3407 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8371 - loss: 1.2490  \n",
      "Epoch 8: val_accuracy improved from 0.90768 to 0.90798, saving model to autosaveP24_11_08.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8371 - loss: 1.2490 - val_accuracy: 0.9080 - val_loss: 1.1331 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9360 - loss: 1.0340  \n",
      "Epoch 8: val_accuracy did not improve from 0.98196\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9360 - loss: 1.0340 - val_accuracy: 0.9810 - val_loss: 0.8456 - learning_rate: 0.0125\n",
      "Run 11, Epoch 9/30\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8248 - loss: 1.3490  \n",
      "Epoch 9: val_accuracy did not improve from 0.87381\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8248 - loss: 1.3489 - val_accuracy: 0.8677 - val_loss: 1.3246 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8486 - loss: 1.2092  \n",
      "Epoch 9: val_accuracy improved from 0.90798 to 0.90922, saving model to autosaveP24_11_09.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8486 - loss: 1.2092 - val_accuracy: 0.9092 - val_loss: 1.1096 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9393 - loss: 0.9944  \n",
      "Epoch 9: val_accuracy did not improve from 0.98196\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9393 - loss: 0.9944 - val_accuracy: 0.9811 - val_loss: 0.8225 - learning_rate: 0.0063\n",
      "Run 11, Epoch 10/30\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8297 - loss: 1.3061  \n",
      "Epoch 10: val_accuracy improved from 0.87381 to 0.87466, saving model to autosaveAdult_11_10.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8297 - loss: 1.3061 - val_accuracy: 0.8747 - val_loss: 1.2945 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8452 - loss: 1.1900  \n",
      "Epoch 10: val_accuracy did not improve from 0.90922\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8452 - loss: 1.1900 - val_accuracy: 0.9077 - val_loss: 1.0929 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9422 - loss: 0.9811  \n",
      "Epoch 10: val_accuracy improved from 0.98196 to 0.98229, saving model to autosaveP48_11_10.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9422 - loss: 0.9811 - val_accuracy: 0.9823 - val_loss: 0.8076 - learning_rate: 0.0063\n",
      "Run 11, Epoch 11/30\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8327 - loss: 1.2895  \n",
      "Epoch 11: val_accuracy did not improve from 0.87466\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8327 - loss: 1.2895 - val_accuracy: 0.8711 - val_loss: 1.2835 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8484 - loss: 1.1728  \n",
      "Epoch 11: val_accuracy improved from 0.90922 to 0.91076, saving model to autosaveP24_11_11.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8484 - loss: 1.1728 - val_accuracy: 0.9108 - val_loss: 1.0850 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9432 - loss: 0.9513  \n",
      "Epoch 11: val_accuracy did not improve from 0.98229\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9432 - loss: 0.9513 - val_accuracy: 0.9811 - val_loss: 0.7975 - learning_rate: 0.0063\n",
      "Run 11, Epoch 12/30\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8324 - loss: 1.2741  \n",
      "Epoch 12: val_accuracy did not improve from 0.87466\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8325 - loss: 1.2741 - val_accuracy: 0.8744 - val_loss: 1.2722 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8513 - loss: 1.1521  \n",
      "Epoch 12: val_accuracy did not improve from 0.91076\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8513 - loss: 1.1521 - val_accuracy: 0.9101 - val_loss: 1.0750 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9459 - loss: 0.9449  \n",
      "Epoch 12: val_accuracy improved from 0.98229 to 0.98278, saving model to autosaveP48_11_12.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9459 - loss: 0.9449 - val_accuracy: 0.9828 - val_loss: 0.7869 - learning_rate: 0.0031\n",
      "Run 11, Epoch 13/30\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8346 - loss: 1.2492  \n",
      "Epoch 13: val_accuracy improved from 0.87466 to 0.87719, saving model to autosaveAdult_11_13.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8346 - loss: 1.2492 - val_accuracy: 0.8772 - val_loss: 1.2665 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8537 - loss: 1.1530  \n",
      "Epoch 13: val_accuracy improved from 0.91076 to 0.91122, saving model to autosaveP24_11_13.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8537 - loss: 1.1530 - val_accuracy: 0.9112 - val_loss: 1.0732 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9455 - loss: 0.9320  \n",
      "Epoch 13: val_accuracy did not improve from 0.98278\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.9320 - val_accuracy: 0.9823 - val_loss: 0.7786 - learning_rate: 0.0031\n",
      "Run 11, Epoch 14/30\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8375 - loss: 1.2512  \n",
      "Epoch 14: val_accuracy did not improve from 0.87719\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8375 - loss: 1.2512 - val_accuracy: 0.8759 - val_loss: 1.2530 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8532 - loss: 1.1425  \n",
      "Epoch 14: val_accuracy did not improve from 0.91122\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8532 - loss: 1.1425 - val_accuracy: 0.9112 - val_loss: 1.0678 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9471 - loss: 0.9231  \n",
      "Epoch 14: val_accuracy did not improve from 0.98278\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9471 - loss: 0.9231 - val_accuracy: 0.9818 - val_loss: 0.7751 - learning_rate: 0.0031\n",
      "Run 11, Epoch 15/30\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8355 - loss: 1.2301  \n",
      "Epoch 15: val_accuracy did not improve from 0.87719\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8355 - loss: 1.2301 - val_accuracy: 0.8742 - val_loss: 1.2563 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8524 - loss: 1.1233  \n",
      "Epoch 15: val_accuracy improved from 0.91122 to 0.91322, saving model to autosaveP24_11_15.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8524 - loss: 1.1233 - val_accuracy: 0.9132 - val_loss: 1.0630 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9471 - loss: 0.9160  \n",
      "Epoch 15: val_accuracy did not improve from 0.98278\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9471 - loss: 0.9160 - val_accuracy: 0.9821 - val_loss: 0.7707 - learning_rate: 0.0016\n",
      "Run 11, Epoch 16/30\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8377 - loss: 1.2271  \n",
      "Epoch 16: val_accuracy did not improve from 0.87719\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8377 - loss: 1.2271 - val_accuracy: 0.8749 - val_loss: 1.2491 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8552 - loss: 1.1245  \n",
      "Epoch 16: val_accuracy improved from 0.91322 to 0.91369, saving model to autosaveP24_11_16.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8552 - loss: 1.1245 - val_accuracy: 0.9137 - val_loss: 1.0605 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9460 - loss: 0.9158  \n",
      "Epoch 16: val_accuracy did not improve from 0.98278\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9460 - loss: 0.9158 - val_accuracy: 0.9821 - val_loss: 0.7681 - learning_rate: 0.0016\n",
      "Run 11, Epoch 17/30\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8358 - loss: 1.2222  \n",
      "Epoch 17: val_accuracy did not improve from 0.87719\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8358 - loss: 1.2222 - val_accuracy: 0.8768 - val_loss: 1.2456 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8580 - loss: 1.1105  \n",
      "Epoch 17: val_accuracy improved from 0.91369 to 0.91415, saving model to autosaveP24_11_17.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8580 - loss: 1.1105 - val_accuracy: 0.9141 - val_loss: 1.0580 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9428 - loss: 0.9162  \n",
      "Epoch 17: val_accuracy did not improve from 0.98278\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9428 - loss: 0.9162 - val_accuracy: 0.9826 - val_loss: 0.7654 - learning_rate: 0.0016\n",
      "Run 11, Epoch 18/30\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8402 - loss: 1.2351  \n",
      "Epoch 18: val_accuracy did not improve from 0.87719\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8402 - loss: 1.2350 - val_accuracy: 0.8753 - val_loss: 1.2434 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8567 - loss: 1.1173  \n",
      "Epoch 18: val_accuracy did not improve from 0.91415\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8567 - loss: 1.1172 - val_accuracy: 0.9129 - val_loss: 1.0556 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9486 - loss: 0.9013  \n",
      "Epoch 18: val_accuracy did not improve from 0.98278\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9486 - loss: 0.9013 - val_accuracy: 0.9826 - val_loss: 0.7632 - learning_rate: 7.8125e-04\n",
      "Run 11, Epoch 19/30\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8355 - loss: 1.2305  \n",
      "Epoch 19: val_accuracy did not improve from 0.87719\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8356 - loss: 1.2305 - val_accuracy: 0.8751 - val_loss: 1.2416 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8572 - loss: 1.1097  \n",
      "Epoch 19: val_accuracy did not improve from 0.91415\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8572 - loss: 1.1097 - val_accuracy: 0.9128 - val_loss: 1.0552 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9487 - loss: 0.9092  \n",
      "Epoch 19: val_accuracy did not improve from 0.98278\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9487 - loss: 0.9092 - val_accuracy: 0.9823 - val_loss: 0.7632 - learning_rate: 7.8125e-04\n",
      "Run 11, Epoch 20/30\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8387 - loss: 1.2145  \n",
      "Epoch 20: val_accuracy did not improve from 0.87719\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8387 - loss: 1.2145 - val_accuracy: 0.8753 - val_loss: 1.2399 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8565 - loss: 1.1118  \n",
      "Epoch 20: val_accuracy did not improve from 0.91415\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8565 - loss: 1.1118 - val_accuracy: 0.9135 - val_loss: 1.0538 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9466 - loss: 0.9001  \n",
      "Epoch 20: val_accuracy did not improve from 0.98278\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9466 - loss: 0.9001 - val_accuracy: 0.9826 - val_loss: 0.7609 - learning_rate: 7.8125e-04\n",
      "Run 11, Epoch 21/30\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8376 - loss: 1.2276  \n",
      "Epoch 21: val_accuracy did not improve from 0.87719\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8376 - loss: 1.2276 - val_accuracy: 0.8757 - val_loss: 1.2389 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8536 - loss: 1.1072  \n",
      "Epoch 21: val_accuracy did not improve from 0.91415\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8536 - loss: 1.1072 - val_accuracy: 0.9138 - val_loss: 1.0532 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9453 - loss: 0.9059  \n",
      "Epoch 21: val_accuracy did not improve from 0.98278\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9453 - loss: 0.9059 - val_accuracy: 0.9828 - val_loss: 0.7601 - learning_rate: 3.9063e-04\n",
      "Run 11, Epoch 22/30\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8378 - loss: 1.2145  \n",
      "Epoch 22: val_accuracy did not improve from 0.87719\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8378 - loss: 1.2145 - val_accuracy: 0.8759 - val_loss: 1.2381 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8557 - loss: 1.1047  \n",
      "Epoch 22: val_accuracy did not improve from 0.91415\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8557 - loss: 1.1047 - val_accuracy: 0.9128 - val_loss: 1.0527 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9492 - loss: 0.8998  \n",
      "Epoch 22: val_accuracy did not improve from 0.98278\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9492 - loss: 0.8998 - val_accuracy: 0.9826 - val_loss: 0.7598 - learning_rate: 3.9063e-04\n",
      "Run 11, Epoch 23/30\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8428 - loss: 1.2092  \n",
      "Epoch 23: val_accuracy did not improve from 0.87719\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8428 - loss: 1.2093 - val_accuracy: 0.8770 - val_loss: 1.2372 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8580 - loss: 1.1054  \n",
      "Epoch 23: val_accuracy did not improve from 0.91415\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8580 - loss: 1.1054 - val_accuracy: 0.9134 - val_loss: 1.0521 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9482 - loss: 0.9006  \n",
      "Epoch 23: val_accuracy did not improve from 0.98278\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9482 - loss: 0.9007 - val_accuracy: 0.9823 - val_loss: 0.7592 - learning_rate: 3.9063e-04\n",
      "Run 11, Epoch 24/30\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8405 - loss: 1.2184  \n",
      "Epoch 24: val_accuracy did not improve from 0.87719\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8405 - loss: 1.2184 - val_accuracy: 0.8770 - val_loss: 1.2368 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8559 - loss: 1.0974  \n",
      "Epoch 24: val_accuracy did not improve from 0.91415\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8559 - loss: 1.0974 - val_accuracy: 0.9140 - val_loss: 1.0517 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9480 - loss: 0.9049  \n",
      "Epoch 24: val_accuracy did not improve from 0.98278\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9480 - loss: 0.9049 - val_accuracy: 0.9823 - val_loss: 0.7589 - learning_rate: 1.9531e-04\n",
      "Run 11, Epoch 25/30\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8393 - loss: 1.2043  \n",
      "Epoch 25: val_accuracy did not improve from 0.87719\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8393 - loss: 1.2044 - val_accuracy: 0.8763 - val_loss: 1.2359 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8569 - loss: 1.1014  \n",
      "Epoch 25: val_accuracy did not improve from 0.91415\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8569 - loss: 1.1014 - val_accuracy: 0.9134 - val_loss: 1.0513 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9435 - loss: 0.8981  \n",
      "Epoch 25: val_accuracy did not improve from 0.98278\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9435 - loss: 0.8981 - val_accuracy: 0.9825 - val_loss: 0.7586 - learning_rate: 1.9531e-04\n",
      "Run 11, Epoch 26/30\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8389 - loss: 1.2129  \n",
      "Epoch 26: val_accuracy did not improve from 0.87719\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8389 - loss: 1.2129 - val_accuracy: 0.8763 - val_loss: 1.2357 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8595 - loss: 1.1034  \n",
      "Epoch 26: val_accuracy did not improve from 0.91415\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8595 - loss: 1.1034 - val_accuracy: 0.9132 - val_loss: 1.0507 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9488 - loss: 0.8995  \n",
      "Epoch 26: val_accuracy did not improve from 0.98278\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9488 - loss: 0.8995 - val_accuracy: 0.9825 - val_loss: 0.7585 - learning_rate: 1.9531e-04\n",
      "Run 11, Epoch 27/30\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8374 - loss: 1.2102  \n",
      "Epoch 27: val_accuracy did not improve from 0.87719\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8374 - loss: 1.2102 - val_accuracy: 0.8759 - val_loss: 1.2358 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8564 - loss: 1.1215  \n",
      "Epoch 27: val_accuracy did not improve from 0.91415\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8564 - loss: 1.1215 - val_accuracy: 0.9132 - val_loss: 1.0506 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9495 - loss: 0.8960  \n",
      "Epoch 27: val_accuracy did not improve from 0.98278\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9495 - loss: 0.8960 - val_accuracy: 0.9825 - val_loss: 0.7582 - learning_rate: 9.7656e-05\n",
      "Run 11, Epoch 28/30\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8419 - loss: 1.2032  \n",
      "Epoch 28: val_accuracy did not improve from 0.87719\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8419 - loss: 1.2032 - val_accuracy: 0.8766 - val_loss: 1.2355 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8572 - loss: 1.1025  \n",
      "Epoch 28: val_accuracy did not improve from 0.91415\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8572 - loss: 1.1025 - val_accuracy: 0.9131 - val_loss: 1.0505 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9484 - loss: 0.8981  \n",
      "Epoch 28: val_accuracy did not improve from 0.98278\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9484 - loss: 0.8981 - val_accuracy: 0.9825 - val_loss: 0.7579 - learning_rate: 9.7656e-05\n",
      "Run 11, Epoch 29/30\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8411 - loss: 1.2138  \n",
      "Epoch 29: val_accuracy did not improve from 0.87719\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8411 - loss: 1.2138 - val_accuracy: 0.8768 - val_loss: 1.2353 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8606 - loss: 1.1004  \n",
      "Epoch 29: val_accuracy did not improve from 0.91415\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8606 - loss: 1.1004 - val_accuracy: 0.9135 - val_loss: 1.0505 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9492 - loss: 0.8935  \n",
      "Epoch 29: val_accuracy did not improve from 0.98278\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9492 - loss: 0.8935 - val_accuracy: 0.9825 - val_loss: 0.7577 - learning_rate: 9.7656e-05\n",
      "Run 11, Epoch 30/30\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8340 - loss: 1.2161  \n",
      "Epoch 30: val_accuracy did not improve from 0.87719\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8340 - loss: 1.2161 - val_accuracy: 0.8766 - val_loss: 1.2353 - learning_rate: 4.8828e-05\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8571 - loss: 1.1134  \n",
      "Epoch 30: val_accuracy did not improve from 0.91415\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8571 - loss: 1.1134 - val_accuracy: 0.9137 - val_loss: 1.0504 - learning_rate: 4.8828e-05\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9477 - loss: 0.9018  \n",
      "Epoch 30: val_accuracy did not improve from 0.98278\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9477 - loss: 0.9018 - val_accuracy: 0.9825 - val_loss: 0.7576 - learning_rate: 4.8828e-05\n",
      "Completed run 11 with 30 epochs\n",
      "autosaveAdult_11_13.keras\n",
      "\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 806us/step - accuracy: 0.8819 - loss: 1.2550\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8777 - loss: 1.2694\n",
      "autosaveP24_11_17.keras\n",
      "\u001b[1m1825/1825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 744us/step - accuracy: 0.9095 - loss: 1.0678\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 1.0799\n",
      "autosaveP48_11_12.keras\n",
      "\u001b[1m1699/1699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - accuracy: 0.9803 - loss: 0.7971\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9825 - loss: 0.7943\n",
      "Starting run 12\n",
      "Run 12, Epoch 1/30\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7533 - loss: 1.8444  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.84680, saving model to autosaveAdult_12_01.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7532 - loss: 1.8458 - val_accuracy: 0.8468 - val_loss: 2.3762 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7589 - loss: 1.8651  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.87007, saving model to autosaveP24_12_01.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7589 - loss: 1.8657 - val_accuracy: 0.8701 - val_loss: 1.8897 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8751 - loss: 1.5720  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.94024, saving model to autosaveP48_12_01.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8750 - loss: 1.5736 - val_accuracy: 0.9402 - val_loss: 2.5531 - learning_rate: 0.0500\n",
      "Run 12, Epoch 2/30\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6528 - loss: 3.3006  \n",
      "Epoch 2: val_accuracy did not improve from 0.84680\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6528 - loss: 3.3011 - val_accuracy: 0.8244 - val_loss: 2.9078 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7305 - loss: 2.4370  \n",
      "Epoch 2: val_accuracy improved from 0.87007 to 0.87408, saving model to autosaveP24_12_02.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7305 - loss: 2.4372 - val_accuracy: 0.8741 - val_loss: 2.0201 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7639 - loss: 3.9566  \n",
      "Epoch 2: val_accuracy did not improve from 0.94024\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7639 - loss: 3.9579 - val_accuracy: 0.9383 - val_loss: 4.0904 - learning_rate: 0.0500\n",
      "Run 12, Epoch 3/30\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7095 - loss: 2.9831  \n",
      "Epoch 3: val_accuracy improved from 0.84680 to 0.85039, saving model to autosaveAdult_12_03.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7096 - loss: 2.9824 - val_accuracy: 0.8504 - val_loss: 2.0231 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7661 - loss: 2.1515  \n",
      "Epoch 3: val_accuracy improved from 0.87408 to 0.89041, saving model to autosaveP24_12_03.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7662 - loss: 2.1511 - val_accuracy: 0.8904 - val_loss: 1.4689 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8057 - loss: 4.1175  \n",
      "Epoch 3: val_accuracy improved from 0.94024 to 0.95944, saving model to autosaveP48_12_03.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8057 - loss: 4.1160 - val_accuracy: 0.9594 - val_loss: 2.0959 - learning_rate: 0.0250\n",
      "Run 12, Epoch 4/30\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7745 - loss: 2.0275  \n",
      "Epoch 4: val_accuracy improved from 0.85039 to 0.86368, saving model to autosaveAdult_12_04.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7745 - loss: 2.0273 - val_accuracy: 0.8637 - val_loss: 1.6944 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8046 - loss: 1.6036  \n",
      "Epoch 4: val_accuracy improved from 0.89041 to 0.89118, saving model to autosaveP24_12_04.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8046 - loss: 1.6035 - val_accuracy: 0.8912 - val_loss: 1.3190 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8933 - loss: 2.0794  \n",
      "Epoch 4: val_accuracy improved from 0.95944 to 0.97269, saving model to autosaveP48_12_04.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8933 - loss: 2.0790 - val_accuracy: 0.9727 - val_loss: 1.3372 - learning_rate: 0.0250\n",
      "Run 12, Epoch 5/30\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7880 - loss: 1.7479  \n",
      "Epoch 5: val_accuracy improved from 0.86368 to 0.86896, saving model to autosaveAdult_12_05.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7880 - loss: 1.7478 - val_accuracy: 0.8690 - val_loss: 1.5325 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8153 - loss: 1.4619  \n",
      "Epoch 5: val_accuracy did not improve from 0.89118\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8153 - loss: 1.4619 - val_accuracy: 0.8867 - val_loss: 1.2631 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9115 - loss: 1.4739  \n",
      "Epoch 5: val_accuracy improved from 0.97269 to 0.97699, saving model to autosaveP48_12_05.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9115 - loss: 1.4738 - val_accuracy: 0.9770 - val_loss: 1.0700 - learning_rate: 0.0250\n",
      "Run 12, Epoch 6/30\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8017 - loss: 1.5669  \n",
      "Epoch 6: val_accuracy improved from 0.86896 to 0.87170, saving model to autosaveAdult_12_06.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8017 - loss: 1.5668 - val_accuracy: 0.8717 - val_loss: 1.4414 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8272 - loss: 1.3564  \n",
      "Epoch 6: val_accuracy improved from 0.89118 to 0.90136, saving model to autosaveP24_12_06.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8272 - loss: 1.3564 - val_accuracy: 0.9014 - val_loss: 1.1840 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9259 - loss: 1.2261  \n",
      "Epoch 6: val_accuracy improved from 0.97699 to 0.98047, saving model to autosaveP48_12_06.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9259 - loss: 1.2260 - val_accuracy: 0.9805 - val_loss: 0.9609 - learning_rate: 0.0125\n",
      "Run 12, Epoch 7/30\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8178 - loss: 1.4320  \n",
      "Epoch 7: val_accuracy did not improve from 0.87170\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8178 - loss: 1.4320 - val_accuracy: 0.8698 - val_loss: 1.3891 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8354 - loss: 1.2918  \n",
      "Epoch 7: val_accuracy improved from 0.90136 to 0.90444, saving model to autosaveP24_12_07.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8354 - loss: 1.2918 - val_accuracy: 0.9044 - val_loss: 1.1456 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9302 - loss: 1.1139  \n",
      "Epoch 7: val_accuracy improved from 0.98047 to 0.98113, saving model to autosaveP48_12_07.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9303 - loss: 1.1138 - val_accuracy: 0.9811 - val_loss: 0.8934 - learning_rate: 0.0125\n",
      "Run 12, Epoch 8/30\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8190 - loss: 1.4016  \n",
      "Epoch 8: val_accuracy improved from 0.87170 to 0.87297, saving model to autosaveAdult_12_08.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8190 - loss: 1.4016 - val_accuracy: 0.8730 - val_loss: 1.3402 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8407 - loss: 1.2559  \n",
      "Epoch 8: val_accuracy did not improve from 0.90444\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8407 - loss: 1.2559 - val_accuracy: 0.9006 - val_loss: 1.1298 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9341 - loss: 1.0580  \n",
      "Epoch 8: val_accuracy did not improve from 0.98113\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9341 - loss: 1.0580 - val_accuracy: 0.9810 - val_loss: 0.8595 - learning_rate: 0.0125\n",
      "Run 12, Epoch 9/30\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8250 - loss: 1.3591  \n",
      "Epoch 9: val_accuracy improved from 0.87297 to 0.87318, saving model to autosaveAdult_12_09.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8250 - loss: 1.3591 - val_accuracy: 0.8732 - val_loss: 1.3134 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8463 - loss: 1.2136  \n",
      "Epoch 9: val_accuracy improved from 0.90444 to 0.90583, saving model to autosaveP24_12_09.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8463 - loss: 1.2136 - val_accuracy: 0.9058 - val_loss: 1.1084 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9400 - loss: 1.0139  \n",
      "Epoch 9: val_accuracy improved from 0.98113 to 0.98229, saving model to autosaveP48_12_09.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9400 - loss: 1.0138 - val_accuracy: 0.9823 - val_loss: 0.8338 - learning_rate: 0.0063\n",
      "Run 12, Epoch 10/30\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8281 - loss: 1.3237  \n",
      "Epoch 10: val_accuracy did not improve from 0.87318\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8281 - loss: 1.3237 - val_accuracy: 0.8721 - val_loss: 1.3062 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8460 - loss: 1.1875  \n",
      "Epoch 10: val_accuracy improved from 0.90583 to 0.90860, saving model to autosaveP24_12_10.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8460 - loss: 1.1875 - val_accuracy: 0.9086 - val_loss: 1.0932 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9425 - loss: 0.9724  \n",
      "Epoch 10: val_accuracy did not improve from 0.98229\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9425 - loss: 0.9724 - val_accuracy: 0.9816 - val_loss: 0.8165 - learning_rate: 0.0063\n",
      "Run 12, Epoch 11/30\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8296 - loss: 1.2840  \n",
      "Epoch 11: val_accuracy did not improve from 0.87318\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8296 - loss: 1.2840 - val_accuracy: 0.8732 - val_loss: 1.2835 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8487 - loss: 1.1661  \n",
      "Epoch 11: val_accuracy did not improve from 0.90860\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8487 - loss: 1.1661 - val_accuracy: 0.9063 - val_loss: 1.0896 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9411 - loss: 0.9735  \n",
      "Epoch 11: val_accuracy did not improve from 0.98229\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9411 - loss: 0.9735 - val_accuracy: 0.9811 - val_loss: 0.8004 - learning_rate: 0.0063\n",
      "Run 12, Epoch 12/30\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8344 - loss: 1.2773  \n",
      "Epoch 12: val_accuracy improved from 0.87318 to 0.87529, saving model to autosaveAdult_12_12.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8344 - loss: 1.2773 - val_accuracy: 0.8753 - val_loss: 1.2731 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8557 - loss: 1.1522  \n",
      "Epoch 12: val_accuracy did not improve from 0.90860\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8557 - loss: 1.1523 - val_accuracy: 0.9072 - val_loss: 1.0751 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9447 - loss: 0.9460  \n",
      "Epoch 12: val_accuracy did not improve from 0.98229\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9447 - loss: 0.9460 - val_accuracy: 0.9820 - val_loss: 0.7938 - learning_rate: 0.0031\n",
      "Run 12, Epoch 13/30\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8344 - loss: 1.2493  \n",
      "Epoch 13: val_accuracy improved from 0.87529 to 0.87656, saving model to autosaveAdult_12_13.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8344 - loss: 1.2493 - val_accuracy: 0.8766 - val_loss: 1.2648 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8538 - loss: 1.1429  \n",
      "Epoch 13: val_accuracy improved from 0.90860 to 0.91107, saving model to autosaveP24_12_13.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8538 - loss: 1.1429 - val_accuracy: 0.9111 - val_loss: 1.0685 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9454 - loss: 0.9360  \n",
      "Epoch 13: val_accuracy did not improve from 0.98229\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9454 - loss: 0.9360 - val_accuracy: 0.9818 - val_loss: 0.7861 - learning_rate: 0.0031\n",
      "Run 12, Epoch 14/30\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8367 - loss: 1.2472  \n",
      "Epoch 14: val_accuracy did not improve from 0.87656\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8367 - loss: 1.2472 - val_accuracy: 0.8759 - val_loss: 1.2602 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8568 - loss: 1.1325  \n",
      "Epoch 14: val_accuracy did not improve from 0.91107\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8568 - loss: 1.1326 - val_accuracy: 0.9105 - val_loss: 1.0647 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9462 - loss: 0.9159  \n",
      "Epoch 14: val_accuracy did not improve from 0.98229\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9462 - loss: 0.9159 - val_accuracy: 0.9821 - val_loss: 0.7792 - learning_rate: 0.0031\n",
      "Run 12, Epoch 15/30\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8407 - loss: 1.2393  \n",
      "Epoch 15: val_accuracy did not improve from 0.87656\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8407 - loss: 1.2393 - val_accuracy: 0.8761 - val_loss: 1.2528 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8545 - loss: 1.1299  \n",
      "Epoch 15: val_accuracy did not improve from 0.91107\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8545 - loss: 1.1299 - val_accuracy: 0.9094 - val_loss: 1.0617 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9451 - loss: 0.9223  \n",
      "Epoch 15: val_accuracy improved from 0.98229 to 0.98262, saving model to autosaveP48_12_15.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9451 - loss: 0.9223 - val_accuracy: 0.9826 - val_loss: 0.7765 - learning_rate: 0.0016\n",
      "Run 12, Epoch 16/30\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8377 - loss: 1.2413  \n",
      "Epoch 16: val_accuracy did not improve from 0.87656\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8377 - loss: 1.2413 - val_accuracy: 0.8725 - val_loss: 1.2543 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8548 - loss: 1.1333  \n",
      "Epoch 16: val_accuracy improved from 0.91107 to 0.91184, saving model to autosaveP24_12_16.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8548 - loss: 1.1332 - val_accuracy: 0.9118 - val_loss: 1.0597 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9446 - loss: 0.9194  \n",
      "Epoch 16: val_accuracy did not improve from 0.98262\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9446 - loss: 0.9195 - val_accuracy: 0.9815 - val_loss: 0.7744 - learning_rate: 0.0016\n",
      "Run 12, Epoch 17/30\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8391 - loss: 1.2234  \n",
      "Epoch 17: val_accuracy did not improve from 0.87656\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8391 - loss: 1.2235 - val_accuracy: 0.8757 - val_loss: 1.2462 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8562 - loss: 1.1224  \n",
      "Epoch 17: val_accuracy did not improve from 0.91184\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8562 - loss: 1.1224 - val_accuracy: 0.9100 - val_loss: 1.0568 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9442 - loss: 0.9188  \n",
      "Epoch 17: val_accuracy did not improve from 0.98262\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9442 - loss: 0.9188 - val_accuracy: 0.9823 - val_loss: 0.7717 - learning_rate: 0.0016\n",
      "Run 12, Epoch 18/30\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8397 - loss: 1.2164  \n",
      "Epoch 18: val_accuracy did not improve from 0.87656\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8397 - loss: 1.2164 - val_accuracy: 0.8755 - val_loss: 1.2432 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8567 - loss: 1.1197  \n",
      "Epoch 18: val_accuracy did not improve from 0.91184\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8567 - loss: 1.1197 - val_accuracy: 0.9108 - val_loss: 1.0555 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9474 - loss: 0.9132  \n",
      "Epoch 18: val_accuracy did not improve from 0.98262\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9474 - loss: 0.9132 - val_accuracy: 0.9825 - val_loss: 0.7681 - learning_rate: 7.8125e-04\n",
      "Run 12, Epoch 19/30\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8366 - loss: 1.2204  \n",
      "Epoch 19: val_accuracy did not improve from 0.87656\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8366 - loss: 1.2204 - val_accuracy: 0.8744 - val_loss: 1.2432 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8565 - loss: 1.1155  \n",
      "Epoch 19: val_accuracy did not improve from 0.91184\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8565 - loss: 1.1155 - val_accuracy: 0.9117 - val_loss: 1.0552 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9471 - loss: 0.9225  \n",
      "Epoch 19: val_accuracy improved from 0.98262 to 0.98328, saving model to autosaveP48_12_19.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9471 - loss: 0.9225 - val_accuracy: 0.9833 - val_loss: 0.7670 - learning_rate: 7.8125e-04\n",
      "Run 12, Epoch 20/30\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8351 - loss: 1.2239  \n",
      "Epoch 20: val_accuracy did not improve from 0.87656\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8351 - loss: 1.2239 - val_accuracy: 0.8763 - val_loss: 1.2428 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8585 - loss: 1.1102  \n",
      "Epoch 20: val_accuracy did not improve from 0.91184\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8585 - loss: 1.1103 - val_accuracy: 0.9101 - val_loss: 1.0540 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9482 - loss: 0.9042  \n",
      "Epoch 20: val_accuracy did not improve from 0.98328\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9482 - loss: 0.9042 - val_accuracy: 0.9828 - val_loss: 0.7659 - learning_rate: 7.8125e-04\n",
      "Run 12, Epoch 21/30\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8351 - loss: 1.2325  \n",
      "Epoch 21: val_accuracy did not improve from 0.87656\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8351 - loss: 1.2325 - val_accuracy: 0.8749 - val_loss: 1.2422 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8573 - loss: 1.1056  \n",
      "Epoch 21: val_accuracy did not improve from 0.91184\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8573 - loss: 1.1056 - val_accuracy: 0.9103 - val_loss: 1.0528 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9459 - loss: 0.9088  \n",
      "Epoch 21: val_accuracy did not improve from 0.98328\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9459 - loss: 0.9088 - val_accuracy: 0.9829 - val_loss: 0.7651 - learning_rate: 3.9063e-04\n",
      "Run 12, Epoch 22/30\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8405 - loss: 1.2092  \n",
      "Epoch 22: val_accuracy did not improve from 0.87656\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8405 - loss: 1.2093 - val_accuracy: 0.8742 - val_loss: 1.2411 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8586 - loss: 1.1062  \n",
      "Epoch 22: val_accuracy did not improve from 0.91184\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8586 - loss: 1.1062 - val_accuracy: 0.9117 - val_loss: 1.0523 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9461 - loss: 0.9106  \n",
      "Epoch 22: val_accuracy improved from 0.98328 to 0.98345, saving model to autosaveP48_12_22.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9461 - loss: 0.9106 - val_accuracy: 0.9834 - val_loss: 0.7643 - learning_rate: 3.9063e-04\n",
      "Run 12, Epoch 23/30\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8416 - loss: 1.2066  \n",
      "Epoch 23: val_accuracy did not improve from 0.87656\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8416 - loss: 1.2066 - val_accuracy: 0.8749 - val_loss: 1.2403 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8582 - loss: 1.1167  \n",
      "Epoch 23: val_accuracy did not improve from 0.91184\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8582 - loss: 1.1167 - val_accuracy: 0.9114 - val_loss: 1.0518 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9460 - loss: 0.8998  \n",
      "Epoch 23: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9460 - loss: 0.8998 - val_accuracy: 0.9828 - val_loss: 0.7634 - learning_rate: 3.9063e-04\n",
      "Run 12, Epoch 24/30\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8390 - loss: 1.2113  \n",
      "Epoch 24: val_accuracy did not improve from 0.87656\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8390 - loss: 1.2113 - val_accuracy: 0.8749 - val_loss: 1.2401 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8581 - loss: 1.1114  \n",
      "Epoch 24: val_accuracy did not improve from 0.91184\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8581 - loss: 1.1114 - val_accuracy: 0.9117 - val_loss: 1.0514 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9491 - loss: 0.8993  \n",
      "Epoch 24: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.8993 - val_accuracy: 0.9831 - val_loss: 0.7634 - learning_rate: 1.9531e-04\n",
      "Run 12, Epoch 25/30\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8402 - loss: 1.2093  \n",
      "Epoch 25: val_accuracy did not improve from 0.87656\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8402 - loss: 1.2093 - val_accuracy: 0.8757 - val_loss: 1.2394 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8568 - loss: 1.1118  \n",
      "Epoch 25: val_accuracy did not improve from 0.91184\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8568 - loss: 1.1118 - val_accuracy: 0.9106 - val_loss: 1.0513 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9435 - loss: 0.9091  \n",
      "Epoch 25: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9435 - loss: 0.9091 - val_accuracy: 0.9825 - val_loss: 0.7629 - learning_rate: 1.9531e-04\n",
      "Run 12, Epoch 26/30\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8460 - loss: 1.2034  \n",
      "Epoch 26: val_accuracy did not improve from 0.87656\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8460 - loss: 1.2035 - val_accuracy: 0.8755 - val_loss: 1.2385 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8581 - loss: 1.1126  \n",
      "Epoch 26: val_accuracy did not improve from 0.91184\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8581 - loss: 1.1126 - val_accuracy: 0.9114 - val_loss: 1.0509 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9475 - loss: 0.9077  \n",
      "Epoch 26: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9475 - loss: 0.9077 - val_accuracy: 0.9826 - val_loss: 0.7625 - learning_rate: 1.9531e-04\n",
      "Run 12, Epoch 27/30\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8405 - loss: 1.2051  \n",
      "Epoch 27: val_accuracy did not improve from 0.87656\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8405 - loss: 1.2051 - val_accuracy: 0.8755 - val_loss: 1.2381 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8590 - loss: 1.1081  \n",
      "Epoch 27: val_accuracy did not improve from 0.91184\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8590 - loss: 1.1081 - val_accuracy: 0.9109 - val_loss: 1.0508 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9459 - loss: 0.9146  \n",
      "Epoch 27: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9459 - loss: 0.9146 - val_accuracy: 0.9828 - val_loss: 0.7625 - learning_rate: 9.7656e-05\n",
      "Run 12, Epoch 28/30\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8392 - loss: 1.2153  \n",
      "Epoch 28: val_accuracy did not improve from 0.87656\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8392 - loss: 1.2152 - val_accuracy: 0.8755 - val_loss: 1.2377 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8581 - loss: 1.1043  \n",
      "Epoch 28: val_accuracy did not improve from 0.91184\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8581 - loss: 1.1043 - val_accuracy: 0.9114 - val_loss: 1.0507 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9484 - loss: 0.9035  \n",
      "Epoch 28: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9484 - loss: 0.9035 - val_accuracy: 0.9829 - val_loss: 0.7623 - learning_rate: 9.7656e-05\n",
      "Run 12, Epoch 29/30\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8415 - loss: 1.2219  \n",
      "Epoch 29: val_accuracy did not improve from 0.87656\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8415 - loss: 1.2219 - val_accuracy: 0.8757 - val_loss: 1.2374 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8581 - loss: 1.1033  \n",
      "Epoch 29: val_accuracy did not improve from 0.91184\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8581 - loss: 1.1033 - val_accuracy: 0.9115 - val_loss: 1.0505 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9480 - loss: 0.8985  \n",
      "Epoch 29: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9480 - loss: 0.8985 - val_accuracy: 0.9828 - val_loss: 0.7620 - learning_rate: 9.7656e-05\n",
      "Run 12, Epoch 30/30\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8415 - loss: 1.2052  \n",
      "Epoch 30: val_accuracy did not improve from 0.87656\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8415 - loss: 1.2052 - val_accuracy: 0.8757 - val_loss: 1.2373 - learning_rate: 4.8828e-05\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8612 - loss: 1.0958  \n",
      "Epoch 30: val_accuracy did not improve from 0.91184\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8612 - loss: 1.0959 - val_accuracy: 0.9114 - val_loss: 1.0504 - learning_rate: 4.8828e-05\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9481 - loss: 0.9126  \n",
      "Epoch 30: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9481 - loss: 0.9126 - val_accuracy: 0.9829 - val_loss: 0.7620 - learning_rate: 4.8828e-05\n",
      "Completed run 12 with 30 epochs\n",
      "autosaveAdult_12_13.keras\n",
      "\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 803us/step - accuracy: 0.8838 - loss: 1.2537\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8741 - loss: 1.2691\n",
      "autosaveP24_12_16.keras\n",
      "\u001b[1m1825/1825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 748us/step - accuracy: 0.9087 - loss: 1.0707\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9112 - loss: 1.0808\n",
      "autosaveP48_12_22.keras\n",
      "\u001b[1m1699/1699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - accuracy: 0.9812 - loss: 0.7728\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9822 - loss: 0.7730\n",
      "Starting run 13\n",
      "Run 13, Epoch 1/30\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7625 - loss: 1.7170  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.83077, saving model to autosaveAdult_13_01.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7624 - loss: 1.7182 - val_accuracy: 0.8308 - val_loss: 2.3077 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7702 - loss: 1.7448  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.86359, saving model to autosaveP24_13_01.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7701 - loss: 1.7455 - val_accuracy: 0.8636 - val_loss: 1.9290 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8633 - loss: 1.8722  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.91856, saving model to autosaveP48_13_01.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8631 - loss: 1.8751 - val_accuracy: 0.9186 - val_loss: 4.0789 - learning_rate: 0.0500\n",
      "Run 13, Epoch 2/30\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6827 - loss: 2.7977  \n",
      "Epoch 2: val_accuracy did not improve from 0.83077\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.6826 - loss: 2.7983 - val_accuracy: 0.7922 - val_loss: 2.6825 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7226 - loss: 2.4868  \n",
      "Epoch 2: val_accuracy improved from 0.86359 to 0.86791, saving model to autosaveP24_13_02.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7226 - loss: 2.4869 - val_accuracy: 0.8679 - val_loss: 1.9956 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7329 - loss: 5.0475  \n",
      "Epoch 2: val_accuracy improved from 0.91856 to 0.95100, saving model to autosaveP48_13_02.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7329 - loss: 5.0471 - val_accuracy: 0.9510 - val_loss: 3.1222 - learning_rate: 0.0500\n",
      "Run 13, Epoch 3/30\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7144 - loss: 2.7309  \n",
      "Epoch 3: val_accuracy improved from 0.83077 to 0.85609, saving model to autosaveAdult_13_03.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7145 - loss: 2.7302 - val_accuracy: 0.8561 - val_loss: 1.8841 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7732 - loss: 2.1235  \n",
      "Epoch 3: val_accuracy improved from 0.86791 to 0.88486, saving model to autosaveP24_13_03.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7733 - loss: 2.1231 - val_accuracy: 0.8849 - val_loss: 1.4572 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8371 - loss: 3.1684  \n",
      "Epoch 3: val_accuracy improved from 0.95100 to 0.96838, saving model to autosaveP48_13_03.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8371 - loss: 3.1674 - val_accuracy: 0.9684 - val_loss: 1.7167 - learning_rate: 0.0250\n",
      "Run 13, Epoch 4/30\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7777 - loss: 1.9251  \n",
      "Epoch 4: val_accuracy improved from 0.85609 to 0.86073, saving model to autosaveAdult_13_04.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7777 - loss: 1.9249 - val_accuracy: 0.8607 - val_loss: 1.6107 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8088 - loss: 1.5822  \n",
      "Epoch 4: val_accuracy improved from 0.88486 to 0.89180, saving model to autosaveP24_13_04.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8088 - loss: 1.5822 - val_accuracy: 0.8918 - val_loss: 1.3082 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8996 - loss: 1.8189  \n",
      "Epoch 4: val_accuracy did not improve from 0.96838\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8996 - loss: 1.8186 - val_accuracy: 0.9631 - val_loss: 1.2251 - learning_rate: 0.0250\n",
      "Run 13, Epoch 5/30\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7929 - loss: 1.6752  \n",
      "Epoch 5: val_accuracy improved from 0.86073 to 0.86453, saving model to autosaveAdult_13_05.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7929 - loss: 1.6752 - val_accuracy: 0.8645 - val_loss: 1.4961 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8191 - loss: 1.4582  \n",
      "Epoch 5: val_accuracy did not improve from 0.89180\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8191 - loss: 1.4583 - val_accuracy: 0.8861 - val_loss: 1.2786 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9148 - loss: 1.3686  \n",
      "Epoch 5: val_accuracy improved from 0.96838 to 0.97980, saving model to autosaveP48_13_05.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9148 - loss: 1.3685 - val_accuracy: 0.9798 - val_loss: 1.0232 - learning_rate: 0.0250\n",
      "Run 13, Epoch 6/30\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8084 - loss: 1.5287  \n",
      "Epoch 6: val_accuracy improved from 0.86453 to 0.87001, saving model to autosaveAdult_13_06.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8084 - loss: 1.5286 - val_accuracy: 0.8700 - val_loss: 1.4146 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8301 - loss: 1.3665  \n",
      "Epoch 6: val_accuracy improved from 0.89180 to 0.90428, saving model to autosaveP24_13_06.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8301 - loss: 1.3665 - val_accuracy: 0.9043 - val_loss: 1.1866 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9272 - loss: 1.1835  \n",
      "Epoch 6: val_accuracy improved from 0.97980 to 0.98014, saving model to autosaveP48_13_06.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9272 - loss: 1.1834 - val_accuracy: 0.9801 - val_loss: 0.9264 - learning_rate: 0.0125\n",
      "Run 13, Epoch 7/30\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8181 - loss: 1.4220  \n",
      "Epoch 7: val_accuracy improved from 0.87001 to 0.87044, saving model to autosaveAdult_13_07.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8181 - loss: 1.4220 - val_accuracy: 0.8704 - val_loss: 1.3636 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8399 - loss: 1.2824  \n",
      "Epoch 7: val_accuracy improved from 0.90428 to 0.90521, saving model to autosaveP24_13_07.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8399 - loss: 1.2824 - val_accuracy: 0.9052 - val_loss: 1.1444 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9339 - loss: 1.0947  \n",
      "Epoch 7: val_accuracy did not improve from 0.98014\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9339 - loss: 1.0947 - val_accuracy: 0.9778 - val_loss: 0.8908 - learning_rate: 0.0125\n",
      "Run 13, Epoch 8/30\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8216 - loss: 1.3733  \n",
      "Epoch 8: val_accuracy did not improve from 0.87044\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8216 - loss: 1.3733 - val_accuracy: 0.8700 - val_loss: 1.3416 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8399 - loss: 1.2437  \n",
      "Epoch 8: val_accuracy improved from 0.90521 to 0.90567, saving model to autosaveP24_13_08.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8399 - loss: 1.2437 - val_accuracy: 0.9057 - val_loss: 1.1314 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9358 - loss: 1.0507  \n",
      "Epoch 8: val_accuracy did not improve from 0.98014\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9358 - loss: 1.0507 - val_accuracy: 0.9793 - val_loss: 0.8536 - learning_rate: 0.0125\n",
      "Run 13, Epoch 9/30\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8291 - loss: 1.3341  \n",
      "Epoch 9: val_accuracy improved from 0.87044 to 0.87635, saving model to autosaveAdult_13_09.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8291 - loss: 1.3341 - val_accuracy: 0.8763 - val_loss: 1.2983 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8440 - loss: 1.2149  \n",
      "Epoch 9: val_accuracy improved from 0.90567 to 0.90983, saving model to autosaveP24_13_09.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8440 - loss: 1.2148 - val_accuracy: 0.9098 - val_loss: 1.1069 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9396 - loss: 1.0054  \n",
      "Epoch 9: val_accuracy improved from 0.98014 to 0.98196, saving model to autosaveP48_13_09.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9396 - loss: 1.0054 - val_accuracy: 0.9820 - val_loss: 0.8299 - learning_rate: 0.0063\n",
      "Run 13, Epoch 10/30\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8329 - loss: 1.2972  \n",
      "Epoch 10: val_accuracy did not improve from 0.87635\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8329 - loss: 1.2972 - val_accuracy: 0.8738 - val_loss: 1.2964 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8498 - loss: 1.1754  \n",
      "Epoch 10: val_accuracy did not improve from 0.90983\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8498 - loss: 1.1754 - val_accuracy: 0.9040 - val_loss: 1.0955 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9411 - loss: 0.9859  \n",
      "Epoch 10: val_accuracy improved from 0.98196 to 0.98278, saving model to autosaveP48_13_10.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9411 - loss: 0.9859 - val_accuracy: 0.9828 - val_loss: 0.8090 - learning_rate: 0.0063\n",
      "Run 13, Epoch 11/30\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8312 - loss: 1.2762  \n",
      "Epoch 11: val_accuracy did not improve from 0.87635\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8312 - loss: 1.2762 - val_accuracy: 0.8736 - val_loss: 1.2759 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8486 - loss: 1.1722  \n",
      "Epoch 11: val_accuracy did not improve from 0.90983\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8486 - loss: 1.1722 - val_accuracy: 0.9086 - val_loss: 1.0828 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9446 - loss: 0.9550  \n",
      "Epoch 11: val_accuracy did not improve from 0.98278\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9446 - loss: 0.9550 - val_accuracy: 0.9823 - val_loss: 0.7976 - learning_rate: 0.0063\n",
      "Run 13, Epoch 12/30\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8348 - loss: 1.2573  \n",
      "Epoch 12: val_accuracy improved from 0.87635 to 0.87656, saving model to autosaveAdult_13_12.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8348 - loss: 1.2573 - val_accuracy: 0.8766 - val_loss: 1.2611 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8467 - loss: 1.1570  \n",
      "Epoch 12: val_accuracy improved from 0.90983 to 0.91184, saving model to autosaveP24_13_12.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8467 - loss: 1.1569 - val_accuracy: 0.9118 - val_loss: 1.0696 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9445 - loss: 0.9467  \n",
      "Epoch 12: val_accuracy did not improve from 0.98278\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9445 - loss: 0.9467 - val_accuracy: 0.9820 - val_loss: 0.7900 - learning_rate: 0.0031\n",
      "Run 13, Epoch 13/30\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8366 - loss: 1.2337  \n",
      "Epoch 13: val_accuracy improved from 0.87656 to 0.87677, saving model to autosaveAdult_13_13.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8366 - loss: 1.2337 - val_accuracy: 0.8768 - val_loss: 1.2525 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8534 - loss: 1.1457  \n",
      "Epoch 13: val_accuracy did not improve from 0.91184\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8534 - loss: 1.1457 - val_accuracy: 0.9109 - val_loss: 1.0659 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9450 - loss: 0.9306  \n",
      "Epoch 13: val_accuracy did not improve from 0.98278\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9450 - loss: 0.9306 - val_accuracy: 0.9820 - val_loss: 0.7850 - learning_rate: 0.0031\n",
      "Run 13, Epoch 14/30\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8391 - loss: 1.2400  \n",
      "Epoch 14: val_accuracy did not improve from 0.87677\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8391 - loss: 1.2400 - val_accuracy: 0.8732 - val_loss: 1.2527 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8530 - loss: 1.1343  \n",
      "Epoch 14: val_accuracy improved from 0.91184 to 0.91261, saving model to autosaveP24_13_14.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8530 - loss: 1.1343 - val_accuracy: 0.9126 - val_loss: 1.0620 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9460 - loss: 0.9272  \n",
      "Epoch 14: val_accuracy improved from 0.98278 to 0.98295, saving model to autosaveP48_13_14.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9460 - loss: 0.9272 - val_accuracy: 0.9829 - val_loss: 0.7799 - learning_rate: 0.0031\n",
      "Run 13, Epoch 15/30\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8335 - loss: 1.2270  \n",
      "Epoch 15: val_accuracy improved from 0.87677 to 0.87698, saving model to autosaveAdult_13_15.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8335 - loss: 1.2270 - val_accuracy: 0.8770 - val_loss: 1.2436 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8517 - loss: 1.1345  \n",
      "Epoch 15: val_accuracy improved from 0.91261 to 0.91307, saving model to autosaveP24_13_15.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8517 - loss: 1.1345 - val_accuracy: 0.9131 - val_loss: 1.0589 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9446 - loss: 0.9260  \n",
      "Epoch 15: val_accuracy improved from 0.98295 to 0.98312, saving model to autosaveP48_13_15.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9446 - loss: 0.9260 - val_accuracy: 0.9831 - val_loss: 0.7744 - learning_rate: 0.0016\n",
      "Run 13, Epoch 16/30\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8374 - loss: 1.2210  \n",
      "Epoch 16: val_accuracy did not improve from 0.87698\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8374 - loss: 1.2210 - val_accuracy: 0.8763 - val_loss: 1.2407 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8583 - loss: 1.1265  \n",
      "Epoch 16: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8583 - loss: 1.1265 - val_accuracy: 0.9125 - val_loss: 1.0578 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9443 - loss: 0.9256  \n",
      "Epoch 16: val_accuracy did not improve from 0.98312\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9443 - loss: 0.9256 - val_accuracy: 0.9828 - val_loss: 0.7714 - learning_rate: 0.0016\n",
      "Run 13, Epoch 17/30\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8418 - loss: 1.2135  \n",
      "Epoch 17: val_accuracy did not improve from 0.87698\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8418 - loss: 1.2135 - val_accuracy: 0.8755 - val_loss: 1.2414 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8527 - loss: 1.1302  \n",
      "Epoch 17: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8527 - loss: 1.1302 - val_accuracy: 0.9108 - val_loss: 1.0546 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9488 - loss: 0.9150  \n",
      "Epoch 17: val_accuracy did not improve from 0.98312\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9488 - loss: 0.9150 - val_accuracy: 0.9828 - val_loss: 0.7687 - learning_rate: 0.0016\n",
      "Run 13, Epoch 18/30\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8386 - loss: 1.2100  \n",
      "Epoch 18: val_accuracy did not improve from 0.87698\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8386 - loss: 1.2100 - val_accuracy: 0.8768 - val_loss: 1.2358 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8572 - loss: 1.1176  \n",
      "Epoch 18: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8572 - loss: 1.1176 - val_accuracy: 0.9125 - val_loss: 1.0529 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9465 - loss: 0.9205  \n",
      "Epoch 18: val_accuracy did not improve from 0.98312\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9465 - loss: 0.9205 - val_accuracy: 0.9828 - val_loss: 0.7677 - learning_rate: 7.8125e-04\n",
      "Run 13, Epoch 19/30\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8389 - loss: 1.2023  \n",
      "Epoch 19: val_accuracy did not improve from 0.87698\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8389 - loss: 1.2023 - val_accuracy: 0.8759 - val_loss: 1.2354 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8594 - loss: 1.1152  \n",
      "Epoch 19: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8594 - loss: 1.1153 - val_accuracy: 0.9121 - val_loss: 1.0527 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9462 - loss: 0.9092  \n",
      "Epoch 19: val_accuracy did not improve from 0.98312\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9462 - loss: 0.9092 - val_accuracy: 0.9829 - val_loss: 0.7670 - learning_rate: 7.8125e-04\n",
      "Run 13, Epoch 20/30\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8418 - loss: 1.2091  \n",
      "Epoch 20: val_accuracy improved from 0.87698 to 0.87740, saving model to autosaveAdult_13_20.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8418 - loss: 1.2091 - val_accuracy: 0.8774 - val_loss: 1.2316 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8570 - loss: 1.1083  \n",
      "Epoch 20: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8570 - loss: 1.1083 - val_accuracy: 0.9117 - val_loss: 1.0511 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9473 - loss: 0.9068  \n",
      "Epoch 20: val_accuracy did not improve from 0.98312\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9473 - loss: 0.9068 - val_accuracy: 0.9821 - val_loss: 0.7650 - learning_rate: 7.8125e-04\n",
      "Run 13, Epoch 21/30\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8379 - loss: 1.2110  \n",
      "Epoch 21: val_accuracy did not improve from 0.87740\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8379 - loss: 1.2110 - val_accuracy: 0.8768 - val_loss: 1.2314 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8564 - loss: 1.1163  \n",
      "Epoch 21: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8564 - loss: 1.1163 - val_accuracy: 0.9117 - val_loss: 1.0504 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9477 - loss: 0.9089  \n",
      "Epoch 21: val_accuracy did not improve from 0.98312\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9477 - loss: 0.9089 - val_accuracy: 0.9825 - val_loss: 0.7644 - learning_rate: 3.9063e-04\n",
      "Run 13, Epoch 22/30\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8372 - loss: 1.1981  \n",
      "Epoch 22: val_accuracy did not improve from 0.87740\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8372 - loss: 1.1981 - val_accuracy: 0.8768 - val_loss: 1.2309 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8572 - loss: 1.1161  \n",
      "Epoch 22: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8572 - loss: 1.1161 - val_accuracy: 0.9109 - val_loss: 1.0495 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9474 - loss: 0.9079  \n",
      "Epoch 22: val_accuracy did not improve from 0.98312\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9474 - loss: 0.9079 - val_accuracy: 0.9828 - val_loss: 0.7636 - learning_rate: 3.9063e-04\n",
      "Run 13, Epoch 23/30\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8414 - loss: 1.2076  \n",
      "Epoch 23: val_accuracy did not improve from 0.87740\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8414 - loss: 1.2076 - val_accuracy: 0.8766 - val_loss: 1.2292 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8575 - loss: 1.1062  \n",
      "Epoch 23: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8575 - loss: 1.1062 - val_accuracy: 0.9112 - val_loss: 1.0488 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9472 - loss: 0.9146  \n",
      "Epoch 23: val_accuracy did not improve from 0.98312\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9472 - loss: 0.9146 - val_accuracy: 0.9828 - val_loss: 0.7635 - learning_rate: 3.9063e-04\n",
      "Run 13, Epoch 24/30\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8394 - loss: 1.2077  \n",
      "Epoch 24: val_accuracy did not improve from 0.87740\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8395 - loss: 1.2077 - val_accuracy: 0.8768 - val_loss: 1.2284 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8577 - loss: 1.1047  \n",
      "Epoch 24: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8577 - loss: 1.1047 - val_accuracy: 0.9121 - val_loss: 1.0486 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9471 - loss: 0.9104  \n",
      "Epoch 24: val_accuracy did not improve from 0.98312\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9471 - loss: 0.9104 - val_accuracy: 0.9828 - val_loss: 0.7632 - learning_rate: 1.9531e-04\n",
      "Run 13, Epoch 25/30\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8415 - loss: 1.2050  \n",
      "Epoch 25: val_accuracy did not improve from 0.87740\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8415 - loss: 1.2050 - val_accuracy: 0.8772 - val_loss: 1.2283 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8574 - loss: 1.1199  \n",
      "Epoch 25: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8574 - loss: 1.1199 - val_accuracy: 0.9120 - val_loss: 1.0484 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9453 - loss: 0.9029  \n",
      "Epoch 25: val_accuracy did not improve from 0.98312\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9453 - loss: 0.9029 - val_accuracy: 0.9831 - val_loss: 0.7626 - learning_rate: 1.9531e-04\n",
      "Run 13, Epoch 26/30\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8381 - loss: 1.2082  \n",
      "Epoch 26: val_accuracy did not improve from 0.87740\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8381 - loss: 1.2082 - val_accuracy: 0.8772 - val_loss: 1.2285 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8578 - loss: 1.1141  \n",
      "Epoch 26: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8578 - loss: 1.1141 - val_accuracy: 0.9118 - val_loss: 1.0483 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9464 - loss: 0.9113  \n",
      "Epoch 26: val_accuracy did not improve from 0.98312\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9464 - loss: 0.9113 - val_accuracy: 0.9831 - val_loss: 0.7623 - learning_rate: 1.9531e-04\n",
      "Run 13, Epoch 27/30\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8448 - loss: 1.2000  \n",
      "Epoch 27: val_accuracy did not improve from 0.87740\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8447 - loss: 1.2000 - val_accuracy: 0.8772 - val_loss: 1.2283 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8566 - loss: 1.1016  \n",
      "Epoch 27: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8566 - loss: 1.1016 - val_accuracy: 0.9118 - val_loss: 1.0482 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9482 - loss: 0.9091  \n",
      "Epoch 27: val_accuracy did not improve from 0.98312\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9482 - loss: 0.9091 - val_accuracy: 0.9828 - val_loss: 0.7621 - learning_rate: 9.7656e-05\n",
      "Run 13, Epoch 28/30\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8419 - loss: 1.2046  \n",
      "Epoch 28: val_accuracy did not improve from 0.87740\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8419 - loss: 1.2046 - val_accuracy: 0.8770 - val_loss: 1.2280 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8566 - loss: 1.1060  \n",
      "Epoch 28: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8566 - loss: 1.1060 - val_accuracy: 0.9120 - val_loss: 1.0481 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9486 - loss: 0.9088  \n",
      "Epoch 28: val_accuracy did not improve from 0.98312\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9486 - loss: 0.9088 - val_accuracy: 0.9828 - val_loss: 0.7620 - learning_rate: 9.7656e-05\n",
      "Run 13, Epoch 29/30\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8426 - loss: 1.2053  \n",
      "Epoch 29: val_accuracy did not improve from 0.87740\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8426 - loss: 1.2053 - val_accuracy: 0.8770 - val_loss: 1.2281 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8600 - loss: 1.1133  \n",
      "Epoch 29: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8600 - loss: 1.1133 - val_accuracy: 0.9121 - val_loss: 1.0480 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9474 - loss: 0.9011  \n",
      "Epoch 29: val_accuracy did not improve from 0.98312\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9474 - loss: 0.9011 - val_accuracy: 0.9829 - val_loss: 0.7617 - learning_rate: 9.7656e-05\n",
      "Run 13, Epoch 30/30\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8405 - loss: 1.2047  \n",
      "Epoch 30: val_accuracy did not improve from 0.87740\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8405 - loss: 1.2047 - val_accuracy: 0.8766 - val_loss: 1.2279 - learning_rate: 4.8828e-05\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8571 - loss: 1.0994  \n",
      "Epoch 30: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8571 - loss: 1.0994 - val_accuracy: 0.9123 - val_loss: 1.0480 - learning_rate: 4.8828e-05\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9490 - loss: 0.9083  \n",
      "Epoch 30: val_accuracy did not improve from 0.98312\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9490 - loss: 0.9082 - val_accuracy: 0.9828 - val_loss: 0.7617 - learning_rate: 4.8828e-05\n",
      "Completed run 13 with 30 epochs\n",
      "autosaveAdult_13_20.keras\n",
      "\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 796us/step - accuracy: 0.8847 - loss: 1.2219\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8759 - loss: 1.2352\n",
      "autosaveP24_13_15.keras\n",
      "\u001b[1m1825/1825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 750us/step - accuracy: 0.9104 - loss: 1.0706\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 1.0790\n",
      "autosaveP48_13_15.keras\n",
      "\u001b[1m1699/1699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - accuracy: 0.9818 - loss: 0.7846\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9824 - loss: 0.7824\n",
      "Starting run 14\n",
      "Run 14, Epoch 1/30\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7625 - loss: 1.7453  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.83562, saving model to autosaveAdult_14_01.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7624 - loss: 1.7466 - val_accuracy: 0.8356 - val_loss: 2.2989 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7728 - loss: 1.7503  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.87762, saving model to autosaveP24_14_01.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7727 - loss: 1.7511 - val_accuracy: 0.8776 - val_loss: 1.8759 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.05.\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8722 - loss: 1.6869  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.92352, saving model to autosaveP48_14_01.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8721 - loss: 1.6886 - val_accuracy: 0.9235 - val_loss: 2.7932 - learning_rate: 0.0500\n",
      "Run 14, Epoch 2/30\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6694 - loss: 2.9461  \n",
      "Epoch 2: val_accuracy improved from 0.83562 to 0.83710, saving model to autosaveAdult_14_02.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.6694 - loss: 2.9464 - val_accuracy: 0.8371 - val_loss: 2.5719 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7373 - loss: 2.3690  \n",
      "Epoch 2: val_accuracy did not improve from 0.87762\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7373 - loss: 2.3692 - val_accuracy: 0.8739 - val_loss: 1.9133 - learning_rate: 0.0500\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.05.\n",
      "Epoch 2/2\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7680 - loss: 3.6475  \n",
      "Epoch 2: val_accuracy improved from 0.92352 to 0.94190, saving model to autosaveP48_14_02.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7680 - loss: 3.6477 - val_accuracy: 0.9419 - val_loss: 3.0450 - learning_rate: 0.0500\n",
      "Run 14, Epoch 3/30\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7171 - loss: 2.7047  \n",
      "Epoch 3: val_accuracy improved from 0.83710 to 0.85756, saving model to autosaveAdult_14_03.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7172 - loss: 2.7041 - val_accuracy: 0.8576 - val_loss: 1.8879 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7670 - loss: 2.0543  \n",
      "Epoch 3: val_accuracy improved from 0.87762 to 0.88456, saving model to autosaveP24_14_03.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.7670 - loss: 2.0540 - val_accuracy: 0.8846 - val_loss: 1.4482 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 3/3\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8271 - loss: 3.1962  \n",
      "Epoch 3: val_accuracy improved from 0.94190 to 0.96656, saving model to autosaveP48_14_03.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8272 - loss: 3.1951 - val_accuracy: 0.9666 - val_loss: 1.7012 - learning_rate: 0.0250\n",
      "Run 14, Epoch 4/30\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7828 - loss: 1.9163  \n",
      "Epoch 4: val_accuracy improved from 0.85756 to 0.87128, saving model to autosaveAdult_14_04.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7828 - loss: 1.9162 - val_accuracy: 0.8713 - val_loss: 1.6084 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8064 - loss: 1.5954  \n",
      "Epoch 4: val_accuracy improved from 0.88456 to 0.90059, saving model to autosaveP24_14_04.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8064 - loss: 1.5953 - val_accuracy: 0.9006 - val_loss: 1.2954 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 4/4\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8973 - loss: 1.7851  \n",
      "Epoch 4: val_accuracy improved from 0.96656 to 0.96971, saving model to autosaveP48_14_04.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8973 - loss: 1.7848 - val_accuracy: 0.9697 - val_loss: 1.2131 - learning_rate: 0.0250\n",
      "Run 14, Epoch 5/30\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7871 - loss: 1.6763  \n",
      "Epoch 5: val_accuracy did not improve from 0.87128\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7871 - loss: 1.6763 - val_accuracy: 0.8662 - val_loss: 1.5047 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8146 - loss: 1.4450  \n",
      "Epoch 5: val_accuracy did not improve from 0.90059\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8146 - loss: 1.4451 - val_accuracy: 0.8966 - val_loss: 1.2519 - learning_rate: 0.0250\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.025.\n",
      "Epoch 5/5\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9163 - loss: 1.3456  \n",
      "Epoch 5: val_accuracy improved from 0.96971 to 0.98179, saving model to autosaveP48_14_05.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9163 - loss: 1.3456 - val_accuracy: 0.9818 - val_loss: 1.0023 - learning_rate: 0.0250\n",
      "Run 14, Epoch 6/30\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8051 - loss: 1.5256  \n",
      "Epoch 6: val_accuracy improved from 0.87128 to 0.87149, saving model to autosaveAdult_14_06.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8051 - loss: 1.5255 - val_accuracy: 0.8715 - val_loss: 1.4094 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8300 - loss: 1.3445  \n",
      "Epoch 6: val_accuracy did not improve from 0.90059\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8300 - loss: 1.3445 - val_accuracy: 0.8997 - val_loss: 1.1759 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 6/6\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9279 - loss: 1.1746  \n",
      "Epoch 6: val_accuracy did not improve from 0.98179\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9279 - loss: 1.1745 - val_accuracy: 0.9805 - val_loss: 0.9188 - learning_rate: 0.0125\n",
      "Run 14, Epoch 7/30\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8192 - loss: 1.3997  \n",
      "Epoch 7: val_accuracy improved from 0.87149 to 0.87677, saving model to autosaveAdult_14_07.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8192 - loss: 1.3997 - val_accuracy: 0.8768 - val_loss: 1.3592 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8384 - loss: 1.2647  \n",
      "Epoch 7: val_accuracy improved from 0.90059 to 0.90074, saving model to autosaveP24_14_07.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8383 - loss: 1.2647 - val_accuracy: 0.9007 - val_loss: 1.1510 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 7/7\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9353 - loss: 1.0718  \n",
      "Epoch 7: val_accuracy did not improve from 0.98179\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9353 - loss: 1.0718 - val_accuracy: 0.9803 - val_loss: 0.8719 - learning_rate: 0.0125\n",
      "Run 14, Epoch 8/30\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8182 - loss: 1.3754  \n",
      "Epoch 8: val_accuracy did not improve from 0.87677\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8182 - loss: 1.3754 - val_accuracy: 0.8698 - val_loss: 1.3319 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8356 - loss: 1.2590  \n",
      "Epoch 8: val_accuracy improved from 0.90074 to 0.90166, saving model to autosaveP24_14_08.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8356 - loss: 1.2590 - val_accuracy: 0.9017 - val_loss: 1.1301 - learning_rate: 0.0125\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0125.\n",
      "Epoch 8/8\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9357 - loss: 1.0407  \n",
      "Epoch 8: val_accuracy improved from 0.98179 to 0.98229, saving model to autosaveP48_14_08.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9357 - loss: 1.0407 - val_accuracy: 0.9823 - val_loss: 0.8391 - learning_rate: 0.0125\n",
      "Run 14, Epoch 9/30\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8233 - loss: 1.3370  \n",
      "Epoch 9: val_accuracy did not improve from 0.87677\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8233 - loss: 1.3370 - val_accuracy: 0.8761 - val_loss: 1.3048 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8452 - loss: 1.2165  \n",
      "Epoch 9: val_accuracy improved from 0.90166 to 0.91030, saving model to autosaveP24_14_09.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8452 - loss: 1.2165 - val_accuracy: 0.9103 - val_loss: 1.1080 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 9/9\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9416 - loss: 0.9886  \n",
      "Epoch 9: val_accuracy improved from 0.98229 to 0.98262, saving model to autosaveP48_14_09.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9416 - loss: 0.9886 - val_accuracy: 0.9826 - val_loss: 0.8154 - learning_rate: 0.0063\n",
      "Run 14, Epoch 10/30\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8298 - loss: 1.3055  \n",
      "Epoch 10: val_accuracy did not improve from 0.87677\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8298 - loss: 1.3055 - val_accuracy: 0.8757 - val_loss: 1.2927 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8477 - loss: 1.1896  \n",
      "Epoch 10: val_accuracy did not improve from 0.91030\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8477 - loss: 1.1895 - val_accuracy: 0.9075 - val_loss: 1.0901 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 10/10\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9419 - loss: 0.9646  \n",
      "Epoch 10: val_accuracy did not improve from 0.98262\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9419 - loss: 0.9646 - val_accuracy: 0.9825 - val_loss: 0.8000 - learning_rate: 0.0063\n",
      "Run 14, Epoch 11/30\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8295 - loss: 1.2800  \n",
      "Epoch 11: val_accuracy did not improve from 0.87677\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8295 - loss: 1.2800 - val_accuracy: 0.8740 - val_loss: 1.2715 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8513 - loss: 1.1700  \n",
      "Epoch 11: val_accuracy improved from 0.91030 to 0.91060, saving model to autosaveP24_14_11.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8513 - loss: 1.1700 - val_accuracy: 0.9106 - val_loss: 1.0805 - learning_rate: 0.0063\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00625.\n",
      "Epoch 11/11\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9452 - loss: 0.9507  \n",
      "Epoch 11: val_accuracy did not improve from 0.98262\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9452 - loss: 0.9507 - val_accuracy: 0.9816 - val_loss: 0.7937 - learning_rate: 0.0063\n",
      "Run 14, Epoch 12/30\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8355 - loss: 1.2491  \n",
      "Epoch 12: val_accuracy improved from 0.87677 to 0.87782, saving model to autosaveAdult_14_12.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8355 - loss: 1.2491 - val_accuracy: 0.8778 - val_loss: 1.2590 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8525 - loss: 1.1440  \n",
      "Epoch 12: val_accuracy improved from 0.91060 to 0.91276, saving model to autosaveP24_14_12.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8525 - loss: 1.1440 - val_accuracy: 0.9128 - val_loss: 1.0725 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 12/12\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9462 - loss: 0.9393  \n",
      "Epoch 12: val_accuracy did not improve from 0.98262\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9462 - loss: 0.9393 - val_accuracy: 0.9821 - val_loss: 0.7855 - learning_rate: 0.0031\n",
      "Run 14, Epoch 13/30\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8369 - loss: 1.2412  \n",
      "Epoch 13: val_accuracy did not improve from 0.87782\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8369 - loss: 1.2412 - val_accuracy: 0.8763 - val_loss: 1.2511 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8522 - loss: 1.1380  \n",
      "Epoch 13: val_accuracy did not improve from 0.91276\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8522 - loss: 1.1381 - val_accuracy: 0.9118 - val_loss: 1.0674 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 13/13\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9471 - loss: 0.9231  \n",
      "Epoch 13: val_accuracy improved from 0.98262 to 0.98295, saving model to autosaveP48_14_13.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9471 - loss: 0.9232 - val_accuracy: 0.9829 - val_loss: 0.7778 - learning_rate: 0.0031\n",
      "Run 14, Epoch 14/30\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8360 - loss: 1.2375  \n",
      "Epoch 14: val_accuracy did not improve from 0.87782\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8360 - loss: 1.2375 - val_accuracy: 0.8747 - val_loss: 1.2478 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8542 - loss: 1.1284  \n",
      "Epoch 14: val_accuracy did not improve from 0.91276\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8542 - loss: 1.1284 - val_accuracy: 0.9105 - val_loss: 1.0651 - learning_rate: 0.0031\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.003125.\n",
      "Epoch 14/14\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9447 - loss: 0.9280  \n",
      "Epoch 14: val_accuracy did not improve from 0.98295\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9447 - loss: 0.9280 - val_accuracy: 0.9810 - val_loss: 0.7743 - learning_rate: 0.0031\n",
      "Run 14, Epoch 15/30\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8381 - loss: 1.2206  \n",
      "Epoch 15: val_accuracy did not improve from 0.87782\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8381 - loss: 1.2206 - val_accuracy: 0.8766 - val_loss: 1.2411 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8558 - loss: 1.1324  \n",
      "Epoch 15: val_accuracy improved from 0.91276 to 0.91307, saving model to autosaveP24_14_15.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8558 - loss: 1.1324 - val_accuracy: 0.9131 - val_loss: 1.0595 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 15/15\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9441 - loss: 0.9203  \n",
      "Epoch 15: val_accuracy did not improve from 0.98295\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9441 - loss: 0.9203 - val_accuracy: 0.9829 - val_loss: 0.7683 - learning_rate: 0.0016\n",
      "Run 14, Epoch 16/30\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8377 - loss: 1.2368  \n",
      "Epoch 16: val_accuracy did not improve from 0.87782\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8377 - loss: 1.2368 - val_accuracy: 0.8772 - val_loss: 1.2359 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8546 - loss: 1.1235  \n",
      "Epoch 16: val_accuracy did not improve from 0.91307\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8546 - loss: 1.1235 - val_accuracy: 0.9111 - val_loss: 1.0589 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 16/16\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9473 - loss: 0.9196  \n",
      "Epoch 16: val_accuracy did not improve from 0.98295\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9473 - loss: 0.9196 - val_accuracy: 0.9826 - val_loss: 0.7649 - learning_rate: 0.0016\n",
      "Run 14, Epoch 17/30\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8392 - loss: 1.2270  \n",
      "Epoch 17: val_accuracy did not improve from 0.87782\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8392 - loss: 1.2270 - val_accuracy: 0.8776 - val_loss: 1.2340 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8550 - loss: 1.1239  \n",
      "Epoch 17: val_accuracy improved from 0.91307 to 0.91322, saving model to autosaveP24_14_17.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8550 - loss: 1.1239 - val_accuracy: 0.9132 - val_loss: 1.0563 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0015625.\n",
      "Epoch 17/17\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9468 - loss: 0.9034  \n",
      "Epoch 17: val_accuracy improved from 0.98295 to 0.98345, saving model to autosaveP48_14_17.keras\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9468 - loss: 0.9034 - val_accuracy: 0.9834 - val_loss: 0.7620 - learning_rate: 0.0016\n",
      "Run 14, Epoch 18/30\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8409 - loss: 1.2180  \n",
      "Epoch 18: val_accuracy improved from 0.87782 to 0.87972, saving model to autosaveAdult_14_18.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8409 - loss: 1.2180 - val_accuracy: 0.8797 - val_loss: 1.2322 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8613 - loss: 1.1057  \n",
      "Epoch 18: val_accuracy improved from 0.91322 to 0.91338, saving model to autosaveP24_14_18.keras\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8613 - loss: 1.1057 - val_accuracy: 0.9134 - val_loss: 1.0537 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 18/18\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9457 - loss: 0.9110  \n",
      "Epoch 18: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9457 - loss: 0.9110 - val_accuracy: 0.9834 - val_loss: 0.7616 - learning_rate: 7.8125e-04\n",
      "Run 14, Epoch 19/30\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8387 - loss: 1.2140  \n",
      "Epoch 19: val_accuracy improved from 0.87972 to 0.88057, saving model to autosaveAdult_14_19.keras\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8387 - loss: 1.2140 - val_accuracy: 0.8806 - val_loss: 1.2305 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8545 - loss: 1.1228  \n",
      "Epoch 19: val_accuracy did not improve from 0.91338\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8545 - loss: 1.1228 - val_accuracy: 0.9129 - val_loss: 1.0531 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 19/19\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9468 - loss: 0.8964  \n",
      "Epoch 19: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9468 - loss: 0.8964 - val_accuracy: 0.9831 - val_loss: 0.7603 - learning_rate: 7.8125e-04\n",
      "Run 14, Epoch 20/30\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8362 - loss: 1.2265  \n",
      "Epoch 20: val_accuracy did not improve from 0.88057\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8362 - loss: 1.2264 - val_accuracy: 0.8778 - val_loss: 1.2296 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8568 - loss: 1.1094  \n",
      "Epoch 20: val_accuracy did not improve from 0.91338\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8568 - loss: 1.1094 - val_accuracy: 0.9114 - val_loss: 1.0523 - learning_rate: 7.8125e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00078125.\n",
      "Epoch 20/20\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9491 - loss: 0.8945  \n",
      "Epoch 20: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9491 - loss: 0.8945 - val_accuracy: 0.9825 - val_loss: 0.7583 - learning_rate: 7.8125e-04\n",
      "Run 14, Epoch 21/30\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8389 - loss: 1.1935  \n",
      "Epoch 21: val_accuracy did not improve from 0.88057\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8389 - loss: 1.1935 - val_accuracy: 0.8787 - val_loss: 1.2272 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8563 - loss: 1.1041  \n",
      "Epoch 21: val_accuracy did not improve from 0.91338\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8563 - loss: 1.1042 - val_accuracy: 0.9117 - val_loss: 1.0512 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 21/21\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9473 - loss: 0.9002  \n",
      "Epoch 21: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9473 - loss: 0.9001 - val_accuracy: 0.9829 - val_loss: 0.7575 - learning_rate: 3.9063e-04\n",
      "Run 14, Epoch 22/30\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8409 - loss: 1.2031  \n",
      "Epoch 22: val_accuracy did not improve from 0.88057\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8409 - loss: 1.2031 - val_accuracy: 0.8789 - val_loss: 1.2270 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8577 - loss: 1.1115  \n",
      "Epoch 22: val_accuracy did not improve from 0.91338\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8577 - loss: 1.1115 - val_accuracy: 0.9128 - val_loss: 1.0505 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 22/22\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9476 - loss: 0.9020  \n",
      "Epoch 22: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9476 - loss: 0.9020 - val_accuracy: 0.9829 - val_loss: 0.7573 - learning_rate: 3.9063e-04\n",
      "Run 14, Epoch 23/30\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8398 - loss: 1.2060  \n",
      "Epoch 23: val_accuracy did not improve from 0.88057\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8398 - loss: 1.2060 - val_accuracy: 0.8785 - val_loss: 1.2258 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8571 - loss: 1.1142  \n",
      "Epoch 23: val_accuracy did not improve from 0.91338\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8571 - loss: 1.1142 - val_accuracy: 0.9132 - val_loss: 1.0496 - learning_rate: 3.9063e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000390625.\n",
      "Epoch 23/23\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9498 - loss: 0.8969  \n",
      "Epoch 23: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9498 - loss: 0.8969 - val_accuracy: 0.9829 - val_loss: 0.7565 - learning_rate: 3.9063e-04\n",
      "Run 14, Epoch 24/30\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8402 - loss: 1.2149  \n",
      "Epoch 24: val_accuracy did not improve from 0.88057\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8402 - loss: 1.2149 - val_accuracy: 0.8785 - val_loss: 1.2251 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8579 - loss: 1.1064  \n",
      "Epoch 24: val_accuracy did not improve from 0.91338\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8579 - loss: 1.1063 - val_accuracy: 0.9121 - val_loss: 1.0492 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 24/24\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9498 - loss: 0.8953  \n",
      "Epoch 24: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9498 - loss: 0.8954 - val_accuracy: 0.9831 - val_loss: 0.7562 - learning_rate: 1.9531e-04\n",
      "Run 14, Epoch 25/30\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8425 - loss: 1.1999  \n",
      "Epoch 25: val_accuracy did not improve from 0.88057\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8425 - loss: 1.1999 - val_accuracy: 0.8780 - val_loss: 1.2251 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8611 - loss: 1.1116  \n",
      "Epoch 25: val_accuracy did not improve from 0.91338\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8611 - loss: 1.1116 - val_accuracy: 0.9129 - val_loss: 1.0489 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 25/25\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9479 - loss: 0.9021  \n",
      "Epoch 25: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9479 - loss: 0.9021 - val_accuracy: 0.9833 - val_loss: 0.7561 - learning_rate: 1.9531e-04\n",
      "Run 14, Epoch 26/30\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8413 - loss: 1.2099  \n",
      "Epoch 26: val_accuracy did not improve from 0.88057\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8413 - loss: 1.2099 - val_accuracy: 0.8782 - val_loss: 1.2255 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8615 - loss: 1.1127  \n",
      "Epoch 26: val_accuracy did not improve from 0.91338\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8614 - loss: 1.1127 - val_accuracy: 0.9125 - val_loss: 1.0489 - learning_rate: 1.9531e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001953125.\n",
      "Epoch 26/26\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9476 - loss: 0.8910  \n",
      "Epoch 26: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9476 - loss: 0.8910 - val_accuracy: 0.9831 - val_loss: 0.7556 - learning_rate: 1.9531e-04\n",
      "Run 14, Epoch 27/30\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8396 - loss: 1.1928  \n",
      "Epoch 27: val_accuracy did not improve from 0.88057\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8396 - loss: 1.1928 - val_accuracy: 0.8782 - val_loss: 1.2252 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8596 - loss: 1.1055  \n",
      "Epoch 27: val_accuracy did not improve from 0.91338\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8596 - loss: 1.1055 - val_accuracy: 0.9123 - val_loss: 1.0486 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 27/27\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9490 - loss: 0.8992  \n",
      "Epoch 27: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9490 - loss: 0.8992 - val_accuracy: 0.9834 - val_loss: 0.7554 - learning_rate: 9.7656e-05\n",
      "Run 14, Epoch 28/30\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8375 - loss: 1.2148  \n",
      "Epoch 28: val_accuracy did not improve from 0.88057\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8375 - loss: 1.2147 - val_accuracy: 0.8782 - val_loss: 1.2252 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8575 - loss: 1.1087  \n",
      "Epoch 28: val_accuracy did not improve from 0.91338\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8575 - loss: 1.1087 - val_accuracy: 0.9121 - val_loss: 1.0485 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 28/28\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9475 - loss: 0.8985  \n",
      "Epoch 28: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9475 - loss: 0.8985 - val_accuracy: 0.9831 - val_loss: 0.7551 - learning_rate: 9.7656e-05\n",
      "Run 14, Epoch 29/30\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8396 - loss: 1.2002  \n",
      "Epoch 29: val_accuracy did not improve from 0.88057\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8396 - loss: 1.2003 - val_accuracy: 0.8782 - val_loss: 1.2252 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8589 - loss: 1.1022  \n",
      "Epoch 29: val_accuracy did not improve from 0.91338\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8589 - loss: 1.1022 - val_accuracy: 0.9123 - val_loss: 1.0484 - learning_rate: 9.7656e-05\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 9.765625e-05.\n",
      "Epoch 29/29\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9485 - loss: 0.9017  \n",
      "Epoch 29: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9485 - loss: 0.9017 - val_accuracy: 0.9829 - val_loss: 0.7548 - learning_rate: 9.7656e-05\n",
      "Run 14, Epoch 30/30\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8380 - loss: 1.2172  \n",
      "Epoch 30: val_accuracy did not improve from 0.88057\n",
      "\u001b[1m371/371\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8380 - loss: 1.2172 - val_accuracy: 0.8782 - val_loss: 1.2250 - learning_rate: 4.8828e-05\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8590 - loss: 1.1030  \n",
      "Epoch 30: val_accuracy did not improve from 0.91338\n",
      "\u001b[1m507/507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8590 - loss: 1.1030 - val_accuracy: 0.9123 - val_loss: 1.0483 - learning_rate: 4.8828e-05\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 4.8828125e-05.\n",
      "Epoch 30/30\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9494 - loss: 0.8998  \n",
      "Epoch 30: val_accuracy did not improve from 0.98345\n",
      "\u001b[1m472/472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9494 - loss: 0.8998 - val_accuracy: 0.9831 - val_loss: 0.7549 - learning_rate: 4.8828e-05\n",
      "Completed run 14 with 30 epochs\n",
      "autosaveAdult_14_19.keras\n",
      "\u001b[1m1333/1333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 803us/step - accuracy: 0.8832 - loss: 1.2221\n",
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8821 - loss: 1.2351\n",
      "autosaveP24_14_18.keras\n",
      "\u001b[1m1825/1825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 752us/step - accuracy: 0.9106 - loss: 1.0645\n",
      "\u001b[1m203/203\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 1.0750\n",
      "autosaveP48_14_17.keras\n",
      "\u001b[1m1699/1699\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step - accuracy: 0.9813 - loss: 0.7718\n",
      "\u001b[1m189/189\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9841 - loss: 0.7701\n",
      "RunTable:\n",
      "      Unnamed: 0  Run  Epoch  Stage         Hist_val_loss  \\\n",
      "0              0    1      1  Adult   [2.938805103302002]   \n",
      "1              1    1      1    P24  [2.2092459201812744]   \n",
      "2              2    1      1    P48   [9.400016784667969]   \n",
      "3              3    1      2  Adult  [2.8421051502227783]   \n",
      "4              4    1      2    P24   [2.054847002029419]   \n",
      "...          ...  ...    ...    ...                   ...   \n",
      "1255        1255   14     29    P24  [1.0483522415161133]   \n",
      "1256        1256   14     29    P48   [0.754846453666687]   \n",
      "1257        1257   14     30  Adult  [1.2249757051467896]   \n",
      "1258        1258   14     30    P24  [1.0483496189117432]   \n",
      "1259        1259   14     30    P48  [0.7548895478248596]   \n",
      "\n",
      "              Hist_val_acc             Hist_loss              Hist_acc  \n",
      "0     [0.8187381029129028]   [4.149147033691406]  [0.5197417140007019]  \n",
      "1     [0.8477188944816589]   [3.356295347213745]  [0.6066309213638306]  \n",
      "2     [0.8829663991928101]   [8.933090209960938]  [0.5696667432785034]  \n",
      "3     [0.8278117775917053]   [3.692173719406128]  [0.6339502334594727]  \n",
      "4       [0.86174476146698]   [2.723989486694336]  [0.7113813757896423]  \n",
      "...                    ...                   ...                   ...  \n",
      "1255   [0.912299633026123]  [1.0968517065048218]  [0.8579641580581665]  \n",
      "1256  [0.9829498529434204]  [0.9018520712852478]  [0.9471767544746399]  \n",
      "1257  [0.8782443404197693]  [1.2123640775680542]  [0.8383311629295349]  \n",
      "1258   [0.912299633026123]  [1.1051117181777954]  [0.8581491708755493]  \n",
      "1259  [0.9831153750419617]  [0.8989394307136536]   [0.948352038860321]  \n",
      "\n",
      "[1260 rows x 8 columns]\n",
      "EvalTable:\n",
      "    Unnamed: 0  Run  EpochSave  Stage                   Filename  \\\n",
      "0            0    1         18  Adult   autosaveAdult_1_18.keras   \n",
      "1            1    1         20    P24     autosaveP24_1_20.keras   \n",
      "2            2    1         15    P48     autosaveP48_1_15.keras   \n",
      "3            3    2         24  Adult   autosaveAdult_2_24.keras   \n",
      "4            4    2         20    P24     autosaveP24_2_20.keras   \n",
      "5            5    2         12    P48     autosaveP48_2_12.keras   \n",
      "6            6    3         22  Adult   autosaveAdult_3_22.keras   \n",
      "7            7    3         22    P24     autosaveP24_3_22.keras   \n",
      "8            8    3         15    P48     autosaveP48_3_15.keras   \n",
      "9            9    4         23  Adult   autosaveAdult_4_23.keras   \n",
      "10          10    4         30    P24     autosaveP24_4_30.keras   \n",
      "11          11    4         11    P48     autosaveP48_4_11.keras   \n",
      "12          12    5         20  Adult   autosaveAdult_5_20.keras   \n",
      "13          13    5         13    P24     autosaveP24_5_13.keras   \n",
      "14          14    5         15    P48     autosaveP48_5_15.keras   \n",
      "15          15    6         14  Adult   autosaveAdult_6_14.keras   \n",
      "16          16    6         26    P24     autosaveP24_6_26.keras   \n",
      "17          17    6         13    P48     autosaveP48_6_13.keras   \n",
      "18          18    7         16  Adult   autosaveAdult_7_16.keras   \n",
      "19          19    7         23    P24     autosaveP24_7_23.keras   \n",
      "20          20    7         20    P48     autosaveP48_7_20.keras   \n",
      "21          21    8         17  Adult   autosaveAdult_8_17.keras   \n",
      "22          22    8         25    P24     autosaveP24_8_25.keras   \n",
      "23          23    8         28    P48     autosaveP48_8_28.keras   \n",
      "24          24    9         18  Adult   autosaveAdult_9_18.keras   \n",
      "25          25    9         20    P24     autosaveP24_9_20.keras   \n",
      "26          26    9         19    P48     autosaveP48_9_19.keras   \n",
      "27          27   10         21  Adult  autosaveAdult_10_21.keras   \n",
      "28          28   10         19    P24    autosaveP24_10_19.keras   \n",
      "29          29   10         17    P48    autosaveP48_10_17.keras   \n",
      "30          30   11         13  Adult  autosaveAdult_11_13.keras   \n",
      "31          31   11         17    P24    autosaveP24_11_17.keras   \n",
      "32          32   11         12    P48    autosaveP48_11_12.keras   \n",
      "33          33   12         13  Adult  autosaveAdult_12_13.keras   \n",
      "34          34   12         16    P24    autosaveP24_12_16.keras   \n",
      "35          35   12         22    P48    autosaveP48_12_22.keras   \n",
      "36          36   13         20  Adult  autosaveAdult_13_20.keras   \n",
      "37          37   13         15    P24    autosaveP24_13_15.keras   \n",
      "38          38   13         15    P48    autosaveP48_13_15.keras   \n",
      "39          39   14         19  Adult  autosaveAdult_14_19.keras   \n",
      "40          40   14         18    P24    autosaveP24_14_18.keras   \n",
      "41          41   14         17    P48    autosaveP48_14_17.keras   \n",
      "\n",
      "    Manual_Val_Loss  Manual_Val_Acc  Manual_Train_Loss  Manual_Train_Acc  \n",
      "0          1.289427        0.878666           1.274774          0.883418  \n",
      "1          1.092069        0.912608           1.096994          0.909385  \n",
      "2          0.844721        0.983612           0.855351          0.980172  \n",
      "3          1.251952        0.877822           1.239374          0.885458  \n",
      "4          1.069798        0.913379           1.074684          0.910396  \n",
      "5          0.823098        0.983943           0.832759          0.981386  \n",
      "6          1.249440        0.879088           1.235688          0.884426  \n",
      "7          1.063993        0.912762           1.068662          0.911166  \n",
      "8          0.773603        0.982950           0.782226          0.981423  \n",
      "9          1.236420        0.882254           1.225002          0.885458  \n",
      "10         1.056712        0.911683           1.061821          0.911423  \n",
      "11         0.795637        0.983943           0.802740          0.982471  \n",
      "12         1.246546        0.880355           1.232611          0.884942  \n",
      "13         1.077232        0.913070           1.081682          0.911646  \n",
      "14         0.787449        0.983778           0.796476          0.981018  \n",
      "15         1.256902        0.879932           1.242799          0.884051  \n",
      "16         1.052390        0.914612           1.057770          0.911475  \n",
      "17         0.783950        0.983446           0.791815          0.982251  \n",
      "18         1.244153        0.880988           1.229693          0.885856  \n",
      "19         1.053494        0.914920           1.058347          0.911389  \n",
      "20         0.761211        0.983115           0.770434          0.981717  \n",
      "21         1.239286        0.879721           1.225729          0.885387  \n",
      "22         1.052654        0.911837           1.057756          0.910550  \n",
      "23         0.754088        0.984274           0.762589          0.982306  \n",
      "24         1.246179        0.880777           1.229464          0.885505  \n",
      "25         1.056380        0.912300           1.061143          0.910498  \n",
      "26         0.759583        0.982950           0.766131          0.981864  \n",
      "27         1.238053        0.879932           1.223012          0.885622  \n",
      "28         1.053085        0.913070           1.060352          0.910002  \n",
      "29         0.754183        0.983612           0.761444          0.981975  \n",
      "30         1.266477        0.877189           1.250357          0.883863  \n",
      "31         1.057970        0.914149           1.062439          0.911372  \n",
      "32         0.786892        0.982784           0.795767          0.980687  \n",
      "33         1.264814        0.876556           1.249092          0.884567  \n",
      "34         1.059712        0.911837           1.065486          0.909488  \n",
      "35         0.764284        0.983446           0.772180          0.981496  \n",
      "36         1.231554        0.877611           1.217166          0.885692  \n",
      "37         1.058930        0.913070           1.065334          0.912091  \n",
      "38         0.774427        0.983115           0.783198          0.982048  \n",
      "39         1.230461        0.880566           1.217888          0.884262  \n",
      "40         1.053694        0.913379           1.059124          0.912005  \n",
      "41         0.762000        0.983446           0.770535          0.981920  \n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import glob\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from joblib import dump\n",
    "import os\n",
    "\n",
    "# Define the directory path where your data is located\n",
    "directory_path = '/n/sci/SCI-004375-NYUDATA/Filippo/Multiome'\n",
    "os.chdir(directory_path)\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# Loading in shuffled datasets with full file paths\n",
    "Adult = np.load(os.path.join(directory_path, \"AdultData_Shuffled.npy\"))\n",
    "ClustersAdult = np.load(os.path.join(directory_path, \"AdultIDs_Shuffled.npy\"))\n",
    "\n",
    "P24 = np.load(os.path.join(directory_path, \"P24Data_Shuffled.npy\"))\n",
    "ClustersP24 = np.load(os.path.join(directory_path, \"P24IDs_Shuffled.npy\"))\n",
    "\n",
    "P48 = np.load(os.path.join(directory_path, \"P48Data_Shuffled.npy\"))\n",
    "ClustersP48 = np.load(os.path.join(directory_path, \"P48IDs_Shuffled.npy\"))\n",
    "\n",
    "# Set the input shapes based on the dataset shapes\n",
    "inputAdult_shape = 742\n",
    "inputP24_shape = 632\n",
    "inputP48_shape = 752\n",
    "\n",
    "# Encoder\n",
    "Clusters = np.concatenate((ClustersAdult, ClustersP24, ClustersP48))\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Clusters)\n",
    "Clusters = encoder.transform(Clusters)\n",
    "Clusters = to_categorical(Clusters)\n",
    "dump(encoder, 'Encoder_multinet.joblib')  # Saving encoder file joblib 0.17.0\n",
    "\n",
    "ClustersAdult = Clusters[:len(ClustersAdult), ]\n",
    "ClustersP24 = Clusters[len(ClustersAdult):len(ClustersAdult) + len(ClustersP24), ]\n",
    "ClustersP48 = Clusters[len(ClustersAdult) + len(ClustersP24):len(ClustersAdult) + len(ClustersP24) + len(ClustersP48), ]\n",
    "\n",
    "# Normalization\n",
    "meanAdult = Adult.mean(axis=0)\n",
    "Adult -= meanAdult\n",
    "np.save('meanAdult.npy', meanAdult)  # Save the mean for normalization\n",
    "\n",
    "meanP24 = P24.mean(axis=0)\n",
    "P24 -= meanP24\n",
    "np.save('meanP24.npy', meanP24)  # Save the mean for normalization\n",
    "\n",
    "meanP48 = P48.mean(axis=0)\n",
    "P48 -= meanP48\n",
    "np.save('meanP48.npy', meanP48)  # Save the mean for normalization\n",
    "\n",
    "y_integers = np.argmax(Clusters, axis=1)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_integers), y=y_integers)\n",
    "d_class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "# Define input layers with the correct shapes\n",
    "inputAdult = Input(shape=(inputAdult_shape,))  # Shape input # of cluster marker genes\n",
    "inputP24 = Input(shape=(inputP24_shape,))\n",
    "inputP48 = Input(shape=(inputP48_shape,))\n",
    "\n",
    "def create_model(input_tensor):\n",
    "    x = layers.Dropout(0.2)(input_tensor)\n",
    "    x = layers.Dense(200, kernel_regularizer=regularizers.l2(0.002), activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    output_tensor = layers.Dense(259, kernel_regularizer=regularizers.l2(0.002), activation='softmax')(x)  # Updated output shape\n",
    "    return Model(input_tensor, output_tensor)\n",
    "\n",
    "modelAdult = create_model(inputAdult)\n",
    "modelP24 = create_model(inputP24)\n",
    "modelP48 = create_model(inputP48)\n",
    "\n",
    "# Define a new optimizer for each model\n",
    "def get_optimizer():\n",
    "    return tf.keras.optimizers.SGD(learning_rate=0.05, momentum=0.9, nesterov=True)\n",
    "\n",
    "modelAdult.compile(optimizer=get_optimizer(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "modelP24.compile(optimizer=get_optimizer(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "modelP48.compile(optimizer=get_optimizer(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.05\n",
    "    drop = 0.5\n",
    "    epochs_drop = 3\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "def find_last(files):\n",
    "    epochs = []\n",
    "    for k in files:\n",
    "        splits = k.split(\"_\")\n",
    "        finalepoch = splits[2].split(\".\")[0]\n",
    "        epochs.append(int(finalepoch))\n",
    "    maxepoch = max(epochs)\n",
    "    return str(maxepoch).zfill(2)\n",
    "\n",
    "RunTable = pd.DataFrame(columns=['Run', 'Epoch', 'Stage', 'Hist_val_loss', 'Hist_val_acc', 'Hist_loss', 'Hist_acc'])\n",
    "EvalTable = pd.DataFrame(columns=['Run', 'EpochSave', 'Stage', 'Filename', 'Manual_Val_Loss', 'Manual_Val_Acc', 'Manual_Train_Loss', 'Manual_Train_Acc'])\n",
    "\n",
    "best_manual_val_loss = float('inf')\n",
    "best_manual_val_acc = 0\n",
    "\n",
    "# Define the split points for new datasets\n",
    "split_P24 = 58390\n",
    "split_P48 = 54368\n",
    "split_Adult = 42648\n",
    "\n",
    "eps = 30\n",
    "for j in range(1, 15):  # Changed to 14 runs\n",
    "    # Print the current run number\n",
    "    print(f\"Starting run {j}\")\n",
    "\n",
    "    # Initialize lists to store metrics for each run\n",
    "    val_loss_Adult = []\n",
    "    val_acc_Adult = []\n",
    "    loss_Adult = []\n",
    "    acc_Adult = []\n",
    "    val_loss_P24 = []\n",
    "    val_acc_P24 = []\n",
    "    loss_P24 = []\n",
    "    acc_P24 = []\n",
    "    val_loss_P48 = []\n",
    "    val_acc_P48 = []\n",
    "    loss_P48 = []\n",
    "    acc_P48 = []\n",
    "\n",
    "    callbacks_list1 = [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath=f'autosaveAdult_{j}_{{epoch:02d}}.keras', monitor='val_accuracy', save_best_only=True, verbose=1),\n",
    "        tf.keras.callbacks.LearningRateScheduler(step_decay, verbose=1),\n",
    "    ]\n",
    "    callbacks_list2 = [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath=f'autosaveP24_{j}_{{epoch:02d}}.keras', monitor='val_accuracy', save_best_only=True, verbose=1),\n",
    "        tf.keras.callbacks.LearningRateScheduler(step_decay, verbose=1),\n",
    "    ]\n",
    "    callbacks_list3 = [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ModelCheckpoint(filepath=f'autosaveP48_{j}_{{epoch:02d}}.keras', monitor='val_accuracy', save_best_only=True, verbose=1),\n",
    "        tf.keras.callbacks.LearningRateScheduler(step_decay, verbose=1),\n",
    "    ]\n",
    "\n",
    "    for i in range(eps):\n",
    "        # Print the current epoch number\n",
    "        print(f\"Run {j}, Epoch {i+1}/{eps}\")\n",
    "\n",
    "        history = modelAdult.fit(Adult, ClustersAdult, epochs=i+1, initial_epoch=i, batch_size=128, callbacks=callbacks_list1, validation_data=(Adult[split_Adult:], ClustersAdult[split_Adult:]), shuffle=True, class_weight=d_class_weights)\n",
    "\n",
    "        val_loss_Adult.append(history.history['val_loss'])\n",
    "        val_acc_Adult.append(history.history['val_accuracy'])\n",
    "        loss_Adult.append(history.history['loss'])\n",
    "        acc_Adult.append(history.history['accuracy'])\n",
    "\n",
    "        RunTable = pd.concat([RunTable, pd.DataFrame({\n",
    "            'Run': [j], 'Epoch': [i+1], 'Stage': ['Adult'],\n",
    "            'Hist_val_loss': [history.history['val_loss']], 'Hist_val_acc': [history.history['val_accuracy']],\n",
    "            'Hist_loss': [history.history['loss']], 'Hist_acc': [history.history['accuracy']]\n",
    "        })], ignore_index=True)\n",
    "\n",
    "        # Copying weights from Adult to P24\n",
    "        w = modelAdult.layers[3].get_weights()\n",
    "        modelP24.layers[3].set_weights(w)\n",
    "        modelP24.compile(optimizer=get_optimizer(), loss='categorical_crossentropy', metrics=['accuracy'])  # Recompile the model\n",
    "        history = modelP24.fit(P24, ClustersP24, epochs=i+1, initial_epoch=i, batch_size=128, callbacks=callbacks_list2, validation_data=(P24[split_P24:], ClustersP24[split_P24:]), shuffle=True, class_weight=d_class_weights)\n",
    "\n",
    "        val_loss_P24.append(history.history['val_loss'])\n",
    "        val_acc_P24.append(history.history['val_accuracy'])\n",
    "        loss_P24.append(history.history['loss'])\n",
    "        acc_P24.append(history.history['accuracy'])\n",
    "\n",
    "        RunTable = pd.concat([RunTable, pd.DataFrame({\n",
    "            'Run': [j], 'Epoch': [i+1], 'Stage': ['P24'],\n",
    "            'Hist_val_loss': [history.history['val_loss']], 'Hist_val_acc': [history.history['val_accuracy']],\n",
    "            'Hist_loss': [history.history['loss']], 'Hist_acc': [history.history['accuracy']]\n",
    "        })], ignore_index=True)\n",
    "\n",
    "        # Copying weights from P24 to P48\n",
    "        w = modelP24.layers[3].get_weights()\n",
    "        modelP48.layers[3].set_weights(w)\n",
    "        modelP48.compile(optimizer=get_optimizer(), loss='categorical_crossentropy', metrics=['accuracy'])  # Recompile the model\n",
    "        history = modelP48.fit(P48, ClustersP48, epochs=i+1, initial_epoch=i, batch_size=128, callbacks=callbacks_list3, validation_data=(P48[split_P48:], ClustersP48[split_P48:]), shuffle=True, class_weight=d_class_weights)\n",
    "\n",
    "        val_loss_P48.append(history.history['val_loss'])\n",
    "        val_acc_P48.append(history.history['val_accuracy'])\n",
    "        loss_P48.append(history.history['loss'])\n",
    "        acc_P48.append(history.history['accuracy'])\n",
    "\n",
    "        RunTable = pd.concat([RunTable, pd.DataFrame({\n",
    "            'Run': [j], 'Epoch': [i+1], 'Stage': ['P48'],\n",
    "            'Hist_val_loss': [history.history['val_loss']], 'Hist_val_acc': [history.history['val_accuracy']],\n",
    "            'Hist_loss': [history.history['loss']], 'Hist_acc': [history.history['accuracy']]\n",
    "        })], ignore_index=True)\n",
    "\n",
    "        # Copying weights from P48 back to Adult\n",
    "        w = modelP48.layers[3].get_weights()\n",
    "        modelAdult.layers[3].set_weights(w)\n",
    "        modelAdult.compile(optimizer=get_optimizer(), loss='categorical_crossentropy', metrics=['accuracy'])  # Recompile the model\n",
    "        RunTable.to_csv('RunTable.csv')\n",
    "\n",
    "    # Print a summary after completing all epochs for the current run\n",
    "    print(f\"Completed run {j} with {eps} epochs\")\n",
    "\n",
    "    # Evaluate and save the best models\n",
    "    for stage, files, model, data, clusters, data_split in [\n",
    "        ('Adult', glob.glob(f'autosaveAdult_{j}_*.keras'), modelAdult, Adult, ClustersAdult, split_Adult),\n",
    "        ('P24', glob.glob(f'autosaveP24_{j}_*.keras'), modelP24, P24, ClustersP24, split_P24),\n",
    "        ('P48', glob.glob(f'autosaveP48_{j}_*.keras'), modelP48, P48, ClustersP48, split_P48)\n",
    "    ]:\n",
    "        topepoch = find_last(files)\n",
    "        topfile = f'autosave{stage}_{j}_{topepoch}.keras'\n",
    "        print(topfile)\n",
    "        try:\n",
    "            top_model = load_model(topfile)\n",
    "            resultsTrain = top_model.evaluate(data[:data_split, ], clusters[:data_split, ])\n",
    "            resultsVal = top_model.evaluate(data[data_split:, ], clusters[data_split:, ])\n",
    "            EvalTable = pd.concat([EvalTable, pd.DataFrame({\n",
    "                'Run': [j], 'EpochSave': [topepoch], 'Stage': [stage],\n",
    "                'Filename': [topfile], 'Manual_Val_Loss': [resultsVal[0]], 'Manual_Val_Acc': [resultsVal[1]],\n",
    "                'Manual_Train_Loss': [resultsTrain[0]], 'Manual_Train_Acc': [resultsTrain[1]]\n",
    "            })], ignore_index=True)\n",
    "            EvalTable.to_csv('EvalTable.csv')\n",
    "\n",
    "            # Check if this is the best model so far based on validation loss and accuracy\n",
    "            if resultsVal[0] < best_manual_val_loss or (resultsVal[0] == best_manual_val_loss and resultsVal[1] > best_manual_val_acc):\n",
    "                best_manual_val_loss = resultsVal[0]\n",
    "                best_manual_val_acc = resultsVal[1]\n",
    "                best_model_path = f'best_model_{stage}_run_{j}.keras'\n",
    "                top_model.save(best_model_path)\n",
    "                print(f\"New best model saved: {best_model_path}\")\n",
    "\n",
    "        except ValueError as e:\n",
    "            print(f\"Error loading model {topfile}: {e}\")\n",
    "            break  # Stop further execution on error\n",
    "\n",
    "    # Re-save the model to ensure compatibility with the current TensorFlow version\n",
    "    modelAdult.save(f'modelAdult_run_{j}.keras')\n",
    "    modelP24.save(f'modelP24_run_{j}.keras')\n",
    "    modelP48.save(f'modelP48_run_{j}.keras')\n",
    "\n",
    "# Visualize the tables after all runs\n",
    "RunTable = pd.read_csv('RunTable.csv')\n",
    "print(\"RunTable:\")\n",
    "print(RunTable)\n",
    "\n",
    "# Load and print the consolidated evaluation table\n",
    "EvalTable = pd.read_csv('EvalTable.csv')\n",
    "print(\"EvalTable:\")\n",
    "print(EvalTable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553f37c2-7067-4a2b-9c2d-b075c83780ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
