{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3eb05bb-ddd3-41eb-a5b7-7d4291ab4d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /n/sci/SCI-004375-NYUDATA/Filippo/Multiome\n",
      "Data loaded from RDS file: (47387, 742)\n",
      "Clusters loaded from CSV file: (47387,)\n",
      "Data and Clusters shuffled\n",
      "Shuffled data shape: (47387, 742)\n",
      "Shuffled clusters shape: (47387,)\n",
      "Shuffled data and clusters saved as .npy files\n",
      "Number of columns in original DataFrame: 47387\n",
      "Number of columns in shuffled data array: 742\n",
      "Warning: Column length mismatch. Adjusting column names for shuffled data.\n",
      "Shuffled data and clusters saved as .csv files\n",
      "Shuffled data and clusters reloaded\n",
      "Clusters encoded and encoder saved\n",
      "Data normalized and mean saved\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pyreadr\n",
    "from joblib import dump\n",
    "import os\n",
    "\n",
    "# Define the directory path where your data is located\n",
    "directory_path = '/n/sci/SCI-004375-NYUDATA/Filippo/Multiome'\n",
    "os.chdir(directory_path)\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# Load the RDS file using pyreadr\n",
    "result = pyreadr.read_r('Adult_markersNN.rds')\n",
    "df = result[None]  # Extract the pandas DataFrame\n",
    "data = df.T\n",
    "print(\"Data loaded from RDS file:\", data.shape)\n",
    "\n",
    "# Load the CSV file\n",
    "Clusters = pd.read_csv('Adult_IDs.csv')\n",
    "Clusters = Clusters['cluster']\n",
    "print(\"Clusters loaded from CSV file:\", Clusters.shape)\n",
    "\n",
    "# Shuffle the data and clusters\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "dataShuf = data.values[indices, :]  # Convert to NumPy array and shuffle\n",
    "ClustersShuf = Clusters.values[indices]\n",
    "print(\"Data and Clusters shuffled\")\n",
    "print(\"Shuffled data shape:\", dataShuf.shape)\n",
    "print(\"Shuffled clusters shape:\", ClustersShuf.shape)\n",
    "\n",
    "# Save the shuffled indices, data, and clusters\n",
    "np.save(\"AdultShufflingIndices.npy\", indices)\n",
    "np.save(\"AdultData_Shuffled.npy\", dataShuf)\n",
    "np.save(\"AdultIDs_Shuffled.npy\", ClustersShuf)\n",
    "print(\"Shuffled data and clusters saved as .npy files\")\n",
    "\n",
    "# Verify the shape of df.columns and the dataShuf shape\n",
    "print(\"Number of columns in original DataFrame:\", len(df.columns))\n",
    "print(\"Number of columns in shuffled data array:\", dataShuf.shape[1])\n",
    "\n",
    "# Ensure the columns match the data shape\n",
    "if len(df.columns) != dataShuf.shape[1]:\n",
    "    print(\"Warning: Column length mismatch. Adjusting column names for shuffled data.\")\n",
    "    columns = [f\"Feature_{i}\" for i in range(dataShuf.shape[1])]\n",
    "else:\n",
    "    columns = df.columns\n",
    "\n",
    "# Also save the shuffled data and clusters as CSV files\n",
    "pd.DataFrame(dataShuf, columns=columns).to_csv(\"AdultData_Shuffled.csv\", index=False)\n",
    "pd.DataFrame(ClustersShuf, columns=['cluster']).to_csv(\"AdultIDs_Shuffled.csv\", index=False)\n",
    "print(\"Shuffled data and clusters saved as .csv files\")\n",
    "\n",
    "# Reload the shuffled data and clusters\n",
    "data = np.load(\"AdultData_Shuffled.npy\")\n",
    "Clusters = np.load(\"AdultIDs_Shuffled.npy\")\n",
    "print(\"Shuffled data and clusters reloaded\")\n",
    "\n",
    "# Encode the clusters\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Clusters)\n",
    "Clusters = encoder.transform(Clusters)\n",
    "Clusters = to_categorical(Clusters)\n",
    "dump(encoder, 'Encoder.joblib')\n",
    "print(\"Clusters encoded and encoder saved\")\n",
    "\n",
    "# Normalize the data\n",
    "meanData = data.mean(axis=0)\n",
    "data -= meanData\n",
    "np.save(\"AdultMeans.npy\", meanData)\n",
    "print(\"Data normalized and mean saved\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea91fb7-7a86-449f-9c96-01563d430284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff4a22fa-cc31-4a3f-b13e-bd2739cd7c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /n/sci/SCI-004375-NYUDATA/Filippo/Multiome\n",
      "Data loaded from RDS file: (64878, 632)\n",
      "Clusters loaded from CSV file: (64878,)\n",
      "Data and Clusters shuffled\n",
      "Shuffled data shape: (64878, 632)\n",
      "Shuffled clusters shape: (64878,)\n",
      "Shuffled data and clusters saved as .npy files\n",
      "Number of columns in original DataFrame: 64878\n",
      "Number of columns in shuffled data array: 632\n",
      "Warning: Column length mismatch. Adjusting column names for shuffled data.\n",
      "Shuffled data and clusters saved as .csv files\n",
      "Shuffled data and clusters reloaded\n",
      "Clusters encoded and encoder saved\n",
      "Data normalized and mean saved\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pyreadr\n",
    "from joblib import dump\n",
    "import os\n",
    "\n",
    "# Define the directory path where your data is located\n",
    "directory_path = '/n/sci/SCI-004375-NYUDATA/Filippo/Multiome'\n",
    "os.chdir(directory_path)\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# Load the RDS file using pyreadr\n",
    "result = pyreadr.read_r('P24_markersNN.rds')\n",
    "df = result[None]  # Extract the pandas DataFrame\n",
    "data = df.T\n",
    "print(\"Data loaded from RDS file:\", data.shape)\n",
    "\n",
    "# Load the CSV file\n",
    "Clusters = pd.read_csv('P24_IDs.csv')\n",
    "Clusters = Clusters['cluster']\n",
    "print(\"Clusters loaded from CSV file:\", Clusters.shape)\n",
    "\n",
    "# Shuffle the data and clusters\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "dataShuf = data.values[indices, :]  # Convert to NumPy array and shuffle\n",
    "ClustersShuf = Clusters.values[indices]\n",
    "print(\"Data and Clusters shuffled\")\n",
    "print(\"Shuffled data shape:\", dataShuf.shape)\n",
    "print(\"Shuffled clusters shape:\", ClustersShuf.shape)\n",
    "\n",
    "# Save the shuffled indices, data, and clusters\n",
    "np.save(\"P24ShufflingIndices.npy\", indices)\n",
    "np.save(\"P24Data_Shuffled.npy\", dataShuf)\n",
    "np.save(\"P24IDs_Shuffled.npy\", ClustersShuf)\n",
    "print(\"Shuffled data and clusters saved as .npy files\")\n",
    "\n",
    "# Verify the shape of df.columns and the dataShuf shape\n",
    "print(\"Number of columns in original DataFrame:\", len(df.columns))\n",
    "print(\"Number of columns in shuffled data array:\", dataShuf.shape[1])\n",
    "\n",
    "# Ensure the columns match the data shape\n",
    "if len(df.columns) != dataShuf.shape[1]:\n",
    "    print(\"Warning: Column length mismatch. Adjusting column names for shuffled data.\")\n",
    "    columns = [f\"Feature_{i}\" for i in range(dataShuf.shape[1])]\n",
    "else:\n",
    "    columns = df.columns\n",
    "\n",
    "# Also save the shuffled data and clusters as CSV files\n",
    "pd.DataFrame(dataShuf, columns=columns).to_csv(\"P24Data_Shuffled.csv\", index=False)\n",
    "pd.DataFrame(ClustersShuf, columns=['cluster']).to_csv(\"P24IDs_Shuffled.csv\", index=False)\n",
    "print(\"Shuffled data and clusters saved as .csv files\")\n",
    "\n",
    "# Reload the shuffled data and clusters\n",
    "data = np.load(\"P24Data_Shuffled.npy\")\n",
    "Clusters = np.load(\"P24IDs_Shuffled.npy\")\n",
    "print(\"Shuffled data and clusters reloaded\")\n",
    "\n",
    "# Encode the clusters\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Clusters)\n",
    "Clusters = encoder.transform(Clusters)\n",
    "Clusters = to_categorical(Clusters)\n",
    "dump(encoder, 'Encoder.joblib')\n",
    "print(\"Clusters encoded and encoder saved\")\n",
    "\n",
    "# Normalize the data\n",
    "meanData = data.mean(axis=0)\n",
    "data -= meanData\n",
    "np.save(\"P24Means.npy\", meanData)\n",
    "print(\"Data normalized and mean saved\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16d624af-5b6a-4b28-930c-b66466ac8bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /n/sci/SCI-004375-NYUDATA/Filippo/Multiome\n",
      "Data loaded from RDS file: (60409, 752)\n",
      "Clusters loaded from CSV file: (60409,)\n",
      "Data and Clusters shuffled\n",
      "Shuffled data shape: (60409, 752)\n",
      "Shuffled clusters shape: (60409,)\n",
      "Shuffled data and clusters saved as .npy files\n",
      "Number of columns in original DataFrame: 60409\n",
      "Number of columns in shuffled data array: 752\n",
      "Warning: Column length mismatch. Adjusting column names for shuffled data.\n",
      "Shuffled data and clusters saved as .csv files\n",
      "Shuffled data and clusters reloaded\n",
      "Clusters encoded and encoder saved\n",
      "Data normalized and mean saved\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pyreadr\n",
    "from joblib import dump\n",
    "import os\n",
    "\n",
    "# Define the directory path where your data is located\n",
    "directory_path = '/n/sci/SCI-004375-NYUDATA/Filippo/Multiome'\n",
    "os.chdir(directory_path)\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# Load the RDS file using pyreadr\n",
    "result = pyreadr.read_r('P48_markersNN.rds')\n",
    "df = result[None]  # Extract the pandas DataFrame\n",
    "data = df.T\n",
    "print(\"Data loaded from RDS file:\", data.shape)\n",
    "\n",
    "# Load the CSV file\n",
    "Clusters = pd.read_csv('P48_IDs.csv')\n",
    "Clusters = Clusters['x']\n",
    "print(\"Clusters loaded from CSV file:\", Clusters.shape)\n",
    "\n",
    "# Shuffle the data and clusters\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "dataShuf = data.values[indices, :]  # Convert to NumPy array and shuffle\n",
    "ClustersShuf = Clusters.values[indices]\n",
    "print(\"Data and Clusters shuffled\")\n",
    "print(\"Shuffled data shape:\", dataShuf.shape)\n",
    "print(\"Shuffled clusters shape:\", ClustersShuf.shape)\n",
    "\n",
    "# Save the shuffled indices, data, and clusters\n",
    "np.save(\"P48ShufflingIndices.npy\", indices)\n",
    "np.save(\"P48Data_Shuffled.npy\", dataShuf)\n",
    "np.save(\"P48IDs_Shuffled.npy\", ClustersShuf)\n",
    "print(\"Shuffled data and clusters saved as .npy files\")\n",
    "\n",
    "# Verify the shape of df.columns and the dataShuf shape\n",
    "print(\"Number of columns in original DataFrame:\", len(df.columns))\n",
    "print(\"Number of columns in shuffled data array:\", dataShuf.shape[1])\n",
    "\n",
    "# Ensure the columns match the data shape\n",
    "if len(df.columns) != dataShuf.shape[1]:\n",
    "    print(\"Warning: Column length mismatch. Adjusting column names for shuffled data.\")\n",
    "    columns = [f\"Feature_{i}\" for i in range(dataShuf.shape[1])]\n",
    "else:\n",
    "    columns = df.columns\n",
    "\n",
    "# Also save the shuffled data and clusters as CSV files\n",
    "pd.DataFrame(dataShuf, columns=columns).to_csv(\"P48Data_Shuffled.csv\", index=False)\n",
    "pd.DataFrame(ClustersShuf, columns=['cluster']).to_csv(\"P48IDs_Shuffled.csv\", index=False)\n",
    "print(\"Shuffled data and clusters saved as .csv files\")\n",
    "\n",
    "# Reload the shuffled data and clusters\n",
    "data = np.load(\"P48Data_Shuffled.npy\")\n",
    "Clusters = np.load(\"P48IDs_Shuffled.npy\")\n",
    "print(\"Shuffled data and clusters reloaded\")\n",
    "\n",
    "# Encode the clusters\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Clusters)\n",
    "Clusters = encoder.transform(Clusters)\n",
    "Clusters = to_categorical(Clusters)\n",
    "dump(encoder, 'Encoder.joblib')\n",
    "print(\"Clusters encoded and encoder saved\")\n",
    "\n",
    "# Normalize the data\n",
    "meanData = data.mean(axis=0)\n",
    "data -= meanData\n",
    "np.save(\"P48Means.npy\", meanData)\n",
    "print(\"Data normalized and mean saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12510f02-8622-451d-816e-ae91d4af2cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
